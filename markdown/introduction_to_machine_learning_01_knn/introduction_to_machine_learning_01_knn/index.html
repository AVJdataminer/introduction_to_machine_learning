



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="University of Wroclaw, Department of Physics and Astronomy">
      
      
        <link rel="canonical" href="https://tomaszgolan.github.io/introduction_to_machine_learning/markdown/introduction_to_machine_learning_01_knn/introduction_to_machine_learning_01_knn/">
      
      
        <meta name="author" content="Tomasz Golan">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-0.17.2, mkdocs-material-2.2.3">
    
    
      
        <title>k-Nearest Neighbors - Introduction to Machine Learning</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/application.bcabdff3.css">
      
        <link rel="stylesheet" href="../../../assets/stylesheets/application-palette.792431c1.css">
      
    
    
    
      <script src="../../../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    <script src="../../../js/require.min.js"></script>

    
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
    
    
    
      <body data-md-color-primary="blue-grey" data-md-color-accent="blue">
    
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://tomaszgolan.github.io/introduction_to_machine_learning/" title="Introduction to Machine Learning" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                Introduction to Machine Learning
              </span>
              <span class="md-header-nav__topic">
                k-Nearest Neighbors
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">&#xE5CD;</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/TomaszGolan/introduction_to_machine_learning/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      IML @ GitHub
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </span>
    Introduction to Machine Learning
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/TomaszGolan/introduction_to_machine_learning/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      IML @ GitHub
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../introduction_to_machine_learning_00_intro/introduction_to_machine_learning_00_intro/" title="Introduction" class="md-nav__link">
      Introduction
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        k-Nearest Neighbors
      </label>
    
    <a href="./" title="k-Nearest Neighbors" class="md-nav__link md-nav__link--active">
      k-Nearest Neighbors
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#useful-but-not-interesting-functions" title="useful (but not interesting) functions" class="md-nav__link">
    useful (but not interesting) functions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#our-first-ml-problem" title="Our first ML problem" class="md-nav__link">
    Our first ML problem
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nearest-neighbor" title="Nearest Neighbor" class="md-nav__link">
    Nearest Neighbor
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementation" title="Implementation" class="md-nav__link">
    Implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-magic-of-numpy" title="The magic of numpy" class="md-nav__link">
    The magic of numpy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#analysis" title="Analysis" class="md-nav__link">
    Analysis
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1-test" title="L1 test" class="md-nav__link">
    L1 test
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l2-test" title="L2 Test" class="md-nav__link">
    L2 Test
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multiclass-classification" title="Multiclass classification" class="md-nav__link">
    Multiclass classification
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#noise" title="Noise" class="md-nav__link">
    Noise
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#overfitting" title="Overfitting" class="md-nav__link">
    Overfitting
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy" title="Accuracy" class="md-nav__link">
    Accuracy
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k-nearest-neighbors_1" title="k-Nearest Neighbors" class="md-nav__link">
    k-Nearest Neighbors
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementation_1" title="Implementation" class="md-nav__link">
    Implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kanalysis" title="kAnalysis" class="md-nav__link">
    kAnalysis
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sanity-check" title="Sanity check" class="md-nav__link">
    Sanity check
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-test" title="k-Test" class="md-nav__link">
    k-Test
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hyperparameters" title="Hyperparameters" class="md-nav__link">
    Hyperparameters
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#over-under-fitting-example" title="Over-, under-fitting example" class="md-nav__link">
    Over-, under-fitting example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-dataset" title="Validation dataset" class="md-nav__link">
    Validation dataset
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#iris-dataset" title="Iris dataset" class="md-nav__link">
    Iris dataset
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#load-dataset" title="Load dataset" class="md-nav__link">
    Load dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visualize-dataset" title="Visualize dataset" class="md-nav__link">
    Visualize dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare-feature-vectors-and-labels" title="Prepare feature vectors and labels" class="md-nav__link">
    Prepare feature vectors and labels
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare-test-dataset" title="Prepare test dataset" class="md-nav__link">
    Prepare test dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#knn-from-scikit-learn" title="kNN from scikit-learn" class="md-nav__link">
    kNN from scikit-learn
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy_1" title="Accuracy" class="md-nav__link">
    Accuracy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-dependence-of-the-accuracy" title="k-dependence of the accuracy" class="md-nav__link">
    k-dependence of the accuracy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-validation" title="Cross-validation" class="md-nav__link">
    Cross-validation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-normalization" title="Data normalization" class="md-nav__link">
    Data normalization
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mnist" title="MNIST" class="md-nav__link">
    MNIST
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#load-digits" title="Load digits" class="md-nav__link">
    Load digits
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distance-between-images" title="Distance between images" class="md-nav__link">
    Distance between images
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare-data" title="Prepare data" class="md-nav__link">
    Prepare data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-validation_1" title="Cross-validation" class="md-nav__link">
    Cross-validation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#final-test" title="Final test" class="md-nav__link">
    Final test
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regression-with-knn" title="Regression with kNN" class="md-nav__link">
    Regression with kNN
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#genearate-some-fake-data" title="Genearate some fake data" class="md-nav__link">
    Genearate some fake data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make-a-fit" title="Make a fit" class="md-nav__link">
    Make a fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comment-on-numpynewaxis" title="Comment on numpy.newaxis" class="md-nav__link">
    Comment on numpy.newaxis
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#and-back-to-the-task" title="And back to the task" class="md-nav__link">
    And back to the task
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" title="Summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../introduction_to_machine_learning_02_dt/introduction_to_machine_learning_02_dt/" title="Decision Trees" class="md-nav__link">
      Decision Trees
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../introduction_to_machine_learning_03_svm/introduction_to_machine_learning_03_svm/" title="Support Vector Machine" class="md-nav__link">
      Support Vector Machine
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#useful-but-not-interesting-functions" title="useful (but not interesting) functions" class="md-nav__link">
    useful (but not interesting) functions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#our-first-ml-problem" title="Our first ML problem" class="md-nav__link">
    Our first ML problem
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#nearest-neighbor" title="Nearest Neighbor" class="md-nav__link">
    Nearest Neighbor
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementation" title="Implementation" class="md-nav__link">
    Implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-magic-of-numpy" title="The magic of numpy" class="md-nav__link">
    The magic of numpy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#analysis" title="Analysis" class="md-nav__link">
    Analysis
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l1-test" title="L1 test" class="md-nav__link">
    L1 test
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l2-test" title="L2 Test" class="md-nav__link">
    L2 Test
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multiclass-classification" title="Multiclass classification" class="md-nav__link">
    Multiclass classification
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#noise" title="Noise" class="md-nav__link">
    Noise
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#overfitting" title="Overfitting" class="md-nav__link">
    Overfitting
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy" title="Accuracy" class="md-nav__link">
    Accuracy
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k-nearest-neighbors_1" title="k-Nearest Neighbors" class="md-nav__link">
    k-Nearest Neighbors
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementation_1" title="Implementation" class="md-nav__link">
    Implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kanalysis" title="kAnalysis" class="md-nav__link">
    kAnalysis
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sanity-check" title="Sanity check" class="md-nav__link">
    Sanity check
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-test" title="k-Test" class="md-nav__link">
    k-Test
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hyperparameters" title="Hyperparameters" class="md-nav__link">
    Hyperparameters
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#over-under-fitting-example" title="Over-, under-fitting example" class="md-nav__link">
    Over-, under-fitting example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#validation-dataset" title="Validation dataset" class="md-nav__link">
    Validation dataset
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#iris-dataset" title="Iris dataset" class="md-nav__link">
    Iris dataset
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#load-dataset" title="Load dataset" class="md-nav__link">
    Load dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#visualize-dataset" title="Visualize dataset" class="md-nav__link">
    Visualize dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare-feature-vectors-and-labels" title="Prepare feature vectors and labels" class="md-nav__link">
    Prepare feature vectors and labels
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare-test-dataset" title="Prepare test dataset" class="md-nav__link">
    Prepare test dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#knn-from-scikit-learn" title="kNN from scikit-learn" class="md-nav__link">
    kNN from scikit-learn
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy_1" title="Accuracy" class="md-nav__link">
    Accuracy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-dependence-of-the-accuracy" title="k-dependence of the accuracy" class="md-nav__link">
    k-dependence of the accuracy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-validation" title="Cross-validation" class="md-nav__link">
    Cross-validation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-normalization" title="Data normalization" class="md-nav__link">
    Data normalization
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mnist" title="MNIST" class="md-nav__link">
    MNIST
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#load-digits" title="Load digits" class="md-nav__link">
    Load digits
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#distance-between-images" title="Distance between images" class="md-nav__link">
    Distance between images
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare-data" title="Prepare data" class="md-nav__link">
    Prepare data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-validation_1" title="Cross-validation" class="md-nav__link">
    Cross-validation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#final-test" title="Final test" class="md-nav__link">
    Final test
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#regression-with-knn" title="Regression with kNN" class="md-nav__link">
    Regression with kNN
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#genearate-some-fake-data" title="Genearate some fake data" class="md-nav__link">
    Genearate some fake data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make-a-fit" title="Make a fit" class="md-nav__link">
    Make a fit
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comment-on-numpynewaxis" title="Comment on numpy.newaxis" class="md-nav__link">
    Comment on numpy.newaxis
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#and-back-to-the-task" title="And back to the task" class="md-nav__link">
    And back to the task
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" title="Summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/TomaszGolan/introduction_to_machine_learning/edit/master/docs/markdown/introduction_to_machine_learning_01_knn/introduction_to_machine_learning_01_knn.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="k-nearest-neighbors">k-Nearest Neighbors<a class="headerlink" href="#k-nearest-neighbors" title="Permanent link">&para;</a></h1>
<h2 id="useful-but-not-interesting-functions"><em>useful (but not interesting) functions</em><a class="headerlink" href="#useful-but-not-interesting-functions" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>Here, I just define some functions used for making demo plots during the introduction.</p>
</li>
<li>
<p>Feel free to look at them later (especially if you are not familiar with <code>numpy</code> and <code>matplotlib</code>).</p>
</li>
<li>
<p>But now let's skip them.</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># numpy and matplotlib will be used a lot during the lecture</span>
<span class="c1"># if you are familiar with these libraries you may skip this part</span>
<span class="c1"># if not - extended comments were added to make it easier to understand</span>

<span class="c1"># it is kind of standard to import numpy as np and pyplot as plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># used later to apply different colors in for loops</span>
<span class="n">mpl_colors</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;m&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>

<span class="c1"># just to overwrite default colab style</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;default&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-talk&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">generate_random_points</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Generate a set of random 2D points</span>

<span class="sd">  size -- number of points to generate</span>
<span class="sd">  low  -- min value</span>
<span class="sd">  high -- max value</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># random_sample([size]) returns random numbers with shape defined by size</span>
  <span class="c1"># e.g.</span>
  <span class="c1"># &gt;&gt;&gt; np.random.random_sample((2, 3))</span>
  <span class="c1">#</span>
  <span class="c1"># array([[ 0.44013807,  0.77358569,  0.64338619],</span>
  <span class="c1">#        [ 0.54363868,  0.31855232,  0.16791031]])</span>
  <span class="c1">#</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">high</span> <span class="o">-</span> <span class="n">low</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="n">low</span>


<span class="k">def</span> <span class="nf">init_plot</span><span class="p">(</span><span class="n">x_range</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">y_range</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">x_label</span><span class="o">=</span><span class="s2">&quot;$x_1$&quot;</span><span class="p">,</span> <span class="n">y_label</span><span class="o">=</span><span class="s2">&quot;$x_2$&quot;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Set axes limits and labels</span>

<span class="sd">  x_range -- [min x, max x]</span>
<span class="sd">  y_range -- [min y, max y]</span>
<span class="sd">  x_label -- string</span>
<span class="sd">  y_label -- string</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># subplots returns figure and axes</span>
  <span class="c1"># (in general you may want many axes on one figure)</span>
  <span class="c1"># we do not need fig here</span>
  <span class="c1"># but we will apply changes (including adding points) to axes</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>

  <span class="c1"># set grid style and color</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;0.70&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">)</span>

  <span class="c1"># set axes limits (x_range and y_range is a list with two elements)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">x_range</span><span class="p">)</span> 
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">y_range</span><span class="p">)</span>

  <span class="c1"># set axes labels</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">x_label</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">y_label</span><span class="p">)</span>

  <span class="c1"># return axes so we can continue modyfing them later</span>
  <span class="k">return</span> <span class="n">ax</span>


<span class="k">def</span> <span class="nf">plot_random_points</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Generate and plot two (separated) sets of random points</span>

<span class="sd">  style -- latter group points style (default as first)</span>
<span class="sd">  color -- latter group color (default as first)</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># create a plot with x and y ranges from 0 to 2.5</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">init_plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">])</span>

  <span class="c1"># add two different sets of random points</span>
  <span class="c1"># first set = 5 points from [0.5, 1.0]x[0.5, 1.0]</span>
  <span class="c1"># second set = 5 points from [1.5, 2.0]x[1.5, 2.0]</span>
  <span class="c1"># generate_random_points return a numpy array in the format like</span>
  <span class="c1"># [[x1, y1], [x2, y2], ..., [xn, yn]]</span>
  <span class="c1"># pyplot.plt take separately arrays with X and Y, like</span>
  <span class="c1"># plot([x1, x2, x3], [y1, y2, y3])</span>
  <span class="c1"># thus, we transpose numpy array to the format</span>
  <span class="c1"># [[x1, x2, ..., xn], [y1, y2, ..., yn]]</span>
  <span class="c1"># and unpack it with *</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">*</span><span class="n">generate_random_points</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">*</span><span class="n">generate_random_points</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">style</span> <span class="ow">or</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">ax</span>


<span class="k">def</span> <span class="nf">plot_an_example</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Class&quot;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Plot an example of supervised or unsupervised learning&quot;&quot;&quot;</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_random_points</span><span class="p">(</span><span class="n">style</span><span class="p">,</span> <span class="n">color</span><span class="p">)</span>

  <span class="c1"># circle areas related to each set of points</span>
  <span class="c1"># pyplot.Circle((x, y), r); (x, y) - the center of a circle; r - radius</span>
  <span class="c1"># lw - line width</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Circle</span><span class="p">((</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Circle</span><span class="p">((</span><span class="mf">1.75</span><span class="p">,</span> <span class="mf">1.75</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span> <span class="ow">or</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>

  <span class="c1"># put group labels</span>
  <span class="c1"># pyplot.text just put arbitrary text in given coordinates</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.65</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">,</span> <span class="n">label</span> <span class="o">+</span> <span class="s2">&quot; I&quot;</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:</span> <span class="s1">&#39;r&#39;</span><span class="p">})</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.65</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="n">label</span> <span class="o">+</span> <span class="s2">&quot; II&quot;</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:</span> <span class="n">color</span> <span class="ow">or</span> <span class="s1">&#39;r&#39;</span><span class="p">})</span>
</pre></div>


<h2 id="our-first-ml-problem">Our first ML problem<a class="headerlink" href="#our-first-ml-problem" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>Two classes: red circles and blue squares (<strong>training</strong> samples)</p>
</li>
<li>
<p>Where does the green triangle (<strong>test</strong> sample) belong?</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">X1</span> <span class="o">=</span> <span class="n">generate_random_points</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">generate_random_points</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">new_point</span> <span class="o">=</span> <span class="n">generate_random_points</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">init_plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># [0, 2] x [0, 2]</span>

<span class="n">plot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">*</span><span class="n">X1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="o">*</span><span class="n">X2</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;bs&#39;</span><span class="p">,</span> <span class="o">*</span><span class="n">new_point</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;g^&#39;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_6_0.png" /></p>
<h2 id="nearest-neighbor">Nearest Neighbor<a class="headerlink" href="#nearest-neighbor" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>The nearest neigbor classifier <em>compares</em> a test sample with all training samples to predict a label (class).</p>
</li>
<li>
<p>How to compare two samples?</p>
<ul>
<li>
<p>L1 distance: <span><span class="MathJax_Preview">d(\vec x_1, \vec x_2) = \sum\limits_i |x_1^i - x_2^i|</span><script type="math/tex">d(\vec x_1, \vec x_2) = \sum\limits_i |x_1^i - x_2^i|</script></span></p>
</li>
<li>
<p>L2 distance: <span><span class="MathJax_Preview">d(\vec x_1, \vec x_2) = \sqrt{\sum\limits_i (x_1^i - x_2^i)^2}</span><script type="math/tex">d(\vec x_1, \vec x_2) = \sqrt{\sum\limits_i (x_1^i - x_2^i)^2}</script></span></p>
<ul>
<li>
<p>note: in practice square root is ignored (becasue is monotonic function)</p>
</li>
<li>
<p>L2 is less forgiving than L1 - prefers many small disagreements than one big one</p>
</li>
</ul>
</li>
<li>
<p>cosine distance (cosine similarity): <span><span class="MathJax_Preview">d(\vec x_1, \vec x_2) = \frac{x_1 \cdot x_1}{||\vec x_1|| \cdot ||\vec x_2||}</span><script type="math/tex">d(\vec x_1, \vec x_2) = \frac{x_1 \cdot x_1}{||\vec x_1|| \cdot ||\vec x_2||}</script></span></p>
</li>
<li>
<p>Chebyshev distance: <span><span class="MathJax_Preview">d(\vec x_1, \vec x_2) = max_i(|x_1^i - x_2^i|)</span><script type="math/tex">d(\vec x_1, \vec x_2) = max_i(|x_1^i - x_2^i|)</script></span></p>
</li>
<li>
<p>and many others</p>
</li>
</ul>
</li>
<li>
<p>The closest one determines the test sample label</p>
</li>
</ul>
<h3 id="implementation">Implementation<a class="headerlink" href="#implementation" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>The implementation of nearest neighbor algorithm is pretty straightforward</p>
</li>
<li>
<p>There is no real training process here - we just need to remember all training feature vectors and corresponding labels</p>
</li>
<li>
<p>To predict a label for new sample we just need to find the label of the closest point from training samples</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">NearestNeighbor</span><span class="p">():</span>
  <span class="sd">&quot;&quot;&quot;Nearest Neighbor Classifier&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set distance definition: 0 - L1, 1 - L2&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">distance</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span>     <span class="c1"># absolute value</span>
    <span class="k">elif</span> <span class="n">distance</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span>  <span class="c1"># square root</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Distance not defined.&quot;</span><span class="p">)</span>


  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Train the classifier (here simply save training data)</span>

<span class="sd">    x -- feature vectors (N x D)</span>
<span class="sd">    y -- labels (N x 1)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">x</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span>


  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predict and return labels for each feature vector from x</span>

<span class="sd">    x -- feature vectors (N x D)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># placeholder for N labels</span>

    <span class="c1"># loop over all test samples</span>
    <span class="k">for</span> <span class="n">x_test</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
      <span class="c1"># array of distances between current test and all training samples</span>
      <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x_train</span> <span class="o">-</span> <span class="n">x_test</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

      <span class="c1"># get the closest one</span>
      <span class="n">min_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>

      <span class="c1"># add corresponding label</span>
      <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="n">min_index</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">predictions</span>
</pre></div>


<h3 id="the-magic-of-numpy">The magic of numpy<a class="headerlink" href="#the-magic-of-numpy" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>NumPy is irreplacable tool for numerical operations on arrays</p>
</li>
<li>
<p>Using numpy we could easily find all distances using one line</p>
</li>
</ul>
<div class="codehilite"><pre><span></span>distances = np.sum(self.distance(self.x_train - x_test), axis=1)
</pre></div>


<ul>
<li>Here is how it works</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># let&#39;s create an array with 5x2 shape</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="c1"># and another array with 1x2 shape</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>

<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>[[0.79036457 0.36571819]
 [0.76743991 0.08439684]
 [0.56876884 0.97967839]
 [0.77020776 0.21238365]
 [0.94235534 0.73884472]]

[[1. 1.]]
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># subtract arguments (element-wise)</span>
<span class="c1"># note, that at least one dimension must be the same </span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>[[-0.20963543 -0.63428181]
 [-0.23256009 -0.91560316]
 [-0.43123116 -0.02032161]
 [-0.22979224 -0.78761635]
 [-0.05764466 -0.26115528]]
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># numpy.abs calculates absolute value (element-wise)</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>[[0.20963543 0.63428181]
 [0.23256009 0.91560316]
 [0.43123116 0.02032161]
 [0.22979224 0.78761635]
 [0.05764466 0.26115528]]
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># sum all elements</span>
<span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>3.7798417848539096
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># sum elements over a given axis</span>
<span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>array([1.16086358, 2.61897821])
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>array([0.84391724, 1.14816326, 0.45155276, 1.01740859, 0.31879994])
</pre></div>


<h3 id="analysis">Analysis<a class="headerlink" href="#analysis" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Before we start using <code>NearestNeighbor</code> let's create a simple mini-framework to apply NN and visualize results easily</p>
</li>
<li>
<p>We want to initilize <code>NearestNeighbor</code> with some feature vectors (and automatically assign labels for each class)</p>
</li>
<li>
<p>We want our test samples to be a grid of uniformly distributed points</p>
</li>
<li>
<p>We want methods to process test data and to make a plots with final results</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Analysis</span><span class="p">():</span>
  <span class="sd">&quot;&quot;&quot;Apply NearestNeighbor to generated (uniformly) test samples.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">distance</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate labels and initilize classifier</span>

<span class="sd">    x -- feature vectors arrays</span>
<span class="sd">    distance -- 0 for L1, 1 for L2    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># get number of classes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nof_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># create lables array</span>
    <span class="c1"># np.ones creates an array of given shape filled with 1 of given type</span>
    <span class="c1"># we apply consecutive integer numbers as class labels</span>
    <span class="c1"># ravel return flatten array</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="c1"># save training samples to plot them later</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">x</span>

    <span class="c1"># merge feature vector arrays for NearestNeighbor</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># train classifier</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn</span> <span class="o">=</span> <span class="n">NearestNeighbor</span><span class="p">(</span><span class="n">distance</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>


  <span class="k">def</span> <span class="nf">prepare_test_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate a grid with test points (from low to high with step)&quot;&quot;&quot;</span>
    <span class="c1"># remember range</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">range</span> <span class="o">=</span> <span class="p">[</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="p">]</span>

    <span class="c1"># start with grid of points from [low, high] x [low, high]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="n">low</span><span class="p">:</span><span class="n">high</span><span class="o">+</span><span class="n">step</span><span class="p">:</span><span class="n">step</span><span class="p">,</span> <span class="n">low</span><span class="p">:</span><span class="n">high</span><span class="o">+</span><span class="n">step</span><span class="p">:</span><span class="n">step</span><span class="p">]</span>

    <span class="c1"># convert to an array of 2D points</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>


  <span class="k">def</span> <span class="nf">analyse</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Run classifier on test samples and split them according to labels.&quot;&quot;&quot;</span>

    <span class="c1"># find labels for test samples </span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x_test</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">classified</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># [class I test points, class II test ...]</span>

    <span class="c1"># loop over available labels</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nof_classes</span><span class="p">):</span>
      <span class="c1"># if i-th label == current label -&gt; add test[i]</span>
      <span class="n">class_i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">x_test</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> \
                          <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_test</span><span class="p">)</span> \
                          <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="n">label</span><span class="p">])</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">classified</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">class_i</span><span class="p">)</span>


  <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Visualize the result of classification&quot;&quot;&quot;</span>
    <span class="n">plot</span> <span class="o">=</span> <span class="n">init_plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">range</span><span class="p">)</span>
    <span class="n">plot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">plot</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

    <span class="c1"># plot training samples</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x_train</span><span class="p">):</span>
      <span class="n">plot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">mpl_colors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>

    <span class="c1"># plot test samples</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classified</span><span class="p">):</span>
      <span class="n">plot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">mpl_colors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;,&#39;</span><span class="p">)</span>
</pre></div>


<h3 id="l1-test">L1 test<a class="headerlink" href="#l1-test" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><span class="n">l1</span> <span class="o">=</span> <span class="n">Analysis</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">l1</span><span class="o">.</span><span class="n">prepare_test_samples</span><span class="p">()</span>
<span class="n">l1</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
<span class="n">l1</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="../output_24_0.png" /></p>
<h3 id="l2-test">L2 Test<a class="headerlink" href="#l2-test" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><span class="n">l2</span> <span class="o">=</span> <span class="n">Analysis</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">l2</span><span class="o">.</span><span class="n">prepare_test_samples</span><span class="p">()</span>
<span class="n">l2</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
<span class="n">l2</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="../output_26_0.png" /></p>
<h3 id="multiclass-classification">Multiclass classification<a class="headerlink" href="#multiclass-classification" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Training samples from 4 squares:</p>
<ul>
<li>[0, 1] x [0, 1]</li>
<li>[0, 1] x [1, 2]</li>
<li>[1, 2] x [0, 1]</li>
<li>[1, 2] x [1, 2]</li>
</ul>
</li>
<li>
<p>We expect 4 squares created by test samples grid</p>
</li>
<li>
<p>How does it depend on the size of training samples?</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">generate4</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Generate 4 sets of random points.&quot;&quot;&quot;</span>

  <span class="c1"># points from [0, 1] x [0, 1]</span>
  <span class="n">X1</span> <span class="o">=</span> <span class="n">generate_random_points</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="c1"># points from [1, 2] x [1, 2]</span>
  <span class="n">X2</span> <span class="o">=</span> <span class="n">generate_random_points</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="c1"># points from [0, 1] x [1, 2]</span>
  <span class="n">X3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="n">generate_random_points</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
  <span class="c1"># points from [1, 2] x [0, 1]</span>
  <span class="n">X4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="ow">in</span> <span class="n">generate_random_points</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)])</span>

  <span class="k">return</span> <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">X3</span><span class="p">,</span> <span class="n">X4</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># loop over no. of training samples</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">):</span>
  <span class="c1"># generate 4 sets of random points (each one with n samples)</span>
  <span class="c1"># unpack them when passing to Analysis</span>
  <span class="n">c4</span> <span class="o">=</span> <span class="n">Analysis</span><span class="p">(</span><span class="o">*</span><span class="n">generate4</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">c4</span><span class="o">.</span><span class="n">prepare_test_samples</span><span class="p">()</span>
  <span class="n">c4</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
  <span class="n">c4</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s2">&quot;No. of samples = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
</pre></div>


<p><img alt="png" src="../output_30_0.png" /></p>
<p><img alt="png" src="../output_30_1.png" /></p>
<p><img alt="png" src="../output_30_2.png" /></p>
<p><img alt="png" src="../output_30_3.png" /></p>
<p><font color=red size=5>Message 01: size matters!</font></p>
<h3 id="noise">Noise<a class="headerlink" href="#noise" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Data are rarely perfect and you may expect some training samples to have unsual features</p>
</li>
<li>
<p>Features shared by a majority of training samples are more important than a single occurrence</p>
</li>
<li>
<p>Let's add some noise to our data and see how Nearest Neighbor deal with it</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># generate 4 classes of 2D points</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">X3</span><span class="p">,</span> <span class="n">X4</span> <span class="o">=</span> <span class="n">generate4</span><span class="p">()</span>

<span class="c1"># add some noise by applying gaussian to every point coordinates</span>
<span class="n">noise</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)]</span>

<span class="n">X1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">X1</span><span class="p">])</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">X2</span><span class="p">])</span>
<span class="n">X3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">X3</span><span class="p">])</span>
<span class="n">X4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">noise</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">X4</span><span class="p">])</span>

<span class="c1"># perform analysis</span>
<span class="n">c4</span> <span class="o">=</span> <span class="n">Analysis</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">X3</span><span class="p">,</span> <span class="n">X4</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">c4</span><span class="o">.</span><span class="n">prepare_test_samples</span><span class="p">()</span>
<span class="n">c4</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
<span class="n">c4</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="../output_34_0.png" /></p>
<h3 id="overfitting">Overfitting<a class="headerlink" href="#overfitting" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>The above is an example of overfitting</p>
<ul>
<li>perfectly describe training data</li>
<li>lose the generalization ability</li>
</ul>
</li>
<li>
<p>In general you want to extract all common features from training samples, but neglect characteristic features of single sample</p>
</li>
</ul>
<p><font color=red size=5>Message 02: avoid overfitting!</font></p>
<h3 id="accuracy">Accuracy<a class="headerlink" href="#accuracy" title="Permanent link">&para;</a></h3>
<ul>
<li>Accuracy defines the fraction of (unseen) samples which are correctly classify by the algorithm </li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># loop over (sample, reconstructed label)</span>
<span class="k">for</span> <span class="n">sample</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">c4</span><span class="o">.</span><span class="n">x_test</span><span class="p">,</span> <span class="n">c4</span><span class="o">.</span><span class="n">y_test</span><span class="p">):</span>
  <span class="c1"># determine true label</span>
  <span class="k">if</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">sample</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">true_label</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">elif</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">sample</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">true_label</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="k">elif</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">sample</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">true_label</span> <span class="o">=</span> <span class="mi">2</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">true_label</span> <span class="o">=</span> <span class="mi">3</span>

  <span class="k">if</span> <span class="n">true_label</span> <span class="o">==</span> <span class="n">label</span><span class="p">:</span> <span class="n">accuracy</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">accuracy</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">c4</span><span class="o">.</span><span class="n">x_test</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.924878097076805
</pre></div>


<ul>
<li>
<p>Please note, that this is a toy model - in the case of real problems there is no way to determine true labels (otherwise there is no point to use ML methods...)</p>
</li>
<li>
<p>To measure accuracy of the model one usually splits data into:</p>
<ul>
<li>
<p>training samples (usually about 80%)</p>
</li>
<li>
<p>test samples (usually about 20%)</p>
</li>
</ul>
</li>
<li>
<p>After the model is trained on training samples, the accuracy is measured on test samples</p>
</li>
</ul>
<p><font color=red size=5>Message 03: keep some data for testing!</font></p>
<h2 id="k-nearest-neighbors_1">k-Nearest Neighbors<a class="headerlink" href="#k-nearest-neighbors_1" title="Permanent link">&para;</a></h2>
<ul>
<li>Instead of letting one closest neighbor to decide, let <em>k</em> nearest neghbors to vote</li>
</ul>
<h3 id="implementation_1">Implementation<a class="headerlink" href="#implementation_1" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>We can base the implementation on <code>NearestNeighbor</code>, but</p>
</li>
<li>
<p>The <em>constructor</em> has an extra parameter <em>k</em></p>
</li>
<li>
<p>and we need to override <code>predict</code> method</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">kNearestNeighbors</span><span class="p">(</span><span class="n">NearestNeighbor</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;k-Nearest Neighbor Classifier&quot;&quot;&quot;</span>


  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set distance definition: 0 - L1, 1 - L2&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">distance</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>


  <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predict and return labels for each feature vector from x</span>

<span class="sd">    x -- feature vectors (N x D)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># placeholder for N labels</span>

    <span class="c1"># no. of classes = max label (labels starts from 0)</span>
    <span class="n">nof_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="c1"># loop over all test samples</span>
    <span class="k">for</span> <span class="n">x_test</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
      <span class="c1"># array of distances between current test and all training samples</span>
      <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x_train</span> <span class="o">-</span> <span class="n">x_test</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

      <span class="c1"># placeholder for labels votes</span>
      <span class="n">votes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nof_classes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>

      <span class="c1"># find k closet neighbors and vote</span>
      <span class="c1"># argsort returns the indices that would sort an array</span>
      <span class="c1"># so indices of nearest neighbors</span>
      <span class="c1"># we take self.k first</span>
      <span class="k">for</span> <span class="n">neighbor_id</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">distances</span><span class="p">)[:</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">]:</span>
        <span class="c1"># this is a label corresponding to one of the closest neighbor</span>
        <span class="n">neighbor_label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train</span><span class="p">[</span><span class="n">neighbor_id</span><span class="p">]</span>
        <span class="c1"># which updates votes array</span>
        <span class="n">votes</span><span class="p">[</span><span class="n">neighbor_label</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

      <span class="c1"># predicted label is the one with most votes</span>
      <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">votes</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">predictions</span>
</pre></div>


<h3 id="kanalysis">kAnalysis<a class="headerlink" href="#kanalysis" title="Permanent link">&para;</a></h3>
<ul>
<li>We also create <code>kAnalysis</code> based on <code>Analysis</code> for visualization of kNN results</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">kAnalysis</span><span class="p">(</span><span class="n">Analysis</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Apply kNearestNeighbor to generated (uniformly) test samples.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate labels and initilize classifier</span>

<span class="sd">    x -- feature vectors arrays</span>
<span class="sd">    k -- number of nearest neighbors</span>
<span class="sd">    distance -- 0 for L1, 1 for L2    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># get number of classes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nof_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># create lables array</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="c1"># save training samples to plot them later</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">x</span>

    <span class="c1"># merge feature vector arrays for NearestNeighbor</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># train classifier (knn this time)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn</span> <span class="o">=</span> <span class="n">kNearestNeighbors</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">distance</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>


<h3 id="sanity-check">Sanity check<a class="headerlink" href="#sanity-check" title="Permanent link">&para;</a></h3>
<ul>
<li>k-Nearest Neighbor classifier with <em>k = 1</em> must give exactly the same results as Nearest Neighbor</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># apply kNN with k=1 on the same set of training samples</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">kAnalysis</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">X3</span><span class="p">,</span> <span class="n">X4</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">prepare_test_samples</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
<span class="n">knn</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="../output_51_0.png" /></p>
<h3 id="k-test">k-Test<a class="headerlink" href="#k-test" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>For <em>k = 1</em> kNN is likely to overfit the problem</p>
</li>
<li>
<p>Although, it does not mean that higher <em>k</em> is better!</p>
</li>
<li>
<p>Now, let's see how different values of <em>k</em> affects the result</p>
</li>
<li>
<p>Later, we will learn how to find optimal value of <em>k</em> for given problem</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># training size = 50</span>
<span class="c1"># let&#39;s check a few values between 1 and 50</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">):</span>
  <span class="n">knn</span> <span class="o">=</span> <span class="n">kAnalysis</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">X3</span><span class="p">,</span> <span class="n">X4</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">knn</span><span class="o">.</span><span class="n">prepare_test_samples</span><span class="p">()</span>
  <span class="n">knn</span><span class="o">.</span><span class="n">analyse</span><span class="p">()</span>
  <span class="n">knn</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="s2">&quot;k = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
</pre></div>


<p><img alt="png" src="../output_54_0.png" /></p>
<p><img alt="png" src="../output_54_1.png" /></p>
<p><img alt="png" src="../output_54_2.png" /></p>
<p><img alt="png" src="../output_54_3.png" /></p>
<h2 id="hyperparameters">Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>ML model may have some hyperparameters - parameters set before training</p>
</li>
<li>
<p>Please note, ML algorithm may have also parameters which are set during training</p>
</li>
<li>
<p>In the case of kNN there are two hyperparameters:</p>
<ul>
<li>
<p>number of nearest neihgbors (<em>k</em>)</p>
</li>
<li>
<p>the definition of distance</p>
</li>
</ul>
</li>
<li>
<p>The choice of hyperparameters values highly depends on a problem</p>
</li>
<li>
<p>The wrong choice of hyperparameters may lead to underfitting or overfitting</p>
</li>
</ul>
<h3 id="over-under-fitting-example">Over-, under-fitting example<a class="headerlink" href="#over-under-fitting-example" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><span class="c1"># generate random data from x^2 function (with some noise)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)]</span> \
                 <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">init_plot</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_58_0.png" /></p>
<ul>
<li>
<p>Let's try to fit this data to a polynomial</p>
</li>
<li>
<p>The degree is a hyperparamter (which defines number of coefficients)</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># loop over degrees of polynomial</span>
<span class="c1"># data is x^2, so let&#39;s try degrees 1, 2, 10</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
  <span class="c1"># polyfit returns an array with polynomial coefficients</span>
  <span class="c1"># poly1d is a polynomial class</span>
  <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

  <span class="c1"># returns an array with 100 uniformly distributed numbers from -1 to 1</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

  <span class="n">plot</span> <span class="o">=</span> <span class="n">init_plot</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
  <span class="n">plot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;n = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
  <span class="n">plot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RankWarning: Polyfit may be poorly conditioned
  after removing the cwd from sys.path.
</pre></div>


<p><img alt="png" src="../output_60_1.png" /></p>
<p><img alt="png" src="../output_60_2.png" /></p>
<p><img alt="png" src="../output_60_3.png" /></p>
<ul>
<li>
<p>For <em>n = 1</em> we clearly underfit the data as we do not have enough parameters to describe the complexity of the problem</p>
</li>
<li>
<p>For <em>n = 2</em> we have appropriate capacity (as we actually generated data form <span><span class="MathJax_Preview">x^2</span><script type="math/tex">x^2</script></span> function)</p>
</li>
<li>
<p>For <em>n = 10</em> we overfit the data - training samples are described perfectly, but we clearly lost the generalization ability</p>
</li>
</ul>
<p><font color=red size=5>Message 04: right choice of hyperparameters is crucial!</font></p>
<h3 id="validation-dataset">Validation dataset<a class="headerlink" href="#validation-dataset" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>One splits data into training and test samples</p>
<ul>
<li>
<p>training samples are used to optimize model parameters</p>
</li>
<li>
<p>test samples are used to measure accuracy</p>
</li>
<li>
<p>there is no rule of thumb on how to split dataset</p>
</li>
</ul>
</li>
<li>
<p>If a model has some hyperparameters the part of training set is used for valitation samples:</p>
<ul>
<li>
<p>training samples - tuning model parameters</p>
</li>
<li>
<p>validation samples - tuning hyperparameters</p>
</li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span>                  +---------------------+      +------------------------+
+----------+      |                     |      |                        |
|          |      | Measure accuracy on |      | Measure final accuracy |
| Training | +--&gt; |                     | +--&gt; |                        |
|          |      | validation samples  |      | on test samples        |
+----------+      |                     |      |                        |
     ^            +----------+----------+      +------------------------+
     |                       |
     |      Change           | 
     +-----------------------+
         hyperparameters
</pre></div>


<h2 id="iris-dataset">Iris dataset<a class="headerlink" href="#iris-dataset" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. <a href="https://archive.ics.uci.edu/ml/datasets/iris">src</a></p>
</li>
<li>
<p>Attribute Information:</p>
<ul>
<li>
<p>sepal length in cm</p>
</li>
<li>
<p>sepal width in cm</p>
</li>
<li>
<p>petal length in cm</p>
</li>
<li>
<p>petal width in cm</p>
</li>
<li>
<p>class: </p>
<ul>
<li>
<p>Iris Setosa</p>
</li>
<li>
<p>Iris Versicolour</p>
</li>
<li>
<p>Iris Virginica</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="load-dataset">Load dataset<a class="headerlink" href="#load-dataset" title="Permanent link">&para;</a></h3>
<ul>
<li>We use <code>pandas</code> for data manipulation - it is super handy and supports many formats</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="c1"># columns names - can be used to access columns later</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Sepal Length&quot;</span><span class="p">,</span> <span class="s2">&quot;Sepal Width&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Petal Length&quot;</span><span class="p">,</span> <span class="s2">&quot;Petal Width&quot;</span><span class="p">,</span>
           <span class="s2">&quot;Class&quot;</span><span class="p">]</span>

<span class="c1"># iris.data is a csv file</span>
<span class="n">src</span> <span class="o">=</span> <span class="s2">&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&quot;</span>

<span class="c1"># load the file with pandas.read_csv </span>
<span class="c1"># it will name columns as defined in columns list</span>
<span class="c1"># so one can access a column through index or name</span>
<span class="n">iris_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">iris_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>  <span class="c1"># print a few first entries</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sepal Length</th>
      <th>Sepal Width</th>
      <th>Petal Length</th>
      <th>Petal Width</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="visualize-dataset">Visualize dataset<a class="headerlink" href="#visualize-dataset" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><code>pandas</code> offers plotting through <code>matplotlib</code> integration</p>
</li>
<li>
<p>Let's visualize Iris data</p>
</li>
<li>
<p>Let's keep the code short - sorry if it is hard to follow</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># to extract rows with class column == class_name</span>
<span class="n">extract</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">class_name</span><span class="p">:</span> <span class="n">iris_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">iris_data</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">class_name</span><span class="p">]</span>

<span class="c1"># axes settings - part = Sepal or Petal; x = Length, y = Width</span>
<span class="n">set_ax</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">part</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">part</span> <span class="o">+</span> <span class="s2">&quot; Length&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">part</span> <span class="o">+</span> <span class="s2">&quot; Width&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;kind&quot;</span><span class="p">:</span> <span class="s2">&quot;scatter&quot;</span><span class="p">}</span>

<span class="c1"># add iris type / sepal or petal / color to existing axis</span>
<span class="n">plot</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">class_name</span><span class="p">,</span> <span class="n">part</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> \
  <span class="n">extract</span><span class="p">(</span><span class="n">class_name</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">set_ax</span><span class="p">(</span><span class="n">part</span><span class="p">),</span>
                           <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                           <span class="n">label</span><span class="o">=</span><span class="n">class_name</span><span class="p">,</span>
                           <span class="n">ax</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>

<span class="c1"># plot all Iris types (sepal or petal) on existing axis</span>
<span class="n">plot_all</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">part</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> \
  <span class="p">[</span><span class="n">plot</span><span class="p">(</span><span class="n">iris</span><span class="p">,</span> <span class="n">part</span><span class="p">,</span> <span class="n">mpl_colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">axis</span><span class="p">)</span> \
   <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">iris</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">iris_data</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]))]</span> 
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># with pyplot.subplots we can create many plots on one figure</span>
<span class="c1"># here we create 2 plots - 1 row and 2 columns</span>
<span class="c1"># thus, subplots returns figure, axes of 1st plot, axes for 2nd plot</span>
<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="c1"># using messy lambda we can plot all Iris types at once</span>
<span class="c1"># Petal data on 1st plots and Sepal data on 2nd plot</span>
<span class="n">plot_all</span><span class="p">(</span><span class="s2">&quot;Petal&quot;</span><span class="p">,</span> <span class="n">ax1</span><span class="p">)</span>
<span class="n">plot_all</span><span class="p">(</span><span class="s2">&quot;Sepal&quot;</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span>

<span class="c1"># tight_layout adjust subplots params so they fit into figure ares</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="../output_73_0.png" /></p>
<h3 id="prepare-feature-vectors-and-labels">Prepare feature vectors and labels<a class="headerlink" href="#prepare-feature-vectors-and-labels" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>First step is to prepare data - we need feature vectors with corresponding labels</p>
</li>
<li>
<p>In this case every sample's feature vector is 4D (sepal length, sepal width, petal length, petal width) and is labeled with one of three classes (Iris Setosa, Iris Versicolour, Iris Virginica)</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># every Iris has 4 features (forming our 4D feature vectors)</span>
<span class="c1"># pandaoc.DataFrame.iloc allows us access data through indices</span>
<span class="c1"># we create an array with feature vectors by taking all rows for first 4 columns</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">4</span><span class="p">]</span>

<span class="c1"># it is still pandoc.DataFrame object - pretty handy</span>
<span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sepal Length</th>
      <th>Sepal Width</th>
      <th>Petal Length</th>
      <th>Petal Width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
  </tbody>
</table>
</div>

<ul>
<li><code>pandas.DataFrame</code> object are handy to manipulate data, but at the end of the day we want to perform algebra with <code>numpy</code></li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># create numpy array (matrix) for further processing</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># print a few first entries</span>
<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>


<div class="codehilite"><pre><span></span>[[5.1 3.5 1.4 0.2]
 [4.9 3.  1.4 0.2]
 [4.7 3.2 1.3 0.2]
 [4.6 3.1 1.5 0.2]
 [5.  3.6 1.4 0.2]]
</pre></div>


<ul>
<li>from the las column ("Class") we create our labels</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># as mentioned before, we can access DataFrame object through column labels</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">iris_data</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">])</span>

<span class="c1"># print a few first entries</span>
<span class="k">print</span><span class="p">(</span><span class="n">Y</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>


<div class="codehilite"><pre><span></span>[&#39;Iris-setosa&#39; &#39;Iris-setosa&#39; &#39;Iris-setosa&#39; &#39;Iris-setosa&#39; &#39;Iris-setosa&#39;]
</pre></div>


<h3 id="prepare-test-dataset">Prepare test dataset<a class="headerlink" href="#prepare-test-dataset" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Let's use 80% for training and 20% for testing</p>
</li>
<li>
<p>We, obviously, can not just take last 20% of samples for testing because our data is ordered</p>
</li>
<li>
<p>But we can randomly select 20% of samples</p>
</li>
<li>
<p>Easy to do by hand, but let's start to use some ML frameworks</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> <span class="k">as</span> <span class="n">split</span>

<span class="c1"># train_test_split: Split arrays or matrices into random train and test subsets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># let&#39;s use 20% of training samples for validation</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_valid</span> <span class="o">=</span> <span class="n">split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># check how many sample we have</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>


<div class="codehilite"><pre><span></span>96 24 30
</pre></div>


<h3 id="knn-from-scikit-learn">kNN from scikit-learn<a class="headerlink" href="#knn-from-scikit-learn" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><code>scikit-learn</code> has already implemented k-Nearest Neighbor algorithm (which is more flexible than the one implemented during this lecture)</p>
</li>
<li>
<p>Let's see how <em>complicated</em> is using one of ML frameworks with Python</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="c1"># create knn classifier with k = 48</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">48</span><span class="p">)</span>

<span class="c1"># train the model</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># predict labels for test samples</span>
<span class="n">Y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
</pre></div>


<h3 id="accuracy_1">Accuracy<a class="headerlink" href="#accuracy_1" title="Permanent link">&para;</a></h3>
<ul>
<li>First let's print true labels along with predicted ones</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># use bold if true != predicted</span>
<span class="k">for</span> <span class="n">true</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">Y_valid</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="n">true</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;{}</span><span class="se">\t</span><span class="s2"> -&gt; {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\033</span><span class="s2">[1m{}</span><span class="se">\t</span><span class="s2"> -&gt; {}</span><span class="se">\033</span><span class="s2">[0m&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Iris-setosa  -&gt; Iris-setosa
Iris-versicolor  -&gt; Iris-versicolor
Iris-setosa  -&gt; Iris-setosa
Iris-versicolor  -&gt; Iris-versicolor
Iris-virginica   -&gt; Iris-virginica
Iris-virginica   -&gt; Iris-virginica
[1mIris-versicolor  -&gt; Iris-virginica[0m
Iris-virginica   -&gt; Iris-virginica
Iris-versicolor  -&gt; Iris-versicolor
Iris-setosa  -&gt; Iris-setosa
Iris-virginica   -&gt; Iris-virginica
Iris-versicolor  -&gt; Iris-versicolor
Iris-virginica   -&gt; Iris-virginica
[1mIris-virginica   -&gt; Iris-versicolor[0m
Iris-virginica   -&gt; Iris-virginica
Iris-virginica   -&gt; Iris-virginica
Iris-versicolor  -&gt; Iris-versicolor
Iris-setosa  -&gt; Iris-setosa
Iris-setosa  -&gt; Iris-setosa
Iris-virginica   -&gt; Iris-virginica
[1mIris-virginica   -&gt; Iris-versicolor[0m
Iris-setosa  -&gt; Iris-setosa
Iris-versicolor  -&gt; Iris-versicolor
[1mIris-virginica   -&gt; Iris-versicolor[0m
</pre></div>


<ul>
<li>We can easily calculate accuracy by hand as it is just a number of correctly predicted labels divided by no. of samples</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># Y_valid == Y_pred -&gt; array of True/False (if two elements are equal or not)</span>
<span class="c1"># (Y_valid == Y_pred).sum() -&gt; number of Trues</span>
<span class="c1"># Y_valid.shape[0] -&gt; number of validation samples</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y_valid</span> <span class="o">==</span> <span class="n">Y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">Y_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.8333333333333334
</pre></div>


<ul>
<li>But we can also use <code>scikit-learn</code> function <code>accuracy_score</code></li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="k">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_valid</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.8333333333333334
</pre></div>


<h3 id="k-dependence-of-the-accuracy">k-dependence of the accuracy<a class="headerlink" href="#k-dependence-of-the-accuracy" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Let's use validation set to determine the best hyperparameter <em>k</em></p>
</li>
<li>
<p>We will run kNN for various values of <em>k</em> and measure accuracy</p>
</li>
<li>
<p>This will allow us to find the optimal value of <em>k</em></p>
</li>
<li>
<p>And check the accuracy on the test dataset</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># placeholder for accuracy</span>

<span class="n">max_k</span> <span class="o">=</span> <span class="mi">85</span>  <span class="c1"># maximum number of voters</span>

<span class="c1"># loop over different values of k</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_k</span><span class="p">):</span>
  <span class="c1"># create knn classifier with k = k</span>
  <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>

  <span class="c1"># train the model</span>
  <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

  <span class="c1"># predict labels for test samples</span>
  <span class="n">Y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>

  <span class="c1"># add accuracy to score table</span>
  <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_valid</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">))</span>
</pre></div>


<ul>
<li>Now, we can plot accuracy as a function of <em>k</em></li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">k_accuracy_plot</span><span class="p">(</span><span class="n">max_k</span><span class="o">=</span><span class="mi">85</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Just plot settings&quot;&quot;&quot;</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_k</span> <span class="o">+</span> <span class="mi">5</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_k</span> <span class="o">+</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">plt</span>

<span class="n">k_accuracy_plot</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_k</span><span class="p">),</span> <span class="n">scores</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_98_0.png" /></p>
<ul>
<li>And check the accuracy measured on the test samples</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">Y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.9666666666666667
</pre></div>


<ul>
<li>
<p>The accuracy plot is not smooth</p>
</li>
<li>
<p>It is common if one does not have enough validation samples</p>
</li>
<li>
<p>But there is another way to measure accuracy dependence on hyperparameters</p>
</li>
</ul>
<h3 id="cross-validation">Cross-validation<a class="headerlink" href="#cross-validation" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span>         Split training samples into N folds

 +-------+   +-------+   +-------+         +-------+
 |       |   |       |   |       |         |       |
 |   1   |   |   2   |   |   3   |   ...   |   N   |
 |       |   |       |   |       |         |       |
 +-------+   +-------+   +-------+         +-------+

Take one fold as validation set and train on N-1 folds

 +-------+   +-------+   +-------+         +-------+
 |*******|   |       |   |       |         |       |
 |*******|   |   2   |   |   3   |   ...   |   N   |
 |*******|   |       |   |       |         |       |
 +-------+   +-------+   +-------+         +-------+

         Take the next one as validation set

 +-------+   +-------+   +-------+         +-------+
 |       |   |*******|   |       |         |       |
 |   1   |   |*******|   |   3   |   ...   |   N   |
 |       |   |*******|   |       |         |       |
 +-------+   +-------+   +-------+         +-------+

          Repeat the procedure for all folds

 +-------+   +-------+   +-------+         +-------+
 |       |   |       |   |       |         |*******|
 |   1   |   |   2   |   |   3   |   ...   |*******|
 |       |   |       |   |       |         |*******|
 +-------+   +-------+   +-------+         +-------+

            And average out the accuracy
</pre></div>


<ul>
<li>Once again <code>scikit-learn</code> has already implemented the procedure we need</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="c1"># this time we do not create dedicated validation set</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">avg_scores</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># average score for different k</span>

<span class="n">nof_folds</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># loop over different values of k</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_k</span><span class="p">):</span>
  <span class="c1"># create knn classifier with k = k</span>
  <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>

  <span class="c1"># cross-validate knn on our training sample with nof_folds</span>
  <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span>
                           <span class="n">cv</span><span class="o">=</span><span class="n">nof_folds</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>

  <span class="c1"># add avg accuracy to score table</span>
  <span class="n">avg_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">k_accuracy_plot</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_k</span><span class="p">),</span> <span class="n">avg_scores</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_106_0.png" /></p>
<ul>
<li>
<p>In theory, k-fold cross-validation is the way to go (especially if a dataset is small)</p>
</li>
<li>
<p>In practice, people tend to use a single validation split as it is not that computational expensive</p>
</li>
</ul>
<h3 id="data-normalization">Data normalization<a class="headerlink" href="#data-normalization" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Sometimes there is a need to preprocess data before training</p>
</li>
<li>
<p>Let's imagine Iris sepal data is in cm but petal data in mm</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># original data - both in cm</span>
<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>


<div class="codehilite"><pre><span></span>[[5.1 3.5 1.4 0.2]
 [4.9 3.  1.4 0.2]
 [4.7 3.2 1.3 0.2]
 [4.6 3.1 1.5 0.2]
 [5.  3.6 1.4 0.2]]
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># make a copy of X</span>
<span class="n">Xmm</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># and multiply last two columns by 0.1</span>
<span class="n">Xmm</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span> <span class="o">*=</span> <span class="mf">0.1</span>

<span class="c1"># and we have our fake Iris data with petal length/width in mm</span>
<span class="k">print</span><span class="p">(</span><span class="n">Xmm</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>


<div class="codehilite"><pre><span></span>[[5.1  3.5  0.14 0.02]
 [4.9  3.   0.14 0.02]
 [4.7  3.2  0.13 0.02]
 [4.6  3.1  0.15 0.02]
 [5.   3.6  0.14 0.02]]
</pre></div>


<ul>
<li>Let's compare result of the same classifier on both dataset</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Make training and test datasets and process through kNN&quot;&quot;&quot;</span>

  <span class="c1"># prepare training / test samples</span>
  <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

  <span class="c1"># create a kNN with k = k</span>
  <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>

  <span class="c1"># get prediction for original dataset</span>
  <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
  <span class="n">Y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">Y_pred</span><span class="p">)</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">mm</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">Xmm</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:</span><span class="se">\n\t</span><span class="s2">both in cm: {}</span><span class="se">\n\t</span><span class="s2">petal in mm: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">mm</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Accuracy:
    both in cm: 1.0
    petal in mm: 0.7
</pre></div>


<ul>
<li>
<p>It is kind of obvious here - petal information will barely contribute to the distance</p>
</li>
<li>
<p>However, it is not always obvious if some features are not suppressed by the way data is normalized</p>
</li>
</ul>
<p><font color=red size=5>Message 05: be aware of data normalization!</font></p>
<h2 id="mnist">MNIST<a class="headerlink" href="#mnist" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p><a href="http://yann.lecun.com/exdb/mnist/">THE MNIST DATABASE of handwritten digits</a></p>
</li>
<li>
<p><em>The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.</em></p>
</li>
<li>
<p><em>It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.</em></p>
</li>
</ul>
<hr />
<ul>
<li>
<p>To make it simpler (and faster) let's use digits toy dataset which comes with <code>scikit-learn</code> <a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html">src</a></p>
</li>
<li>
<p>Each datapoint is a 8x8 image of a digit.</p>
</li>
<li>
<p>About 180 samples per class (digit)</p>
</li>
<li>
<p>Total number of samples 1797</p>
</li>
</ul>
<h3 id="load-digits">Load digits<a class="headerlink" href="#load-digits" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>

<span class="n">digits</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(1797, 64)
</pre></div>


<ul>
<li>
<p><code>digits.images</code> is a <code>numpy</code> array with 1797 <code>numpy</code> arrays 8x8 (feature vectors) representing digits</p>
</li>
<li>
<p><code>digits.target</code> is a <code>numpy</code> array with 1797 integer numbers (class labels)</p>
</li>
<li>
<p>the code below allow us to visualize a random digits from the dataset</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># set grayscale</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gray</span><span class="p">()</span>

<span class="c1"># get some random index from 0 to dataset size</span>
<span class="n">random_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1796</span><span class="p">)</span>


<span class="c1"># draw random digit</span>
<span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">random_index</span><span class="p">])</span>

<span class="c1"># and print the matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">random_index</span><span class="p">],</span>
         <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;monospace&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">})</span>

<span class="c1"># and the label</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;This is: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">random_index</span><span class="p">]),</span>
         <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;monospace&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">});</span>
</pre></div>


<div class="codehilite"><pre><span></span>&lt;matplotlib.figure.Figure at 0x7faccc90a048&gt;
</pre></div>


<p><img alt="png" src="../output_120_1.png" /></p>
<h3 id="distance-between-images">Distance between images<a class="headerlink" href="#distance-between-images" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span>  TEST      TRAIN    PIXEL-WISE
| 4 2 0     2 5 8 |   |2 3 8|
| 5 3 9  -  2 8 1 | = |3 5 8|  -&gt;  38
| 0 2 3     1 4 9 |   |1 2 6|
</pre></div>


<h3 id="prepare-data">Prepare data<a class="headerlink" href="#prepare-data" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>We need to split dataset to training and test samples</p>
</li>
<li>
<p>However, images are in 8x8 format and we have to flatten them first</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># the original shape of an image</span>
<span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(1797, 8, 8)
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># numpy.reshape is handy here</span>
<span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1797</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(1797, 64)
</pre></div>


<ul>
<li>
<p>Please note -1 in new shape</p>
</li>
<li>
<p><code>numpy.reshape</code> allows us to pass one <em>unknown</em> dimension which can be determined automatically</p>
</li>
<li>
<p>Thus, the above is equivalent to</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1797</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(1797, 64)
</pre></div>


<div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(1797, 64)
</pre></div>


<ul>
<li>As before, we can split our dataset using <code>sklearn.model_selection.train_test_split</code></li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">label_train</span><span class="p">,</span> <span class="n">label_test</span> <span class="o">=</span> \
  <span class="n">split</span><span class="p">(</span><span class="n">digits</span><span class="o">.</span><span class="n">images</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1797</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>


<h3 id="cross-validation_1">Cross-validation<a class="headerlink" href="#cross-validation_1" title="Permanent link">&para;</a></h3>
<ul>
<li>We perform cross-validation on training samples to determine the best <em>k</em> (as for the Iris dataset)</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">avg_scores</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># average score for different k</span>

<span class="n">max_k</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">nof_folds</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># loop over different values of k</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_k</span><span class="p">):</span>
  <span class="c1"># create knn classifier with k = k</span>
  <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>

  <span class="c1"># cross-validate knn on our training sample with nof_folds</span>
  <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">data_train</span><span class="p">,</span> <span class="n">label_train</span><span class="p">,</span>
                           <span class="n">cv</span><span class="o">=</span><span class="n">nof_folds</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>

  <span class="c1"># add avg accuracy to score table</span>
  <span class="n">avg_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_k</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_k</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_k</span><span class="p">),</span> <span class="n">avg_scores</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_135_0.png" /></p>
<ul>
<li>
<p>We used nearly the same procedure as for the Iris dataset</p>
</li>
<li>
<p>Note, that digits toy dataset prefer different <em>k</em></p>
</li>
<li>
<p>This is the idea of ML - the same algorithm can solve different problems if train on different data</p>
</li>
<li>
<p>Nowadays, in ML field <strong>data is more important than algorithms</strong> (we have good algorithms already) </p>
</li>
</ul>
<h3 id="final-test">Final test<a class="headerlink" href="#final-test" title="Permanent link">&para;</a></h3>
<ul>
<li>Let's take the bes <em>k</em> and check how the classifier works on test samples</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">label_train</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">label_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.9888888888888889
</pre></div>


<ul>
<li>We can take a look at misclassified digits</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">label_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)):</span>
  <span class="k">if</span> <span class="n">true</span> <span class="o">!=</span> <span class="n">predict</span><span class="p">:</span>
    <span class="n">digit</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>  <span class="c1"># reshape again to 8x8</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">digit</span><span class="p">)</span>                    <span class="c1"># for matshow</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;{} predicted as {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">predict</span><span class="p">))</span>
</pre></div>


<p><img alt="png" src="../output_141_0.png" /></p>
<p><img alt="png" src="../output_141_1.png" /></p>
<p><img alt="png" src="../output_141_2.png" /></p>
<p><img alt="png" src="../output_141_3.png" /></p>
<h2 id="regression-with-knn">Regression with kNN<a class="headerlink" href="#regression-with-knn" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>It is also possible to do regression using k-Nearest Neighbors</p>
<ul>
<li>
<p>find <em>k</em> nearest neighbors from training samples</p>
</li>
<li>
<p>calculate the predicted value using inverse distance weighting method</p>
</li>
</ul>
<div>
<div class="MathJax_Preview">y_{pred}(\vec x) = \frac{\sum\limits_i w_i(\vec x) y_{train, i}}{\sum\limits_i w_i(\vec x_i)}</div>
<script type="math/tex; mode=display">y_{pred}(\vec x) = \frac{\sum\limits_i w_i(\vec x) y_{train, i}}{\sum\limits_i w_i(\vec x_i)}</script>
</div>
<ul>
<li>
<p>where <span><span class="MathJax_Preview">w_i(\vec x) = \frac{1}{d(\vec x, \vec x_{train, i})}</span><script type="math/tex">w_i(\vec x) = \frac{1}{d(\vec x, \vec x_{train, i})}</script></span></p>
</li>
<li>
<p>Note, that <span><span class="MathJax_Preview">y_{pred}(\vec x) = y_{train, i}</span><script type="math/tex">y_{pred}(\vec x) = y_{train, i}</script></span> if <span><span class="MathJax_Preview">d(\vec x, \vec x_{train, i}) = 0</span><script type="math/tex">d(\vec x, \vec x_{train, i}) = 0</script></span></p>
</li>
</ul>
</li>
</ul>
<h3 id="genearate-some-fake-data">Genearate some fake data<a class="headerlink" href="#genearate-some-fake-data" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Let's grab some random points from the sine function</p>
</li>
<li>
<p>And add some noise to make it more like real data</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">data_size</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># generate and sort *data_size* numbers from 0 to 4pi </span>
<span class="n">x_train</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">data_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># let&#39;s fit to sine  </span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="c1"># add some noise to the data</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">y_train</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="s1">&#39;ro&#39;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_146_0.png" /></p>
<h3 id="make-a-fit">Make a fit<a class="headerlink" href="#make-a-fit" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>In general, one should do cross-validation to determine the best <em>k</em></p>
</li>
<li>
<p>We will skip this part during the lecture (feel free to check this at home though!)</p>
</li>
<li>
<p>Let's just check how kNN fit works for a few different values of <em>k</em></p>
</li>
</ul>
<h3 id="comment-on-numpynewaxis">Comment on <code>numpy.newaxis</code><a class="headerlink" href="#comment-on-numpynewaxis" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><span class="c1"># let&#39;s create a 1D numpy array</span>
<span class="n">D1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="n">D1</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>[1 2 3 4]
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># we can easily add another dimension using numpy.newaxis</span>
<span class="n">D2</span> <span class="o">=</span> <span class="n">D1</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="n">D2</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>[[1]
 [2]
 [3]
 [4]]
</pre></div>


<h3 id="and-back-to-the-task">And back to the task<a class="headerlink" href="#and-back-to-the-task" title="Permanent link">&para;</a></h3>
<ul>
<li>We use kNN regressor from <code>scikit-learn</code> (from intro: <em>What I really do...</em>)</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>

<span class="c1"># first we need test sample</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)):</span>
  <span class="c1"># weights=distance - weight using distances</span>
  <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;distance&#39;</span><span class="p">)</span>

  <span class="c1"># calculate y_test for all points in x_test</span>
  <span class="n">y_test</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;k = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">);</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="../output_154_0.png" /></p>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>We have learned first ML algorithm - k-Nearest Neighbors</p>
</li>
<li>
<p>It has some pros:</p>
<ul>
<li>
<p>easy to understand and implement</p>
</li>
<li>
<p>no time needed for training - may be used for initial analysis before one reaches for some <em>heavier</em> tool</p>
</li>
<li>
<p>solves nonlinear problems </p>
</li>
<li>
<p>limited number of hyperparameters</p>
</li>
<li>
<p>no parameters!</p>
</li>
<li>
<p><em>at the end of this lecture we will deal with tens of hyperparameters and thousands of parameters</em></p>
</li>
</ul>
</li>
<li>
<p>Although cons make it hard to use in practice</p>
<ul>
<li>
<p>training data must be kept for the whole time (so called <strong>lazy training</strong>)</p>
<ul>
<li>
<p>imagine having GB of training samples and you want to make mobile app</p>
</li>
<li>
<p>other algorithms allows to discard training samples once the model is trained (<strong>eager learning</strong>) - usually it means long training process but super fast classification (which is what we really want)</p>
</li>
</ul>
</li>
<li>
<p>distance-comparing is not suitable for all data - a picture of a cat on a blue background (e.g. sky) can be close to a ship on a sea (because background pixels vote too)</p>
<ul>
<li>e.g. for <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> (60k pictures, 10 classes, more about that later) vanilla kNN get less than 40% accuracy</li>
</ul>
</li>
<li>
<p>still better than random guessing (10%), but convolutional neural networks get &gt;95%</p>
</li>
</ul>
</li>
<li>
<p>Still, we have learned from kNN a few important things:</p>
<ul>
<li>
<p>Data is important (both size and quality)</p>
</li>
<li>
<p>Sometimes data requires preprocessing</p>
</li>
<li>
<p>Wrong choice of hyperparameters may lead to under- or over-fitting</p>
<ul>
<li>
<p>Use validation samples to tune the model</p>
</li>
<li>
<p>And <strong>DO NOT</strong> touch test samples until you are done!    </p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../../introduction_to_machine_learning_00_intro/introduction_to_machine_learning_00_intro/" title="Introduction" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Introduction
              </span>
            </div>
          </a>
        
        
          <a href="../../introduction_to_machine_learning_02_dt/introduction_to_machine_learning_02_dt/" title="Decision Trees" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Decision Trees
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
  <div class="md-footer-social">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    
      <a href="https://github.com/TomaszGolan/introduction_to_machine_learning" class="md-footer-social__link fa fa-github"></a>
    
  </div>

      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/application.6cdc17f0.js"></script>
      
      <script>app.initialize({version:"0.17.2",url:{base:"../../.."}})</script>
      
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
    
      
    
  </body>
</html>