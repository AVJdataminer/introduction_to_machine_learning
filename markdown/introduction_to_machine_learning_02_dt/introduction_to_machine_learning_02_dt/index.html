



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="University of Wroclaw, Department of Physics and Astronomy">
      
      
        <link rel="canonical" href="https://tomaszgolan.github.io/introduction_to_machine_learning/markdown/introduction_to_machine_learning_02_dt/introduction_to_machine_learning_02_dt/">
      
      
        <meta name="author" content="Tomasz Golan">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-0.17.2, mkdocs-material-2.2.3">
    
    
      
        <title>Decision Trees - Introduction to Machine Learning</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/application.bcabdff3.css">
      
        <link rel="stylesheet" href="../../../assets/stylesheets/application-palette.792431c1.css">
      
    
    
    
      <script src="../../../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    <script src="../../../js/require.min.js"></script>

    
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
    
    
    
      <body data-md-color-primary="blue-grey" data-md-color-accent="blue">
    
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://tomaszgolan.github.io/introduction_to_machine_learning/" title="Introduction to Machine Learning" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                Introduction to Machine Learning
              </span>
              <span class="md-header-nav__topic">
                Decision Trees
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">&#xE5CD;</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/TomaszGolan/introduction_to_machine_learning/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      IML @ GitHub
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </span>
    Introduction to Machine Learning
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/TomaszGolan/introduction_to_machine_learning/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      IML @ GitHub
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../introduction_to_machine_learning_00_intro/introduction_to_machine_learning_00_intro/" title="Introduction" class="md-nav__link">
      Introduction
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../introduction_to_machine_learning_01_knn/introduction_to_machine_learning_01_knn/" title="k-Nearest Neighbors" class="md-nav__link">
      k-Nearest Neighbors
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        Decision Trees
      </label>
    
    <a href="./" title="Decision Trees" class="md-nav__link md-nav__link--active">
      Decision Trees
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#graphviz" title="Graphviz" class="md-nav__link">
    Graphviz
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#installing-graphviz" title="Installing graphviz" class="md-nav__link">
    Installing graphviz
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a-tree-example" title="A tree example" class="md-nav__link">
    A tree example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" title="Introduction" class="md-nav__link">
    Introduction
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#decision-trees_1" title="Decision trees" class="md-nav__link">
    Decision trees
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example" title="Example" class="md-nav__link">
    Example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#id3-and-c45-algorithms" title="ID3 and C4.5 algorithms" class="md-nav__link">
    ID3 and C4.5 algorithms
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#information-gain" title="Information gain" class="md-nav__link">
    Information gain
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#self-information" title="Self-information" class="md-nav__link">
    Self-information
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#information-entropy" title="Information entropy" class="md-nav__link">
    Information entropy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#information-gain_1" title="Information gain" class="md-nav__link">
    Information gain
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example_1" title="Example" class="md-nav__link">
    Example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#id3-algorithm" title="ID3 algorithm" class="md-nav__link">
    ID3 algorithm
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play-golf-dataset" title="Play Golf dataset" class="md-nav__link">
    Play Golf dataset
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#play-golf-entropy" title="Play golf entropy" class="md-nav__link">
    Play golf entropy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play-golf-vs-outlook" title="Play golf vs outlook" class="md-nav__link">
    Play golf vs outlook
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results-for-all-features" title="Results for all features" class="md-nav__link">
    Results for all features
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#root-of-the-tree" title="Root of the tree" class="md-nav__link">
    Root of the tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#next-branch" title="Next branch" class="md-nav__link">
    Next branch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#last-branch" title="Last branch" class="md-nav__link">
    Last branch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" title="Summary" class="md-nav__link">
    Summary
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#c45-algorithm" title="C4.5 algorithm" class="md-nav__link">
    C4.5 algorithm
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#information-gain-ratio" title="Information gain ratio" class="md-nav__link">
    Information gain ratio
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example_2" title="Example" class="md-nav__link">
    Example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#continuous-values" title="Continuous values" class="md-nav__link">
    Continuous values
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example_3" title="Example" class="md-nav__link">
    Example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unknown-parameters" title="Unknown parameters" class="md-nav__link">
    Unknown parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pruning" title="Pruning" class="md-nav__link">
    Pruning
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#first-example-step-by-step" title="First example - step by step" class="md-nav__link">
    First example - step by step
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#validation-set" title="Validation set" class="md-nav__link">
    Validation set
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#thresholds-finder" title="Thresholds finder" class="md-nav__link">
    Thresholds finder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-x" title="Feature X" class="md-nav__link">
    Feature X
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-y" title="Feature Y" class="md-nav__link">
    Feature Y
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-root" title="The root" class="md-nav__link">
    The root
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#branch-x-4" title="Branch x &gt; 4" class="md-nav__link">
    Branch x &gt; 4
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#branch-x-8" title="Branch x&lt;= 8" class="md-nav__link">
    Branch x&lt;= 8
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#branch-y-2" title="Branch y &gt; 2" class="md-nav__link">
    Branch y &gt; 2
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-final-tree" title="The final tree" class="md-nav__link">
    The final tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sanity-check" title="Sanity check" class="md-nav__link">
    Sanity check
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy-before-pruning" title="Accuracy before pruning" class="md-nav__link">
    Accuracy before pruning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pruning-i" title="Pruning I" class="md-nav__link">
    Pruning I
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pruning-ii" title="Pruning II" class="md-nav__link">
    Pruning II
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_1" title="Summary" class="md-nav__link">
    Summary
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cart" title="CART" class="md-nav__link">
    CART
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gini-impurity" title="Gini impurity" class="md-nav__link">
    Gini impurity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play-golf" title="Play Golf" class="md-nav__link">
    Play Golf
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gini-impurity_1" title="Gini impurity" class="md-nav__link">
    Gini impurity
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scikit-learn" title="Scikit learn" class="md-nav__link">
    Scikit learn
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regression" title="Regression" class="md-nav__link">
    Regression
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#simple-example" title="Simple example" class="md-nav__link">
    Simple example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#growing-a-tree" title="Growing a tree" class="md-nav__link">
    Growing a tree
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree-cross-validation" title="Tree: cross-validation" class="md-nav__link">
    Tree: cross-validation
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#traning-dataset" title="Traning dataset" class="md-nav__link">
    Traning dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_depth" title="max_depth" class="md-nav__link">
    max_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#min_samples_leaf" title="min_samples_leaf" class="md-nav__link">
    min_samples_leaf
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#min_impurity_split" title="min_impurity_split" class="md-nav__link">
    min_impurity_split
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#min_impurity_decrease" title="min_impurity_decrease" class="md-nav__link">
    min_impurity_decrease
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias-variance-trade-off" title="Bias-Variance trade-off" class="md-nav__link">
    Bias-Variance trade-off
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quick-math" title="Quick math" class="md-nav__link">
    Quick math
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic" title="Basic" class="md-nav__link">
    Basic
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bias-and-variance" title="Bias and variance" class="md-nav__link">
    Bias and variance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goodness-of-a-model" title="Goodness of a model" class="md-nav__link">
    Goodness of a model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example_4" title="Example" class="md-nav__link">
    Example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-and-test-errors" title="Training and test errors" class="md-nav__link">
    Training and test errors
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ensemble-learning" title="Ensemble learning" class="md-nav__link">
    Ensemble learning
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#random-forest" title="Random forest" class="md-nav__link">
    Random forest
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intuitive-naive-example" title="Intuitive / naive example" class="md-nav__link">
    Intuitive / naive example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-algorithm" title="The algorithm" class="md-nav__link">
    The algorithm
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#boosted-trees" title="Boosted trees" class="md-nav__link">
    Boosted trees
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adaboost" title="AdaBoost" class="md-nav__link">
    AdaBoost
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#out-of-bag-error" title="Out-of-bag error" class="md-nav__link">
    Out-of-bag error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example_5" title="Example" class="md-nav__link">
    Example
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataset" title="Dataset" class="md-nav__link">
    Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train-and-visualize" title="Train and visualize" class="md-nav__link">
    Train and visualize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree" title="Decision tree" class="md-nav__link">
    Decision tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forest_1" title="Random forest" class="md-nav__link">
    Random forest
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary_2" title="Summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../introduction_to_machine_learning_03_svm/introduction_to_machine_learning_03_svm/" title="Support Vector Machine" class="md-nav__link">
      Support Vector Machine
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#graphviz" title="Graphviz" class="md-nav__link">
    Graphviz
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#installing-graphviz" title="Installing graphviz" class="md-nav__link">
    Installing graphviz
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#a-tree-example" title="A tree example" class="md-nav__link">
    A tree example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#introduction" title="Introduction" class="md-nav__link">
    Introduction
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#decision-trees_1" title="Decision trees" class="md-nav__link">
    Decision trees
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example" title="Example" class="md-nav__link">
    Example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#id3-and-c45-algorithms" title="ID3 and C4.5 algorithms" class="md-nav__link">
    ID3 and C4.5 algorithms
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#information-gain" title="Information gain" class="md-nav__link">
    Information gain
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#self-information" title="Self-information" class="md-nav__link">
    Self-information
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#information-entropy" title="Information entropy" class="md-nav__link">
    Information entropy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#information-gain_1" title="Information gain" class="md-nav__link">
    Information gain
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example_1" title="Example" class="md-nav__link">
    Example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#id3-algorithm" title="ID3 algorithm" class="md-nav__link">
    ID3 algorithm
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play-golf-dataset" title="Play Golf dataset" class="md-nav__link">
    Play Golf dataset
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#play-golf-entropy" title="Play golf entropy" class="md-nav__link">
    Play golf entropy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play-golf-vs-outlook" title="Play golf vs outlook" class="md-nav__link">
    Play golf vs outlook
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results-for-all-features" title="Results for all features" class="md-nav__link">
    Results for all features
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#root-of-the-tree" title="Root of the tree" class="md-nav__link">
    Root of the tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#next-branch" title="Next branch" class="md-nav__link">
    Next branch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#last-branch" title="Last branch" class="md-nav__link">
    Last branch
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary" title="Summary" class="md-nav__link">
    Summary
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#c45-algorithm" title="C4.5 algorithm" class="md-nav__link">
    C4.5 algorithm
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#information-gain-ratio" title="Information gain ratio" class="md-nav__link">
    Information gain ratio
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example_2" title="Example" class="md-nav__link">
    Example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#continuous-values" title="Continuous values" class="md-nav__link">
    Continuous values
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#example_3" title="Example" class="md-nav__link">
    Example
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unknown-parameters" title="Unknown parameters" class="md-nav__link">
    Unknown parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pruning" title="Pruning" class="md-nav__link">
    Pruning
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#first-example-step-by-step" title="First example - step by step" class="md-nav__link">
    First example - step by step
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#validation-set" title="Validation set" class="md-nav__link">
    Validation set
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#thresholds-finder" title="Thresholds finder" class="md-nav__link">
    Thresholds finder
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-x" title="Feature X" class="md-nav__link">
    Feature X
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#feature-y" title="Feature Y" class="md-nav__link">
    Feature Y
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-root" title="The root" class="md-nav__link">
    The root
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#branch-x-4" title="Branch x &gt; 4" class="md-nav__link">
    Branch x &gt; 4
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#branch-x-8" title="Branch x&lt;= 8" class="md-nav__link">
    Branch x&lt;= 8
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#branch-y-2" title="Branch y &gt; 2" class="md-nav__link">
    Branch y &gt; 2
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-final-tree" title="The final tree" class="md-nav__link">
    The final tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sanity-check" title="Sanity check" class="md-nav__link">
    Sanity check
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy-before-pruning" title="Accuracy before pruning" class="md-nav__link">
    Accuracy before pruning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pruning-i" title="Pruning I" class="md-nav__link">
    Pruning I
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pruning-ii" title="Pruning II" class="md-nav__link">
    Pruning II
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summary_1" title="Summary" class="md-nav__link">
    Summary
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cart" title="CART" class="md-nav__link">
    CART
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gini-impurity" title="Gini impurity" class="md-nav__link">
    Gini impurity
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play-golf" title="Play Golf" class="md-nav__link">
    Play Golf
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gini-impurity_1" title="Gini impurity" class="md-nav__link">
    Gini impurity
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scikit-learn" title="Scikit learn" class="md-nav__link">
    Scikit learn
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#regression" title="Regression" class="md-nav__link">
    Regression
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#simple-example" title="Simple example" class="md-nav__link">
    Simple example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#growing-a-tree" title="Growing a tree" class="md-nav__link">
    Growing a tree
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tree-cross-validation" title="Tree: cross-validation" class="md-nav__link">
    Tree: cross-validation
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#traning-dataset" title="Traning dataset" class="md-nav__link">
    Traning dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#max_depth" title="max_depth" class="md-nav__link">
    max_depth
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#min_samples_leaf" title="min_samples_leaf" class="md-nav__link">
    min_samples_leaf
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#min_impurity_split" title="min_impurity_split" class="md-nav__link">
    min_impurity_split
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#min_impurity_decrease" title="min_impurity_decrease" class="md-nav__link">
    min_impurity_decrease
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bias-variance-trade-off" title="Bias-Variance trade-off" class="md-nav__link">
    Bias-Variance trade-off
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#quick-math" title="Quick math" class="md-nav__link">
    Quick math
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#basic" title="Basic" class="md-nav__link">
    Basic
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bias-and-variance" title="Bias and variance" class="md-nav__link">
    Bias and variance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#goodness-of-a-model" title="Goodness of a model" class="md-nav__link">
    Goodness of a model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example_4" title="Example" class="md-nav__link">
    Example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-and-test-errors" title="Training and test errors" class="md-nav__link">
    Training and test errors
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ensemble-learning" title="Ensemble learning" class="md-nav__link">
    Ensemble learning
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#random-forest" title="Random forest" class="md-nav__link">
    Random forest
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#intuitive-naive-example" title="Intuitive / naive example" class="md-nav__link">
    Intuitive / naive example
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-algorithm" title="The algorithm" class="md-nav__link">
    The algorithm
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#boosted-trees" title="Boosted trees" class="md-nav__link">
    Boosted trees
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#adaboost" title="AdaBoost" class="md-nav__link">
    AdaBoost
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#out-of-bag-error" title="Out-of-bag error" class="md-nav__link">
    Out-of-bag error
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example_5" title="Example" class="md-nav__link">
    Example
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dataset" title="Dataset" class="md-nav__link">
    Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train-and-visualize" title="Train and visualize" class="md-nav__link">
    Train and visualize
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree" title="Decision tree" class="md-nav__link">
    Decision tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forest_1" title="Random forest" class="md-nav__link">
    Random forest
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary_2" title="Summary" class="md-nav__link">
    Summary
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/TomaszGolan/introduction_to_machine_learning/edit/master/docs/markdown/introduction_to_machine_learning_02_dt/introduction_to_machine_learning_02_dt.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="decision-trees">Decision Trees<a class="headerlink" href="#decision-trees" title="Permanent link">&para;</a></h1>
<h2 id="graphviz">Graphviz<a class="headerlink" href="#graphviz" title="Permanent link">&para;</a></h2>
<h3 id="installing-graphviz">Installing graphviz<a class="headerlink" href="#installing-graphviz" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><span class="err">!</span><span class="n">apt</span> <span class="n">install</span> <span class="o">-</span><span class="n">y</span> <span class="n">graphviz</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">graphviz</span>
</pre></div>


<h3 id="a-tree-example">A tree example<a class="headerlink" href="#a-tree-example" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">graphviz</span> <span class="kn">import</span> <span class="n">Digraph</span>

<span class="n">styles</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;top&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;shape&#39;</span><span class="p">:</span> <span class="s1">&#39;ellipse&#39;</span><span class="p">,</span> <span class="s1">&#39;style&#39;</span><span class="p">:</span> <span class="s1">&#39;filled&#39;</span><span class="p">,</span> <span class="s1">&#39;color&#39;</span><span class="p">:</span> <span class="s1">&#39;lightblue&#39;</span><span class="p">},</span>
    <span class="s1">&#39;no&#39;</span><span class="p">:</span>  <span class="p">{</span><span class="s1">&#39;shape&#39;</span><span class="p">:</span> <span class="s1">&#39;circle&#39;</span><span class="p">,</span> <span class="s1">&#39;style&#39;</span><span class="p">:</span> <span class="s1">&#39;filled&#39;</span><span class="p">,</span> <span class="s1">&#39;color&#39;</span><span class="p">:</span> <span class="s1">&#39;red&#39;</span><span class="p">},</span>
    <span class="s1">&#39;yes&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;shape&#39;</span><span class="p">:</span> <span class="s1">&#39;circle&#39;</span><span class="p">,</span> <span class="s1">&#39;style&#39;</span><span class="p">:</span> <span class="s1">&#39;filled&#39;</span><span class="p">,</span> <span class="s1">&#39;color&#39;</span><span class="p">:</span> <span class="s1">&#39;lightgreen&#39;</span><span class="p">},</span>
    <span class="s1">&#39;qst&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;shape&#39;</span><span class="p">:</span> <span class="s1">&#39;rect&#39;</span><span class="p">}</span>
<span class="p">}</span>

<span class="n">example_tree</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">()</span>

<span class="n">example_tree</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="s1">&#39;Should I attend the ML lecture?&#39;</span><span class="p">,</span> <span class="n">styles</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">])</span>
<span class="n">example_tree</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;q1&#39;</span><span class="p">,</span> <span class="s1">&#39;Do I fulfill requirements?&#39;</span><span class="p">,</span> <span class="n">styles</span><span class="p">[</span><span class="s1">&#39;qst&#39;</span><span class="p">])</span>

<span class="n">example_tree</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;q2&#39;</span><span class="p">,</span> <span class="s1">&#39;Do I like CS?&#39;</span><span class="p">,</span> <span class="n">styles</span><span class="p">[</span><span class="s1">&#39;qst&#39;</span><span class="p">])</span>
<span class="n">example_tree</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;no1&#39;</span><span class="p">,</span> <span class="s1">&#39;No &#39;</span><span class="p">,</span> <span class="n">styles</span><span class="p">[</span><span class="s1">&#39;no&#39;</span><span class="p">])</span>

<span class="n">example_tree</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;q3&#39;</span><span class="p">,</span> <span class="s1">&#39;Is the lecture early in the morning?&#39;</span><span class="p">,</span> <span class="n">styles</span><span class="p">[</span><span class="s1">&#39;qst&#39;</span><span class="p">])</span>
<span class="n">example_tree</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;no2&#39;</span><span class="p">,</span> <span class="s1">&#39;No &#39;</span><span class="p">,</span> <span class="n">styles</span><span class="p">[</span><span class="s1">&#39;no&#39;</span><span class="p">])</span>

<span class="n">example_tree</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;no3&#39;</span><span class="p">,</span> <span class="s1">&#39;No &#39;</span><span class="p">,</span> <span class="n">styles</span><span class="p">[</span><span class="s1">&#39;no&#39;</span><span class="p">])</span>
<span class="n">example_tree</span><span class="o">.</span><span class="n">node</span><span class="p">(</span><span class="s1">&#39;yes&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">,</span> <span class="n">styles</span><span class="p">[</span><span class="s1">&#39;yes&#39;</span><span class="p">])</span>

<span class="n">example_tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="s1">&#39;q1&#39;</span><span class="p">)</span>

<span class="n">example_tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;q1&#39;</span><span class="p">,</span> <span class="s1">&#39;q2&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">)</span>
<span class="n">example_tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;q1&#39;</span><span class="p">,</span> <span class="s1">&#39;no1&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">)</span>

<span class="n">example_tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;q2&#39;</span><span class="p">,</span> <span class="s1">&#39;q3&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">)</span>
<span class="n">example_tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;q2&#39;</span><span class="p">,</span> <span class="s1">&#39;no2&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">)</span>

<span class="n">example_tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;q3&#39;</span><span class="p">,</span> <span class="s1">&#39;no3&#39;</span><span class="p">,</span> <span class="s1">&#39;Yes&#39;</span><span class="p">)</span>
<span class="n">example_tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s1">&#39;q3&#39;</span><span class="p">,</span> <span class="s1">&#39;yes&#39;</span><span class="p">,</span> <span class="s1">&#39;No&#39;</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">example_tree</span>
</pre></div>


<p><img alt="svg" src="../output_6_0.svg" /></p>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<h3 id="decision-trees_1">Decision trees<a class="headerlink" href="#decision-trees_1" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Supervised learning algorithm - training dataset with known labels</p>
</li>
<li>
<p>Eager learning - final model does not need training data to make prediction (all parameters are evaluated during learning step)</p>
</li>
<li>
<p>It can do both classification and regression</p>
</li>
<li>
<p>A decision tree is built from:</p>
<ul>
<li><strong>decision nodes</strong> - correspond to features (attributes)</li>
<li><strong>leaf nodes</strong> - correspond to class labels</li>
</ul>
</li>
<li>
<p>The <strong>root</strong> of a tree is (should be) the best predictor (feature)</p>
</li>
</ul>
<h3 id="example">Example<a class="headerlink" href="#example" title="Permanent link">&para;</a></h3>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c1"># just to overwrite default colab style</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;default&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-talk&#39;</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># first define some points representing two classes</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">set01</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>
<span class="n">set01</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">set01</span><span class="p">,</span> <span class="p">[</span><span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">24</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="mi">6</span><span class="p">:</span><span class="mi">16</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">set02</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>
<span class="n">set02</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">set02</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">set01</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">set02</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;There are two attributes: x and y</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;    * each decision node splits dataset based on one of the attributes</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;    * each leaf node defines a class label&quot;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_12_0.png" /></p>
<div class="codehilite"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">set01</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">set02</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">14</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;g&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;We start with [20, 20] (blue, orange)</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;Red line splits dataset in [15, 0] (left) and [5, 20] (right)</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;Green line split dataset in [10, 6] (bottom) and [10, 14] (top)</span><span class="se">\n\n</span><span class="s2">&quot;</span>
                <span class="s2">&quot;Red line is a winner and should be the root of our tree&quot;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_13_0.png" /></p>
<div class="codehilite"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">()</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 5?</span><span class="se">\n</span><span class="s2">[20, 20]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[15, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 5?</span><span class="se">\n</span><span class="s2">[20, 20]&quot;</span><span class="p">,</span> <span class="s2">&quot;y &gt; 3?</span><span class="se">\n</span><span class="s2">[5, 20]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 3?</span><span class="se">\n</span><span class="s2">[5, 20]&quot;</span><span class="p">,</span> <span class="s2">&quot;x &gt; 9?</span><span class="se">\n</span><span class="s2">[4, 6]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 3?</span><span class="se">\n</span><span class="s2">[5, 20]&quot;</span><span class="p">,</span> <span class="s2">&quot;almost orange</span><span class="se">\n</span><span class="s2">[1, 14]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 9?</span><span class="se">\n</span><span class="s2">[4, 6]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[4, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 9?</span><span class="se">\n</span><span class="s2">[4, 6]&quot;</span><span class="p">,</span> <span class="s2">&quot;orange</span><span class="se">\n</span><span class="s2">[0, 6]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;almost orange</span><span class="se">\n</span><span class="s2">[1, 14]&quot;</span><span class="p">,</span> <span class="s2">&quot;Should we continue?</span><span class="se">\n</span><span class="s2">Or would it be overfitting?&quot;</span><span class="p">)</span>

<span class="n">tree</span>
</pre></div>


<p><img alt="svg" src="../output_14_0.svg" /></p>
<ul>
<li>
<p>It is important to start with good predictor</p>
<ul>
<li>
<p>Our choice of the root classifies 37.5% of points  in the first step</p>
</li>
<li>
<p>Note, that we could also start with <code>x &gt; 9?</code></p>
</li>
<li>
<p>However, if we started with <code>y &gt; 3</code> we would never classify a point in the first step - does it mean that it is worse choice?</p>
</li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">()</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 3?</span><span class="se">\n</span><span class="s2">[20, 20]&quot;</span><span class="p">,</span> <span class="s2">&quot;x &gt; 9?</span><span class="se">\n</span><span class="s2">[10, 6]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 3?</span><span class="se">\n</span><span class="s2">[20, 20]&quot;</span><span class="p">,</span> <span class="s2">&quot;x &gt; 5?</span><span class="se">\n</span><span class="s2">[10, 14]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 9?</span><span class="se">\n</span><span class="s2">[10, 6]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[10, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 9?</span><span class="se">\n</span><span class="s2">[10, 6]&quot;</span><span class="p">,</span> <span class="s2">&quot;orange</span><span class="se">\n</span><span class="s2">[0, 6]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 5?</span><span class="se">\n</span><span class="s2">[10, 14]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[9, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 5?</span><span class="se">\n</span><span class="s2">[10, 14]&quot;</span><span class="p">,</span> <span class="s2">&quot;almost orange</span><span class="se">\n</span><span class="s2">[1, 14]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span>
</pre></div>


<p><img alt="svg" src="../output_16_0.svg" /></p>
<ul>
<li>
<p>In this case we never have to make more than 2 checks</p>
</li>
<li>
<p>There are two open questions to answer:</p>
<ul>
<li>
<p>How to automate the procees of chosing nodes?</p>
</li>
<li>
<p>How deep should we go?</p>
</li>
</ul>
</li>
</ul>
<h2 id="id3-and-c45-algorithms">ID3 and C4.5 algorithms<a class="headerlink" href="#id3-and-c45-algorithms" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>We start with algorithms based on information theory</p>
<ul>
<li>
<p>ID3 (Iterative Dichotomiser 3)</p>
</li>
<li>
<p>C4.5 - extension of ID3 (why C4.5? C stands for programming language and 4.5 for version?)</p>
</li>
<li>
<p>C5.0/See5 - improved C4.5 (commercial; single-threaded Linux version is available under GPL though)</p>
</li>
</ul>
</li>
<li>
<p>The idea is to find nodes which maximize information gain</p>
</li>
</ul>
<h3 id="information-gain">Information gain<a class="headerlink" href="#information-gain" title="Permanent link">&para;</a></h3>
<h4 id="self-information">Self-information<a class="headerlink" href="#self-information" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Let <span><span class="MathJax_Preview">X = (x_1, x_2, ..., x_n)</span><script type="math/tex">X = (x_1, x_2, ..., x_n)</script></span> be our <em>information source</em> (feature), e.g. weather condition: <span><span class="MathJax_Preview">x_1</span><script type="math/tex">x_1</script></span> = sunny, <span><span class="MathJax_Preview">x_2</span><script type="math/tex">x_2</script></span> = overcast, <span><span class="MathJax_Preview">x_3</span><script type="math/tex">x_3</script></span> = rainy</p>
</li>
<li>
<p>And let <span><span class="MathJax_Preview">P = (p_1, p_2, ..., p_n)</span><script type="math/tex">P = (p_1, p_2, ..., p_n)</script></span> be corresponding probrability distribution (or more precisely - probability mass function)</p>
</li>
<li>
<p>We want some measure of information <span><span class="MathJax_Preview">I</span><script type="math/tex">I</script></span> provided by an event. It should satisfy the following properties:</p>
<ul>
<li>
<p><span><span class="MathJax_Preview">I</span><script type="math/tex">I</script></span> depends only on the probability of <span><span class="MathJax_Preview">x_i</span><script type="math/tex">x_i</script></span>, thus <span><span class="MathJax_Preview">I \equiv I(p_i)</span><script type="math/tex">I \equiv I(p_i)</script></span></p>
</li>
<li>
<p><span><span class="MathJax_Preview">I</span><script type="math/tex">I</script></span> is continuous and deacreasing function of <span><span class="MathJax_Preview">p_i</span><script type="math/tex">p_i</script></span></p>
</li>
<li>
<p><span><span class="MathJax_Preview">I</span><script type="math/tex">I</script></span> is non-negative and <span><span class="MathJax_Preview">I(1) = 0</span><script type="math/tex">I(1) = 0</script></span></p>
</li>
<li>
<p>if <span><span class="MathJax_Preview">p_i = p_{i, 1} \cdot p_{i, 2}</span><script type="math/tex">p_i = p_{i, 1} \cdot p_{i, 2}</script></span> (independent events) then <span><span class="MathJax_Preview">I(p_i) = I(p_{i, 1}) + I(p_{i, 2})</span><script type="math/tex">I(p_i) = I(p_{i, 1}) + I(p_{i, 2})</script></span></p>
</li>
</ul>
</li>
<li>
<p>Logarithmic function satisfies all above condition, so we define self-information as: <p align="center"><br><span><span class="MathJax_Preview">I(p) = -\log(p)</span><script type="math/tex">I(p) = -\log(p)</script></span></p><br></p>
<ul>
<li>
<p>The most common log base is <strong>2</strong> and then information is in <strong>shannons (Sh)</strong>, also known as <strong>bits</strong></p>
</li>
<li>
<p>In the case of <strong>natural logarithm</strong> the unit is <strong>nat</strong> (natural unit of information)</p>
</li>
<li>
<p>In the case of base <strong>10</strong> the unit is <strong>hartley (Hart)</strong>, also known as <strong>dit</strong></p>
</li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;p&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;I(p)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;bit&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;nat&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;dit&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>


<p><img alt="png" src="../output_23_0.png" /></p>
<ul>
<li>
<p>Lets X = (head, tail) with P = (0.5, 0.5)</p>
<ul>
<li>We get 1 Sh of information</li>
</ul>
</li>
<li>
<p>Lets X = (sunny, overcast, rainy) with P = (0.25, 0.75, 0.25)</p>
<ul>
<li>
<p>If it is overcast, we get 0.415 Sh of information</p>
</li>
<li>
<p>Otherwise, we get 2 Sh of information</p>
</li>
</ul>
</li>
<li>
<p>If an event is more likely we learn less</p>
</li>
</ul>
<h4 id="information-entropy">Information entropy<a class="headerlink" href="#information-entropy" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Also called Shannon entropy (after the father of intromation theory)</p>
</li>
<li>
<p>Usually information entropy is denoted as <span><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span></p>
</li>
<li>
<p><span><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span> is defined as the weighted average of the self-information of all possible outcomes <p align="center"><br><span><span class="MathJax_Preview">H(X) = \sum\limits_{i=1}^N p_i \cdot I(p_i) = -\sum\limits_{i=1}^N p_i\cdot\log(p_i)</span><script type="math/tex">H(X) = \sum\limits_{i=1}^N p_i \cdot I(p_i) = -\sum\limits_{i=1}^N p_i\cdot\log(p_i)</script></span></p><br></p>
</li>
<li>
<p>Lets consider two case scenario with <span><span class="MathJax_Preview">P = (p, 1 - p)</span><script type="math/tex">P = (p, 1 - p)</script></span>, so entropy is given by <span><span class="MathJax_Preview">H = -p \log(p) - (1 - p) \log(1 - p)</span><script type="math/tex">H = -p \log(p) - (1 - p) \log(1 - p)</script></span></p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;p&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;H&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;we are surprised&#39;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">),</span>
             <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">shrink</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;we are not that surprised&#39;</span><span class="p">,</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">),</span>
             <span class="n">arrowprops</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">shrink</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="o">-</span><span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">));</span>
</pre></div>


<p><img alt="png" src="../output_27_0.png" /></p>
<ul>
<li>Lets consider three case scenario with <span><span class="MathJax_Preview">P = (p, q, 1 - p - q)</span><script type="math/tex">P = (p, q, 1 - p - q)</script></span>, so entropy is given by <span><span class="MathJax_Preview">H = -p \log(p) - q\log(q) - (1 - p - q) \log(1 - p - q)</span><script type="math/tex">H = -p \log(p) - q\log(q) - (1 - p - q) \log(1 - p - q)</script></span></li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">mpl_toolkits</span> <span class="kn">import</span> <span class="n">mplot3d</span>

<span class="c1"># grid of p, q probabilities</span>
<span class="n">p</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">))</span>

<span class="c1"># remove (set to 0) points which do not fulfill P &lt;= 1</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">p</span> <span class="o">+</span> <span class="n">q</span> <span class="o">&gt;</span> <span class="mi">1</span>
<span class="n">p</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">q</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># calculate entropy (disable warnings - we are aware of log(0))</span>
<span class="n">np</span><span class="o">.</span><span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="o">-</span><span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">-</span> <span class="n">q</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">q</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span> <span class="o">-</span> <span class="n">q</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span> <span class="o">-</span> <span class="n">q</span><span class="p">)</span>

<span class="c1"># make a plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">h</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_29_0.png" /></p>
<h4 id="information-gain_1">Information gain<a class="headerlink" href="#information-gain_1" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Let <span><span class="MathJax_Preview">T</span><script type="math/tex">T</script></span> be the set of training samples with <span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> possible outcomes, thus <span><span class="MathJax_Preview">T = \{T_1, T_2, ..., T_n\}</span><script type="math/tex">T = \{T_1, T_2, ..., T_n\}</script></span></p>
</li>
<li>
<p>The entropy is given by <p align="center"><br><span><span class="MathJax_Preview">H(T) = -\sum\limits_{i=1}^N p_i\cdot\log(p_i) = -\sum\limits_{i=1}^N \frac{|T_i|}{|T|}\cdot\log(\frac{|T_i|}{|T|})</span><script type="math/tex">H(T) = -\sum\limits_{i=1}^N p_i\cdot\log(p_i) = -\sum\limits_{i=1}^N \frac{|T_i|}{|T|}\cdot\log(\frac{|T_i|}{|T|})</script></span></p><br></p>
</li>
<li>
<p>We can also calulate the entropy after <span><span class="MathJax_Preview">T</span><script type="math/tex">T</script></span> was partitioned in <span><span class="MathJax_Preview">T_i</span><script type="math/tex">T_i</script></span> with respect to some feature <span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span> <p align="center"><br><span><span class="MathJax_Preview">H(T, X) = \sum\limits_{i=1}^N p_i\cdot H(T_i)</span><script type="math/tex">H(T, X) = \sum\limits_{i=1}^N p_i\cdot H(T_i)</script></span></p></p>
</li>
<li>
<p>And the information gain is defined as <p align="center"><br><span><span class="MathJax_Preview">G(X) = H(T) - H(T, X)</span><script type="math/tex">G(X) = H(T) - H(T, X)</script></span></p></p>
</li>
</ul>
<h5 id="example_1">Example<a class="headerlink" href="#example_1" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>Lets calculate some example step by step</p>
</li>
<li>
<p>Lets consider a fake dataset</p>
<ul>
<li>
<p>two classes: C01, C02</p>
</li>
<li>
<p>three features: X1, X2, X3</p>
</li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span>   X1  ||  A  |  A  |  A  |  B  |  B  |  C  |  C  |  C  |  C  |
---------------------------------------------------------------
   X2  ||  0  |  0  |  1  |  1  |  0  |  1  |  1  |  1  |  0  |
---------------------------------------------------------------
   X3  || RED | GRN | GRN | BLU | RED | GRN | BLU | RED | GRN |
===============================================================
 Class || C01 | C01 | C02 | C02 | C02 | C02 | C01 | C01 | C02 |
</pre></div>


<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">log</span>

<span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="o">*</span><span class="n">probs</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calculate information entropy&quot;&quot;&quot;</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">total</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="o">-</span><span class="n">p</span> <span class="o">/</span> <span class="n">total</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="n">p</span> <span class="o">/</span> <span class="n">total</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">probs</span><span class="p">])</span>
  <span class="k">except</span><span class="p">:</span>
    <span class="k">return</span> <span class="mi">0</span>

<span class="k">print</span><span class="p">(</span><span class="n">entropy</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.9910760598382222 0.9182958340544896 1.0
</pre></div>


<ul>
<li>
<p>The <em>root</em> entropy</p>
<ul>
<li>We have 9 samples: 4 belong to class C01 and 5 to C02 <p align="center"><br><span><span class="MathJax_Preview">H(T) = -\frac{4}{9}\log(\frac{4}{9}) - \frac{5}{9}\log(\frac{5}{9}) = 0.99</span><script type="math/tex">H(T) = -\frac{4}{9}\log(\frac{4}{9}) - \frac{5}{9}\log(\frac{5}{9}) = 0.99</script></span></p><br></li>
</ul>
</li>
<li>
<p>Now lets consider feature X1, which splits data into subsets <span><span class="MathJax_Preview">T_1</span><script type="math/tex">T_1</script></span>, <span><span class="MathJax_Preview">T_2</span><script type="math/tex">T_2</script></span>, and <span><span class="MathJax_Preview">T_3</span><script type="math/tex">T_3</script></span> (with X1 value A, B, and C, respectively)<br><br></p>
<ul>
<li>
<p>Within <span><span class="MathJax_Preview">T_1</span><script type="math/tex">T_1</script></span> there are 3 samples: 2 from C01 and 1 from C02 <p align="center"><br><span><span class="MathJax_Preview">H(T_1) = -\frac{2}{3}\log(\frac{2}{3}) - \frac{1}{3}\log(\frac{1}{3}) = 0.92</span><script type="math/tex">H(T_1) = -\frac{2}{3}\log(\frac{2}{3}) - \frac{1}{3}\log(\frac{1}{3}) = 0.92</script></span></p><br></p>
</li>
<li>
<p>Within <span><span class="MathJax_Preview">T_2</span><script type="math/tex">T_2</script></span> there are 2 samples: 0 from C01 and 2 from C02 <p align="center"><br><span><span class="MathJax_Preview">H(T_2) = -\frac{2}{2}\log(\frac{2}{2}) - \frac{0}{2}\log(\frac{0}{2}) = 0.00</span><script type="math/tex">H(T_2) = -\frac{2}{2}\log(\frac{2}{2}) - \frac{0}{2}\log(\frac{0}{2}) = 0.00</script></span></p><br></p>
</li>
<li>
<p>Within <span><span class="MathJax_Preview">T_3</span><script type="math/tex">T_3</script></span> there are 4 samples: 2 from C01 and 2 from C02 <p align="center"><br><span><span class="MathJax_Preview">H(T_3) = -\frac{2}{4}\log(\frac{2}{4}) - \frac{2}{4}\log(\frac{2}{4}) = 1.00</span><script type="math/tex">H(T_3) = -\frac{2}{4}\log(\frac{2}{4}) - \frac{2}{4}\log(\frac{2}{4}) = 1.00</script></span></p><br></p>
</li>
<li>
<p>The resulting entropy is <p align="center"><br><span><span class="MathJax_Preview">H(T, X1) = \frac{3}{9}\cdot H(T_1) + \frac{2}{9}\cdot H(T_2) + \frac{4}{9}\cdot H(T_3) = 0.75</span><script type="math/tex">H(T, X1) = \frac{3}{9}\cdot H(T_1) + \frac{2}{9}\cdot H(T_2) + \frac{4}{9}\cdot H(T_3) = 0.75</script></span></p><br></p>
</li>
<li>
<p>Thus, infromation gain if the set is split according to X1 <p align="center"><br><span><span class="MathJax_Preview">G(X1) = H(T) - H(T, X1) = 0.99 - 0.75 = 0.24 \mbox{ Sh }</span><script type="math/tex">G(X1) = H(T) - H(T, X1) = 0.99 - 0.75 = 0.24 \mbox{ Sh }</script></span></p><br></p>
</li>
</ul>
</li>
</ul>
<h3 id="id3-algorithm">ID3 algorithm<a class="headerlink" href="#id3-algorithm" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>For every attribute (feature) calculate the entropy</p>
</li>
<li>
<p>Split the training set using the one for which information gain is maximum</p>
</li>
<li>
<p>Continue recursively on subsets using remaining features</p>
</li>
</ul>
<h3 id="play-golf-dataset">Play Golf dataset<a class="headerlink" href="#play-golf-dataset" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Popular dataset to explain decision trees</p>
</li>
<li>
<p>4 features:</p>
<ul>
<li>
<p><strong>outlook</strong>: <em>rainy, overcast, sunny</em></p>
</li>
<li>
<p><strong>temperature</strong>: <em>cool, mild, hot</em></p>
</li>
<li>
<p><strong>humidity</strong>: <em>normal, high</em></p>
</li>
<li>
<p><strong>windy</strong>: <em>false, true</em></p>
</li>
</ul>
</li>
<li>
<p>Possible outcomes (play golf?):</p>
<ul>
<li>
<p><strong>false</strong></p>
</li>
<li>
<p><strong>true</strong></p>
</li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="c1"># first row = headers</span>
<span class="n">src</span> <span class="o">=</span> <span class="s2">&quot;http://chem-eng.utoronto.ca/~datamining/dmc/datasets/weather_nominal.csv&quot;</span>

<span class="n">golf_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">golf_data</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Outlook</th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Windy</th>
      <th>Play golf</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Rainy</td>
      <td>Hot</td>
      <td>High</td>
      <td>False</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Rainy</td>
      <td>Hot</td>
      <td>High</td>
      <td>True</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Overcast</td>
      <td>Hot</td>
      <td>High</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sunny</td>
      <td>Mild</td>
      <td>High</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Sunny</td>
      <td>Cool</td>
      <td>Normal</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Sunny</td>
      <td>Cool</td>
      <td>Normal</td>
      <td>True</td>
      <td>No</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Overcast</td>
      <td>Cool</td>
      <td>Normal</td>
      <td>True</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Rainy</td>
      <td>Mild</td>
      <td>High</td>
      <td>False</td>
      <td>No</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Rainy</td>
      <td>Cool</td>
      <td>Normal</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Sunny</td>
      <td>Mild</td>
      <td>Normal</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Rainy</td>
      <td>Mild</td>
      <td>Normal</td>
      <td>True</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Overcast</td>
      <td>Mild</td>
      <td>High</td>
      <td>True</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Overcast</td>
      <td>Hot</td>
      <td>Normal</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Sunny</td>
      <td>Mild</td>
      <td>High</td>
      <td>True</td>
      <td>No</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="play-golf-entropy">Play golf entropy<a class="headerlink" href="#play-golf-entropy" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">entropy</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.9402859586706309
</pre></div>


<div class="codehilite"><pre><span></span>| Play golf |
=============
| yes | no  |  -&gt; H(T) = 0.94
-------------
|  9  |  5  |
</pre></div>


<h4 id="play-golf-vs-outlook">Play golf vs outlook<a class="headerlink" href="#play-golf-vs-outlook" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span>                   | Play golf |
                   =============
                   | yes | no  |
        ------------------------
        | sunny    |  3  |  2  |  5
outlook | overcast |  4  |  0  |  4
        | rainy    |  2  |  3  |  5
        ------------------------
                      9     5
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">entropy</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(0.9709505944546686, 0, 0.9709505944546686)
</pre></div>


<p><br></p>
<p align="center">
\begin{eqnarray}
   H(\mbox{sunny}) & = & 0.97 \\
   H(\mbox{rainy}) & = & 0.97 \\
H(\mbox{overcast}) & = & 0
\end{eqnarray}
</p>

<p><br></p>
<hr />
<p><br></p>
<p align="center">
\begin{eqnarray}
H(T, \mbox{outlook}) & = & P(\mbox{sunny})\cdot H(\mbox{sunny}) + P(\mbox{overcast})\cdot H(\mbox{overcast}) + P(\mbox{rainy})\cdot H(\mbox{rainy}) \\
                     & = & \frac{5}{14}\cdot 0.97 + \frac{4}{14} \cdot 0 + \frac{5}{14}\cdot 0.97 = 0.69
\end{eqnarray}
</p>

<p><br></p>
<hr />
<p><br></p>
<p align="center">
\begin{eqnarray}
G(\mbox{outlook}) & = & H(T) - H(T, \mbox{outlook}) = 0.94 - 0.69 = 0.25
\end{eqnarray}
</p>

<p><br></p>
<h4 id="results-for-all-features">Results for all features<a class="headerlink" href="#results-for-all-features" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span>                    | Play golf |                         | Play golf |
                    =============                         =============
                    | yes | no  |                         | yes | no  |
         ------------------------                 --------------------
         | sunny    |  3  |  2  |                 | hot   |  2  |  2  |
 outlook | overcast |  4  |  0  |     temperature | mild  |  4  |  2  |
         | rainy    |  2  |  3  |                 | cool  |  3  |  1  |
         ------------------------                 --------------------
            Info. gain = 0.25                       Info gain = 0.03


                    | Play golf |                         | Play golf |
                    =============                         =============
                    | yes | no  |                         | yes | no  |
         ------------------------                 --------------------
         | high     |  3  |  4  |                 | false |  6  |  2  |
humidity | normal   |  6  |  1  |           windy | true  |  3  |  3  |
         ------------------------                 --------------------
            Info. gain = 0.15                       Info gain = 0.05
</pre></div>


<h4 id="root-of-the-tree">Root of the tree<a class="headerlink" href="#root-of-the-tree" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Start building a tree with the feature with the largest information gain: <strong>outlook</strong></p>
</li>
<li>
<p>A branch with <strong>entropy 0</strong> is a leaf node: <strong>overcast</strong></p>
</li>
<li>
<p>Other branches must be spliited using other features </p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">()</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;outlook&quot;</span><span class="p">,</span> <span class="s2">&quot;sunny&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;outlook&quot;</span><span class="p">,</span> <span class="s2">&quot;overcast&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;outlook&quot;</span><span class="p">,</span> <span class="s2">&quot;rainy&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;overcast&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">)</span>

<span class="n">tree</span>
</pre></div>


<p><img alt="svg" src="../output_54_0.svg" /></p>
<h4 id="next-branch">Next branch<a class="headerlink" href="#next-branch" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">golf_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">golf_data</span><span class="p">[</span><span class="s1">&#39;Outlook&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Sunny&quot;</span><span class="p">]</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Outlook</th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Windy</th>
      <th>Play golf</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>Sunny</td>
      <td>Mild</td>
      <td>High</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Sunny</td>
      <td>Cool</td>
      <td>Normal</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Sunny</td>
      <td>Cool</td>
      <td>Normal</td>
      <td>True</td>
      <td>No</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Sunny</td>
      <td>Mild</td>
      <td>Normal</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Sunny</td>
      <td>Mild</td>
      <td>High</td>
      <td>True</td>
      <td>No</td>
    </tr>
  </tbody>
</table>
</div>

<ul>
<li>
<p>In general, one should calculate information gain for each feature for this subset</p>
</li>
<li>
<p>In this case it is clear that we can take <strong>windy</strong> </p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;sunny&quot;</span><span class="p">,</span> <span class="s2">&quot;windy&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;windy&quot;</span><span class="p">,</span> <span class="s2">&quot;false&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;windy&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;false&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;true&quot;</span><span class="p">,</span> <span class="s2">&quot;no&quot;</span><span class="p">)</span>

<span class="n">tree</span>
</pre></div>


<p><img alt="svg" src="../output_58_0.svg" /></p>
<h4 id="last-branch">Last branch<a class="headerlink" href="#last-branch" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">golf_data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">golf_data</span><span class="p">[</span><span class="s1">&#39;Outlook&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Rainy&quot;</span><span class="p">]</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Outlook</th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Windy</th>
      <th>Play golf</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Rainy</td>
      <td>Hot</td>
      <td>High</td>
      <td>False</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Rainy</td>
      <td>Hot</td>
      <td>High</td>
      <td>True</td>
      <td>No</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Rainy</td>
      <td>Mild</td>
      <td>High</td>
      <td>False</td>
      <td>No</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Rainy</td>
      <td>Cool</td>
      <td>Normal</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Rainy</td>
      <td>Mild</td>
      <td>Normal</td>
      <td>True</td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>
</div>

<div class="codehilite"><pre><span></span><span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;rainy&quot;</span><span class="p">,</span> <span class="s2">&quot;humidity&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;humidity&quot;</span><span class="p">,</span> <span class="s2">&quot;high&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;humidity&quot;</span><span class="p">,</span> <span class="s2">&quot;normal&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;normal&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;high&quot;</span><span class="p">,</span> <span class="s2">&quot;no &quot;</span><span class="p">)</span>

<span class="n">tree</span>
</pre></div>


<p><img alt="svg" src="../output_61_0.svg" /></p>
<h4 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>We got the final tree for Play Golf dataset using ID3 algorithm</p>
</li>
<li>
<p>We do not even use temperature attribute (for which information gain was 0.03)</p>
</li>
<li>
<p>The main problem is that the algorithm may overfit easily (tree does not stop growing until the whole training set is classified)</p>
<ul>
<li>
<p>Imagine some crazy guys went playing on a <strong>rainy</strong>, <strong>windy</strong> day with <strong>high humidity</strong>, beacaue it was still <strong>hot</strong></p>
</li>
<li>
<p>With this extra data point we would have to create more branches</p>
</li>
<li>
<p>Is one unique data sample worth to extend the whole tree?</p>
</li>
</ul>
</li>
<li>
<p>And there is more disadvantages:</p>
<ul>
<li>
<p>It handles only discrete attributes</p>
</li>
<li>
<p>There is a strong bias for features with many possible outcomes</p>
</li>
<li>
<p>And finally, it does not handle missing values</p>
</li>
</ul>
</li>
</ul>
<h3 id="c45-algorithm">C4.5 algorithm<a class="headerlink" href="#c45-algorithm" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>C4.5 introduces some improvements to ID3:</p>
<ul>
<li>
<p>continuous values using threshold</p>
</li>
<li>
<p>tree pruning to avoid overfitting</p>
</li>
<li>
<p>normalized information gain</p>
</li>
<li>
<p>missing values</p>
</li>
</ul>
</li>
</ul>
<h4 id="information-gain-ratio">Information gain ratio<a class="headerlink" href="#information-gain-ratio" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>To avoid a bias in favor of features with a lot of different values C4.5 uses information gain ratio instead of information gain</p>
</li>
<li>
<p>Lets define intrinsic value <span><span class="MathJax_Preview">V</span><script type="math/tex">V</script></span> of an attribute <span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span> as <p align="center"><span><span class="MathJax_Preview">V(X) = -\sum\limits_{i=1}^N \frac{|T_i|}{|T|}\cdot\log(\frac{|T_i|}{|T|})</span><script type="math/tex">V(X) = -\sum\limits_{i=1}^N \frac{|T_i|}{|T|}\cdot\log(\frac{|T_i|}{|T|})</script></span></p></p>
</li>
<li>
<p>where <span><span class="MathJax_Preview">T_i</span><script type="math/tex">T_i</script></span> are samples corresponding to <span><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span>-th possible value of <span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span> feature</p>
</li>
<li>
<p>Information gain ratio <span><span class="MathJax_Preview">R(X)</span><script type="math/tex">R(X)</script></span> is defined as <p align="center"><span><span class="MathJax_Preview">R(X) = \frac{G(X)}{V(X)}</span><script type="math/tex">R(X) = \frac{G(X)}{V(X)}</script></span></p></p>
</li>
</ul>
<h5 id="example_2">Example<a class="headerlink" href="#example_2" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>Lets consider a fake data set</p>
</li>
<li>
<p>The goal is to determine if someone plays or not video games</p>
</li>
<li>
<p>We have three features:</p>
<ul>
<li>
<p>name - mostly unique</p>
</li>
<li>
<p>sex - 50% females and 50% males </p>
</li>
<li>
<p>age - just old or young</p>
</li>
</ul>
</li>
<li>
<p>Looking at data we can say that</p>
<ul>
<li>
<p>most young people play video games, why old people don't</p>
</li>
<li>
<p>sex does not matter</p>
</li>
<li>
<p>names are almost distinct</p>
</li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span>     name   ||  John  |  Mark  |  Anne  |  Adam  |  John  |  Alex  |  Alex  |  Xena  |  Tina  |  Lucy  |
--------------------------------------------------------------------------------------------------------
     sex    ||   M    |   M    |   F    |   M    |   M    |   F    |   M    |   F    |   F    |   F    |
--------------------------------------------------------------------------------------------------------
     age    ||  old   | young  |  old   | young  | young  | young  |  old   |  old   | young  | young  |
========================================================================================================
 play games ||   N    |   Y    |   Y    |   Y    |   Y    |   N    |   N    |   N    |   Y    |   Y    |
</pre></div>


<ul>
<li>Information gain for <strong>name</strong></li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">h</span> <span class="o">=</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>  <span class="c1"># dataset entropy H(T)</span>

<span class="c1"># one John plays and the other one doesn&#39;t</span>
<span class="c1"># in other cases entropy = 0</span>
<span class="n">g_name</span> <span class="o">=</span> <span class="n">h</span> <span class="o">-</span> <span class="mi">2</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">g_name</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.7709505944546686
</pre></div>


<ul>
<li>Information gain for <strong>sex</strong></li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># 5 men - 3 play</span>
<span class="c1"># 5 women - 3 play</span>
<span class="n">g_sex</span> <span class="o">=</span> <span class="n">h</span> <span class="o">-</span> <span class="mi">5</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">-</span> <span class="mi">5</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">g_sex</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.0
</pre></div>


<ul>
<li>Information gain for <strong>age</strong></li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># 4 old people - 1 plays</span>
<span class="c1"># 6 young people - 5 play</span>
<span class="n">g_age</span> <span class="o">=</span> <span class="n">h</span> <span class="o">-</span> <span class="mi">4</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">-</span> <span class="mi">6</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">g_age</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.256425891682003
</pre></div>


<ul>
<li>
<p>In ID3 a feature with entropy = 0 is always a winner</p>
<ul>
<li>Imagine having all distinct values (e.g. credit card numbers)</li>
</ul>
</li>
<li>
<p>In this case we would choose <strong>name</strong> as the best predictor</p>
<ul>
<li>
<p>Creating a tree with 8 branches (from 10 samples)</p>
</li>
<li>
<p>Training data would be perfectly classify</p>
</li>
<li>
<p>But it is unlikely that the algorithm would be able to generalize for unseen data</p>
</li>
</ul>
</li>
<li>
<p>Lets calculate information gain ratio and see how it changes the choice of the best feature</p>
</li>
<li>
<p>Information gain ratio for <strong>name</strong></p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># 2x John, 2x Alex, 6x unique name </span>
<span class="n">g_name</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">6</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.26384995435159336
</pre></div>


<ul>
<li>Information gain ratio for <strong>sex</strong></li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># 5 males and 5 females - zero stays zero though</span>
<span class="n">g_sex</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.0
</pre></div>


<ul>
<li>Information gain ratio for <strong>age</strong></li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># 4x old and 6x young</span>
<span class="n">g_age</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.26409777505314147
</pre></div>


<ul>
<li>
<p>Based on information gain ratio we choose <strong>age</strong> as the best predictor</p>
</li>
<li>
<p>Because the denominator in a ratio penalizes features with many values</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Two possible values:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">({}, {}) split -&gt; entropy = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">10</span><span class="o">-</span><span class="n">i</span><span class="p">,</span> <span class="n">entropy</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">10</span><span class="o">-</span><span class="n">i</span><span class="p">)))</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">10 possible values:&quot;</span><span class="p">,</span> <span class="n">entropy</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">10</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Two possible values:

    (0, 10) split -&gt; entropy = 0
    (1, 9) split -&gt; entropy = 0.4689955935892812
    (2, 8) split -&gt; entropy = 0.7219280948873623
    (3, 7) split -&gt; entropy = 0.8812908992306927
    (4, 6) split -&gt; entropy = 0.9709505944546686
    (5, 5) split -&gt; entropy = 1.0
    (6, 4) split -&gt; entropy = 0.9709505944546686
    (7, 3) split -&gt; entropy = 0.8812908992306927
    (8, 2) split -&gt; entropy = 0.7219280948873623
    (9, 1) split -&gt; entropy = 0.4689955935892812
    (10, 0) split -&gt; entropy = 0

10 possible values: 3.321928094887362
</pre></div>


<ul>
<li>This datset was handcrafted to make a point, but I hope the message is still clear</li>
</ul>
<h4 id="continuous-values">Continuous values<a class="headerlink" href="#continuous-values" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Attributes with continuous values must be first discretize</p>
</li>
<li>
<p>The best way is to find an optimal threshold which splits the set</p>
</li>
<li>
<p>The optimal threshold is the one which maximize the infromation gain</p>
</li>
</ul>
<h5 id="example_3">Example<a class="headerlink" href="#example_3" title="Permanent link">&para;</a></h5>
<ul>
<li>
<p>Lets consider the same example as before</p>
</li>
<li>
<p>But this time age has numerical values</p>
</li>
</ul>
<div class="codehilite"><pre><span></span>     name   ||  John  |  Mark  |  Anne  |  Adam  |  John  |  Alex  |  Alex  |  Xena  |  Tina  |  Lucy  |
--------------------------------------------------------------------------------------------------------
     sex    ||   M    |   M    |   F    |   M    |   M    |   F    |   M    |   F    |   F    |   F    |
--------------------------------------------------------------------------------------------------------
     age    ||   50   |   18   |   65   |   24   |   31   |   18   |   50   |   50   |   24   |   31   |
========================================================================================================
 play games ||   N    |   Y    |   Y    |   Y    |   Y    |   N    |   N    |   N    |   Y    |   Y    |
</pre></div>


<ul>
<li>The possible thesholds are therefore <span><span class="MathJax_Preview">\{18, 24, 31, 50\}</span><script type="math/tex">\{18, 24, 31, 50\}</script></span></li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># calculate entropy for all possible thresholds</span>
<span class="n">e18</span> <span class="o">=</span> <span class="mi">2</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">8</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">e24</span> <span class="o">=</span> <span class="mi">4</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="mi">6</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">e31</span> <span class="o">=</span> <span class="mi">6</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="mi">4</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">e50</span> <span class="o">=</span> <span class="mi">9</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="mi">10</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;With threshold = {}, entropy = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="n">e18</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;With threshold = {}, entropy = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">e24</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;With threshold = {}, entropy = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">31</span><span class="p">,</span> <span class="n">e31</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;With threshold = {}, entropy = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">e50</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>With threshold = 18, entropy = 0.963547202339972
With threshold = 24, entropy = 0.9245112497836532
With threshold = 31, entropy = 0.7145247027726656
With threshold = 50, entropy = 0.8919684538544
</pre></div>


<ul>
<li>
<p>The best test is <code>if age &gt; 31</code></p>
<ul>
<li>it splits the dataset to 6 samples (with 5 players) and 4 samples (with 3 non-players)</li>
</ul>
</li>
<li>
<p>Please note, that the best threshold may change once a node is created</p>
</li>
</ul>
<h4 id="unknown-parameters">Unknown parameters<a class="headerlink" href="#unknown-parameters" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>In the case some samples are incomplete one needs to correct the information gain</p>
</li>
<li>
<p>The information gain is calculated as before for samples with known attributes</p>
</li>
<li>
<p>But then it is normalized with respect to the probability that the given attribute has known values</p>
</li>
<li>
<p>Lets define the factor <span><span class="MathJax_Preview">F</span><script type="math/tex">F</script></span> as the ratio of the number of samples with known value for a given feature to the number of all samples in a dataset</p>
</li>
<li>
<p>Then information gain is defines as <p align="center"><span><span class="MathJax_Preview">G(X) = F\cdot (H(T) - H(T, X))</span><script type="math/tex">G(X) = F\cdot (H(T) - H(T, X))</script></span></p></p>
</li>
<li>
<p>Please note, that <span><span class="MathJax_Preview">F = 1</span><script type="math/tex">F = 1</script></span> if all values are known</p>
</li>
<li>
<p>Otherwise, information gain is scaled accordingly</p>
</li>
</ul>
<h4 id="pruning">Pruning<a class="headerlink" href="#pruning" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>The algorithm creates as many nodes as needed to classify all test samples</p>
</li>
<li>
<p>It may lead to overfitting and the resulting tree would fail to classify correctly unseen samples</p>
</li>
<li>
<p>To avoid this one can prune a tree</p>
<ul>
<li>
<p>pre-pruning (early stopping)</p>
<ul>
<li>
<p>stop building a tree before leaves with few samples are produced</p>
</li>
<li>
<p>how to decide when it is good time to stop? e.g. using cross-validation on validation set (stop if the error does not increase significantly)</p>
</li>
<li>
<p>underfitting if stop to early</p>
</li>
</ul>
</li>
<li>
<p>post-pruning</p>
<ul>
<li>
<p>let a tree grow completely</p>
</li>
<li>
<p>then go from bottom to top and try to replace a node with a leaf</p>
</li>
<li>
<p>if there is improvement in accuracy - cut a tree</p>
</li>
<li>
<p>if the accuracy stays the same - cut a tree (Occam's razor)</p>
</li>
<li>
<p>otherwise leave a node   </p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="first-example-step-by-step">First example - step by step<a class="headerlink" href="#first-example-step-by-step" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Lets consider the problem from the beginning of the lecture</p>
</li>
<li>
<p>Our dataset has 20 blue points and 20 orange points</p>
</li>
<li>
<p>Each point has two features (both are numerical)</p>
</li>
<li>
<p>We expect overfitting if pruning is not applied</p>
</li>
<li>
<p>We will calculate everything step by step (it is boring, but demonstrates how the algorithm works)</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># first define some points representing two classes</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">set01</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>
<span class="n">set01</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">set01</span><span class="p">,</span> <span class="p">[</span><span class="mi">17</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">24</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="mi">6</span><span class="p">:</span><span class="mi">16</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">set02</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>
<span class="n">set02</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">set02</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">set01</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">set02</span><span class="o">.</span><span class="n">T</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_101_0.png" /></p>
<h4 id="validation-set">Validation set<a class="headerlink" href="#validation-set" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>We will use 10 points from the dataset for validation</p>
</li>
<li>
<p>This time selected manually to perform by hand calculations</p>
</li>
<li>
<p>On the plot below X denotes validation samples</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># split dataset to training and validation set</span>
<span class="c1"># note, we should splt them randomly</span>
<span class="c1"># but here we do this by hand</span>
<span class="n">valid_idx</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">18</span><span class="p">]</span>

<span class="n">blue_valid</span> <span class="o">=</span> <span class="n">set01</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">]</span>
<span class="n">blue_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">set01</span><span class="p">,</span> <span class="n">valid_idx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">orange_valid</span> <span class="o">=</span> <span class="n">set02</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">]</span>
<span class="n">orange_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">set02</span><span class="p">,</span> <span class="n">valid_idx</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># circles - training set</span>
<span class="c1"># x - validation set</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">blue_train</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">blue_valid</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">orange_train</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">orange_valid</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_104_0.png" /></p>
<h4 id="thresholds-finder">Thresholds finder<a class="headerlink" href="#thresholds-finder" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>When building a tree we need to calculate information gain for every threshold in current subset</p>
</li>
<li>
<p>Every subset <span><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span> has <span><span class="MathJax_Preview">N_b</span><script type="math/tex">N_b</script></span> blue samples and <span><span class="MathJax_Preview">N_o</span><script type="math/tex">N_o</script></span> orange samples</p>
</li>
<li>
<p>After split into accoring to some threshold we get two subsets</p>
<ul>
<li>
<p><span><span class="MathJax_Preview">n_b</span><script type="math/tex">n_b</script></span> of blue points and <span><span class="MathJax_Preview">n_o</span><script type="math/tex">n_o</script></span> of orange points (<span><span class="MathJax_Preview">S_1</span><script type="math/tex">S_1</script></span>)</p>
</li>
<li>
<p><span><span class="MathJax_Preview">N_b - n_b</span><script type="math/tex">N_b - n_b</script></span> of blue points and <span><span class="MathJax_Preview">N_o - n_o</span><script type="math/tex">N_o - n_o</script></span> of orange points (<span><span class="MathJax_Preview">S_2</span><script type="math/tex">S_2</script></span>)</p>
</li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="n">nb</span><span class="p">,</span> <span class="n">no</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calculate information gain for given split&quot;&quot;&quot;</span>
  <span class="n">h</span> <span class="o">=</span> <span class="n">entropy</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">)</span> <span class="c1"># H(S)</span>
  <span class="n">total</span> <span class="o">=</span> <span class="n">Nb</span> <span class="o">+</span> <span class="n">No</span>     <span class="c1"># total number of samples</span>
  <span class="n">subtotal</span> <span class="o">=</span> <span class="n">nb</span> <span class="o">+</span> <span class="n">no</span>  <span class="c1"># number of samples in subset</span>

  <span class="k">return</span> <span class="n">h</span> <span class="o">-</span> <span class="n">subtotal</span> <span class="o">/</span> <span class="n">total</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="n">nb</span><span class="p">,</span> <span class="n">no</span><span class="p">)</span> \
           <span class="o">-</span> <span class="p">(</span><span class="n">total</span> <span class="o">-</span> <span class="n">subtotal</span><span class="p">)</span> <span class="o">/</span> <span class="n">total</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="n">Nb</span> <span class="o">-</span> <span class="n">nb</span><span class="p">,</span> <span class="n">No</span> <span class="o">-</span> <span class="n">no</span><span class="p">)</span>
</pre></div>


<h4 id="feature-x">Feature X<a class="headerlink" href="#feature-x" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>We need to calculate information gain ratio for the best threshold (the one that maximize information gain)</p>
</li>
<li>
<p>Possible thresholds <span><span class="MathJax_Preview">\{0, 2, 4, 6, 8, 10, 12\}</span><script type="math/tex">\{0, 2, 4, 6, 8, 10, 12\}</script></span></p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Nb</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">No</span> <span class="o">=</span> <span class="mi">15</span>

<span class="n">splits</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;0&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">&quot;2 &quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">&quot;4&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">&quot;6&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
          <span class="s2">&quot;8&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="s2">&quot;10&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="s2">&quot;12&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">11</span><span class="p">)}</span>

<span class="k">for</span> <span class="n">threshold</span><span class="p">,</span> <span class="p">(</span><span class="n">no</span><span class="p">,</span> <span class="n">nb</span><span class="p">)</span> <span class="ow">in</span> <span class="n">splits</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Threshold = {}</span><span class="se">\t</span><span class="s2"> -&gt; {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="n">no</span><span class="p">,</span> <span class="n">nb</span><span class="p">)))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Threshold = 0    -&gt; 0.14818913558232172
Threshold = 2    -&gt; 0.33824492595034883
Threshold = 4    -&gt; 0.5297578726233217
Threshold = 6    -&gt; 0.3525728312615027
Threshold = 8    -&gt; 0.5297578726233217
Threshold = 10   -&gt; 0.28538113149388267
Threshold = 12   -&gt; 0.14818913558232172
</pre></div>


<ul>
<li>
<p>We got the same cuts as predicted at the beginning of the lecture: <span><span class="MathJax_Preview">x &gt; 4</span><script type="math/tex">x > 4</script></span> or <span><span class="MathJax_Preview">x &gt; 8</span><script type="math/tex">x > 8</script></span></p>
</li>
<li>
<p>Lets choose <span><span class="MathJax_Preview">x &gt; 4</span><script type="math/tex">x > 4</script></span> and calculate information gain ratio</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># 4 samples with x = 0, 4 samples with x = 2 etc</span>
<span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="o">*</span><span class="n">splits</span><span class="p">[</span><span class="s2">&quot;4&quot;</span><span class="p">])</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.1779055922617179
</pre></div>


<h4 id="feature-y">Feature Y<a class="headerlink" href="#feature-y" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Repeat the procedure</p>
</li>
<li>
<p>This time possible thresholds = <span><span class="MathJax_Preview">\{0, 2, 4, 6\}</span><script type="math/tex">\{0, 2, 4, 6\}</script></span></p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Nb</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">No</span> <span class="o">=</span> <span class="mi">15</span>

<span class="n">splits</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;0&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;2&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="s2">&quot;4&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="s2">&quot;6&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">11</span><span class="p">)}</span>

<span class="k">for</span> <span class="n">threshold</span><span class="p">,</span> <span class="p">(</span><span class="n">no</span><span class="p">,</span> <span class="n">nb</span><span class="p">)</span> <span class="ow">in</span> <span class="n">splits</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Threshold = {}</span><span class="se">\t</span><span class="s2"> -&gt; {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="n">no</span><span class="p">,</span> <span class="n">nb</span><span class="p">)))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Threshold = 0    -&gt; 0.02035297064032593
Threshold = 2    -&gt; 0.029594041354123246
Threshold = 4    -&gt; 0.013406861436605633
Threshold = 6    -&gt; 0.0203529706403259
</pre></div>


<ul>
<li>
<p>The best cut is <span><span class="MathJax_Preview">y &gt; 2</span><script type="math/tex">y > 2</script></span> (as predicted before)</p>
</li>
<li>
<p>Lets calculate information gain ratio</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="o">*</span><span class="n">splits</span><span class="p">[</span><span class="s2">&quot;2&quot;</span><span class="p">])</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.01278981522839263
</pre></div>


<h4 id="the-root">The root<a class="headerlink" href="#the-root" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>At the beginning we discussed the choice of <span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span> as a root predictor</p>
</li>
<li>
<p>ID3 and C4.5 are greedy algorithms and select optimal solution at given stage</p>
</li>
<li>
<p>We can start to build the tree with the first best predictor</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">()</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 4?</span><span class="se">\n</span><span class="s2">[15, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[11, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 4?</span><span class="se">\n</span><span class="s2">[15, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span>
</pre></div>


<p><img alt="svg" src="../output_120_0.svg" /></p>
<h4 id="branch-x-4">Branch x &gt; 4<a class="headerlink" href="#branch-x-4" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Now we have to repeat the procedure for the branch <span><span class="MathJax_Preview">[4, 15]</span><script type="math/tex">[4, 15]</script></span></p>
</li>
<li>
<p>Lets take a look what points are left</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">5.5</span><span class="p">,</span> <span class="mf">14.5</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">blue_train</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">orange_train</span><span class="o">.</span><span class="n">T</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_123_0.png" /></p>
<ul>
<li>Check <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> maximum information gain ratio</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Nb</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">No</span> <span class="o">=</span> <span class="mi">15</span>

<span class="n">splits</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;6&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s2">&quot;8&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="s2">&quot;10&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="s2">&quot;12&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">11</span><span class="p">)}</span>

<span class="k">for</span> <span class="n">threshold</span><span class="p">,</span> <span class="p">(</span><span class="n">no</span><span class="p">,</span> <span class="n">nb</span><span class="p">)</span> <span class="ow">in</span> <span class="n">splits</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Threshold = {}</span><span class="se">\t</span><span class="s2"> -&gt; {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="n">no</span><span class="p">,</span> <span class="n">nb</span><span class="p">)))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Threshold = 6    -&gt; 0.051004839414443226
Threshold = 8    -&gt; 0.32143493796317624
Threshold = 10   -&gt; 0.16251125329718286
Threshold = 12   -&gt; 0.08198172064120202
</pre></div>


<div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Information gain ratio with x &gt; 8:&quot;</span><span class="p">,</span>
      <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="o">*</span><span class="n">splits</span><span class="p">[</span><span class="s2">&quot;8&quot;</span><span class="p">])</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Information gain ratio with x &gt; 8: 0.14010311259651076
</pre></div>


<ul>
<li>Check <span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span> maximum information gain ratio</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Nb</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">No</span> <span class="o">=</span> <span class="mi">15</span>

<span class="n">splits</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;0&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s2">&quot;2&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="s2">&quot;4&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="s2">&quot;6&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">9</span><span class="p">)}</span>

<span class="k">for</span> <span class="n">threshold</span><span class="p">,</span> <span class="p">(</span><span class="n">no</span><span class="p">,</span> <span class="n">nb</span><span class="p">)</span> <span class="ow">in</span> <span class="n">splits</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Threshold = {}</span><span class="se">\t</span><span class="s2"> -&gt; {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="n">no</span><span class="p">,</span> <span class="n">nb</span><span class="p">)))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Threshold = 0    -&gt; 0.08471690647404045
Threshold = 2    -&gt; 0.08617499693494635
Threshold = 4    -&gt; 0.06066554625879636
Threshold = 6    -&gt; 0.13320381570773476
</pre></div>


<div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Information gain ratio with y &gt; 6:&quot;</span><span class="p">,</span>
      <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="o">*</span><span class="n">splits</span><span class="p">[</span><span class="s2">&quot;6&quot;</span><span class="p">])</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Information gain ratio with y &gt; 6: 0.05757775370755489
</pre></div>


<ul>
<li>
<p>Once again <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> is a winner</p>
</li>
<li>
<p>And we have a new node</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">()</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 4?</span><span class="se">\n</span><span class="s2">[15, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[11, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 4?</span><span class="se">\n</span><span class="s2">[15, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;[4, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;orange</span><span class="se">\n</span><span class="s2">[0, 11]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span>
</pre></div>


<p><img alt="svg" src="../output_131_0.svg" /></p>
<h4 id="branch-x-8">Branch x&lt;= 8<a class="headerlink" href="#branch-x-8" title="Permanent link">&para;</a></h4>
<ul>
<li>We will continue until the tree is fully grown</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">5.5</span><span class="p">,</span> <span class="mf">8.5</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">blue_train</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">orange_train</span><span class="o">.</span><span class="n">T</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_134_0.png" /></p>
<ul>
<li>Again, the best cut may be pretty obvious, but lets check the math</li>
<li>We have one possible cut in <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span></li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">Nb</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">No</span> <span class="o">=</span> <span class="mi">4</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Information gain ratio with x &gt; 6:&quot;</span><span class="p">,</span>
      <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Information gain ratio with x &gt; 6: 0.05112447853477686
</pre></div>


<ul>
<li>And usual threshold candidates in <span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span></li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">splits</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;0&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">&quot;2&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">&quot;4&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;6&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)}</span>

<span class="k">for</span> <span class="n">threshold</span><span class="p">,</span> <span class="p">(</span><span class="n">no</span><span class="p">,</span> <span class="n">nb</span><span class="p">)</span> <span class="ow">in</span> <span class="n">splits</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Threshold = {}</span><span class="se">\t</span><span class="s2"> -&gt; {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="n">no</span><span class="p">,</span> <span class="n">nb</span><span class="p">)))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Threshold = 0    -&gt; 0.31127812445913283
Threshold = 2    -&gt; 0.5487949406953986
Threshold = 4    -&gt; 0.1887218755408671
Threshold = 6    -&gt; 0.31127812445913283
</pre></div>


<div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Information gain ratio with y &gt; 2:&quot;</span><span class="p">,</span>
      <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="o">*</span><span class="n">splits</span><span class="p">[</span><span class="s2">&quot;2&quot;</span><span class="p">])</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Information gain ratio with y &gt; 2: 0.24390886253128827
</pre></div>


<ul>
<li>And the tree is growing</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">()</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 4?</span><span class="se">\n</span><span class="s2">[15, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[11, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 4?</span><span class="se">\n</span><span class="s2">[15, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;y &gt; 2?</span><span class="se">\n</span><span class="s2">[4, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;orange</span><span class="se">\n</span><span class="s2">[0, 11]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 2?</span><span class="se">\n</span><span class="s2">[4, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[3, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 2?</span><span class="se">\n</span><span class="s2">[4, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;[1, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span>
</pre></div>


<p><img alt="svg" src="../output_141_0.svg" /></p>
<h4 id="branch-y-2">Branch y &gt; 2<a class="headerlink" href="#branch-y-2" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">5.5</span><span class="p">,</span> <span class="mf">8.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">8.5</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">blue_train</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">orange_train</span><span class="o">.</span><span class="n">T</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_143_0.png" /></p>
<div class="codehilite"><pre><span></span><span class="n">Nb</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">No</span> <span class="o">=</span> <span class="mi">4</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Information gain ratio with x &gt; 6:&quot;</span><span class="p">,</span>
      <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Information gain ratio with x &gt; 6: 0.33155970728682876
</pre></div>


<div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Information gain ratio with y &gt; 4:&quot;</span><span class="p">,</span>
      <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Information gain ratio with y &gt; 6:&quot;</span><span class="p">,</span>
      <span class="n">info_gain</span><span class="p">(</span><span class="n">Nb</span><span class="p">,</span> <span class="n">No</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">entropy</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>Information gain ratio with y &gt; 4: 0.047903442721748145
Information gain ratio with y &gt; 6: 0.11232501392736344
</pre></div>


<h4 id="the-final-tree">The final tree<a class="headerlink" href="#the-final-tree" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">()</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 4?</span><span class="se">\n</span><span class="s2">[15, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[11, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 4?</span><span class="se">\n</span><span class="s2">[15, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;y &gt; 2?</span><span class="se">\n</span><span class="s2">[4, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;orange</span><span class="se">\n</span><span class="s2">[0, 11]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 2?</span><span class="se">\n</span><span class="s2">[4, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[3, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 2?</span><span class="se">\n</span><span class="s2">[4, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;x &gt; 6?</span><span class="se">\n</span><span class="s2">[1, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 6?</span><span class="se">\n</span><span class="s2">[1, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;orange</span><span class="se">\n</span><span class="s2">[0, 3]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 6?</span><span class="se">\n</span><span class="s2">[1, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;y &gt; 6?</span><span class="se">\n</span><span class="s2">[1, 1]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 6?</span><span class="se">\n</span><span class="s2">[1, 1]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[1, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 6?</span><span class="se">\n</span><span class="s2">[1, 1]&quot;</span><span class="p">,</span> <span class="s2">&quot;orange</span><span class="se">\n</span><span class="s2">[0, 1]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span>
</pre></div>


<p><img alt="svg" src="../output_147_0.svg" /></p>
<ul>
<li>
<p>It is likely that this tree is overfitted</p>
</li>
<li>
<p>We will proceed with pruning as it was explained</p>
</li>
<li>
<p>But first lets implement decision rules to measure accuracy</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">tree_nominal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Implementation of above tree&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;blue&quot;</span>
  <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">8</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;orange&quot;</span>
  <span class="k">elif</span> <span class="n">y</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;blue&quot;</span>
  <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">6</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;orange&quot;</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;orange&quot;</span> <span class="k">if</span> <span class="n">y</span> <span class="o">&gt;</span> <span class="mi">6</span> <span class="k">else</span> <span class="s2">&quot;blue&quot;</span>
</pre></div>


<h4 id="sanity-check">Sanity check<a class="headerlink" href="#sanity-check" title="Permanent link">&para;</a></h4>
<ul>
<li>If the tree is built <em>correctly</em> we expect 100% accuracy on training set</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">blue_train</span><span class="p">:</span>
  <span class="k">print</span><span class="p">(</span><span class="n">tree_nominal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>blue blue blue blue blue blue blue blue blue blue blue blue blue blue blue
</pre></div>


<div class="codehilite"><pre><span></span><span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">orange_train</span><span class="p">:</span>
  <span class="k">print</span><span class="p">(</span><span class="n">tree_nominal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">)</span> 
</pre></div>


<div class="codehilite"><pre><span></span>orange orange orange orange orange orange orange orange orange orange orange orange orange orange orange
</pre></div>


<h4 id="accuracy-before-pruning">Accuracy before pruning<a class="headerlink" href="#accuracy-before-pruning" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">tree</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Just print the result of classification&quot;&quot;&quot;</span>
  <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;({}, {}) -&gt; {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">tree</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)))</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">blue_valid</span><span class="p">,</span> <span class="n">tree_nominal</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(0, 6) -&gt; blue
(2, 4) -&gt; blue
(4, 0) -&gt; blue
(4, 8) -&gt; blue
(8, 2) -&gt; blue
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">orange_valid</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(8, 4) -&gt; blue
(10, 4) -&gt; orange
(12, 0) -&gt; orange
(12, 8) -&gt; orange
(14, 6) -&gt; orange
</pre></div>


<h4 id="pruning-i">Pruning I<a class="headerlink" href="#pruning-i" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>We want to prune last decision node <span><span class="MathJax_Preview">y &gt; 6</span><script type="math/tex">y > 6</script></span></p>
</li>
<li>
<p>In general, majority decides about the leaf node class</p>
</li>
<li>
<p>As it is a tie here, lets check both</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">tree_prune01a</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Implementation of above tree&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;blue&quot;</span>
  <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">8</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;orange&quot;</span>
  <span class="k">elif</span> <span class="n">y</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;blue&quot;</span>
  <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">6</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;orange&quot;</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;blue&quot;</span>

<span class="k">def</span> <span class="nf">tree_prune01b</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Implementation of above tree&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;blue&quot;</span>
  <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">8</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;orange&quot;</span>
  <span class="k">elif</span> <span class="n">y</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;blue&quot;</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;orange&quot;</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">blue_valid</span><span class="p">,</span> <span class="n">tree_prune01a</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(0, 6) -&gt; blue
(2, 4) -&gt; blue
(4, 0) -&gt; blue
(4, 8) -&gt; blue
(8, 2) -&gt; blue
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">orange_valid</span><span class="p">,</span> <span class="n">tree_prune01a</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(8, 4) -&gt; blue
(10, 4) -&gt; orange
(12, 0) -&gt; orange
(12, 8) -&gt; orange
(14, 6) -&gt; orange
</pre></div>


<ul>
<li>
<p>Pruning does not change the accuracy</p>
</li>
<li>
<p>We always use Occam's razor and <code>prune01a</code> is preferred over nominal tree</p>
</li>
<li>
<p>But lets see how <code>prune01b</code> works</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">blue_valid</span><span class="p">,</span> <span class="n">tree_prune01b</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(0, 6) -&gt; blue
(2, 4) -&gt; blue
(4, 0) -&gt; blue
(4, 8) -&gt; blue
(8, 2) -&gt; blue
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">orange_valid</span><span class="p">,</span> <span class="n">tree_prune01b</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(8, 4) -&gt; orange
(10, 4) -&gt; orange
(12, 0) -&gt; orange
(12, 8) -&gt; orange
(14, 6) -&gt; orange
</pre></div>


<ul>
<li>
<p>In this case we even get the increase of the accuracy</p>
</li>
<li>
<p>We decide to prune a tree by replacing <span><span class="MathJax_Preview">y &gt; 6</span><script type="math/tex">y > 6</script></span> decision node with "orange" leaf node</p>
</li>
<li>
<p>Which automatically removes <span><span class="MathJax_Preview">x &gt; 6</span><script type="math/tex">x > 6</script></span> decision node</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">()</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 4?</span><span class="se">\n</span><span class="s2">[15, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[11, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 4?</span><span class="se">\n</span><span class="s2">[15, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;y &gt; 2?</span><span class="se">\n</span><span class="s2">[4, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &gt; 8?</span><span class="se">\n</span><span class="s2">[4, 15]&quot;</span><span class="p">,</span> <span class="s2">&quot;orange</span><span class="se">\n</span><span class="s2">[0, 11]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 2?</span><span class="se">\n</span><span class="s2">[4, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;blue</span><span class="se">\n</span><span class="s2">[3, 0]&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;y &gt; 2?</span><span class="se">\n</span><span class="s2">[4, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;orange</span><span class="se">\n</span><span class="s2">[1, 4]&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span>
</pre></div>


<p><img alt="svg" src="../output_167_0.svg" /></p>
<h4 id="pruning-ii">Pruning II<a class="headerlink" href="#pruning-ii" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Now, lets see the accuracy after removing <span><span class="MathJax_Preview">y &gt; 2</span><script type="math/tex">y > 2</script></span> node</p>
</li>
<li>
<p>It is once again a tie, so lets check both scenarios</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">tree_prune02a</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Implementation of above tree&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;blue&quot;</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;orange&quot;</span>

<span class="k">def</span> <span class="nf">tree_prune02b</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Implementation of above tree&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">4</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;blue&quot;</span>
  <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">8</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;orange&quot;</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">&quot;blue&quot;</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">blue_valid</span><span class="p">,</span> <span class="n">tree_prune02a</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(0, 6) -&gt; blue
(2, 4) -&gt; blue
(4, 0) -&gt; blue
(4, 8) -&gt; blue
(8, 2) -&gt; orange
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">orange_valid</span><span class="p">,</span> <span class="n">tree_prune02a</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(8, 4) -&gt; orange
(10, 4) -&gt; orange
(12, 0) -&gt; orange
(12, 8) -&gt; orange
(14, 6) -&gt; orange
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">blue_valid</span><span class="p">,</span> <span class="n">tree_prune02b</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(0, 6) -&gt; blue
(2, 4) -&gt; blue
(4, 0) -&gt; blue
(4, 8) -&gt; blue
(8, 2) -&gt; blue
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">accuracy</span><span class="p">(</span><span class="n">orange_valid</span><span class="p">,</span> <span class="n">tree_prune02b</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>(8, 4) -&gt; blue
(10, 4) -&gt; orange
(12, 0) -&gt; orange
(12, 8) -&gt; orange
(14, 6) -&gt; orange
</pre></div>


<ul>
<li>
<p>In both cases the error increased</p>
</li>
<li>
<p>We stop pruning and leave the tree as it is in <code>prune01b</code> version </p>
</li>
</ul>
<h4 id="summary_1">Summary<a class="headerlink" href="#summary_1" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>C4.5 algorithm gives the full and clear prescription for building decision trees</p>
</li>
<li>
<p>It may look as a long procedure, but it is only because I wanted to show everything step by step and avoid <em>"after a few trivial steps..."</em></p>
</li>
<li>
<p>ID3/C4.5/C5.0 are based on information theory</p>
</li>
<li>
<p>There is alternative procedure based on <em>gini impurity</em>, which is used by CART</p>
</li>
</ul>
<h2 id="cart">CART<a class="headerlink" href="#cart" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>CART stands for Classification and Regression Tree</p>
</li>
<li>
<p>It was created independently from ID3 (more or less at the same time)</p>
</li>
<li>
<p>The main differences:</p>
<ul>
<li>
<p>it creates binary trees (each decision node has two branches)</p>
</li>
<li>
<p>it uses gini impurity instead of information gain</p>
</li>
<li>
<p>it supports numerical target variables (regression)</p>
</li>
</ul>
</li>
</ul>
<h3 id="gini-impurity">Gini impurity<a class="headerlink" href="#gini-impurity" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Let <span><span class="MathJax_Preview">T = \{T_1, T_2, ..., T_n\}</span><script type="math/tex">T = \{T_1, T_2, ..., T_n\}</script></span> be the set of <span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> classes</p>
</li>
<li>
<p>and <span><span class="MathJax_Preview">P = \{p_1, p_2, ..., p_n\}</span><script type="math/tex">P = \{p_1, p_2, ..., p_n\}</script></span> be the probability distribution</p>
</li>
<li>
<p>where <span><span class="MathJax_Preview">p_i</span><script type="math/tex">p_i</script></span> is the probability that a sample belongs to class <span><span class="MathJax_Preview">T_i</span><script type="math/tex">T_i</script></span></p>
</li>
<li>
<p>and <span><span class="MathJax_Preview">1 - p_i</span><script type="math/tex">1 - p_i</script></span> is the probability that it belongs to another class</p>
</li>
<li>
<p>Gini impurity is defines as <p align="center"><span><span class="MathJax_Preview">I(P) = \sum\limits_{i=1}^n p_i\cdot (1 - p_i) = \sum\limits_{i=1}^n p_i - \sum\limits_{i=1}^n p_i^2 = 1 - \sum\limits_{i=1}^n p_i^2</span><script type="math/tex">I(P) = \sum\limits_{i=1}^n p_i\cdot (1 - p_i) = \sum\limits_{i=1}^n p_i - \sum\limits_{i=1}^n p_i^2 = 1 - \sum\limits_{i=1}^n p_i^2</script></span></p></p>
</li>
<li>
<p>As before (for entropy), lets consider two case scenario with <span><span class="MathJax_Preview">P = (p, 1 - p)</span><script type="math/tex">P = (p, 1 - p)</script></span>, so gini impurity is given by <span><span class="MathJax_Preview">I = 1 - p^2 - (1 - p)^2 = -2p(p - 1)</span><script type="math/tex">I = 1 - p^2 - (1 - p)^2 = -2p(p - 1)</script></span></p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;p&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;surprise factor&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="o">-</span><span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Entropy&quot;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">p</span><span class="o">*</span><span class="p">(</span><span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gini impurity&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>


<p><img alt="png" src="../output_182_0.png" /></p>
<h3 id="play-golf">Play Golf<a class="headerlink" href="#play-golf" title="Permanent link">&para;</a></h3>
<ul>
<li>Lets consider once again Play Golf dataset</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="c1"># first row = headers</span>
<span class="n">src</span> <span class="o">=</span> <span class="s2">&quot;http://chem-eng.utoronto.ca/~datamining/dmc/datasets/weather_nominal.csv&quot;</span>

<span class="n">golf_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">golf_data</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Outlook</th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Windy</th>
      <th>Play golf</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Rainy</td>
      <td>Hot</td>
      <td>High</td>
      <td>False</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Rainy</td>
      <td>Hot</td>
      <td>High</td>
      <td>True</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Overcast</td>
      <td>Hot</td>
      <td>High</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sunny</td>
      <td>Mild</td>
      <td>High</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Sunny</td>
      <td>Cool</td>
      <td>Normal</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Sunny</td>
      <td>Cool</td>
      <td>Normal</td>
      <td>True</td>
      <td>No</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Overcast</td>
      <td>Cool</td>
      <td>Normal</td>
      <td>True</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Rainy</td>
      <td>Mild</td>
      <td>High</td>
      <td>False</td>
      <td>No</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Rainy</td>
      <td>Cool</td>
      <td>Normal</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Sunny</td>
      <td>Mild</td>
      <td>Normal</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Rainy</td>
      <td>Mild</td>
      <td>Normal</td>
      <td>True</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Overcast</td>
      <td>Mild</td>
      <td>High</td>
      <td>True</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Overcast</td>
      <td>Hot</td>
      <td>Normal</td>
      <td>False</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Sunny</td>
      <td>Mild</td>
      <td>High</td>
      <td>True</td>
      <td>No</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="gini-impurity_1">Gini impurity<a class="headerlink" href="#gini-impurity_1" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>We treat all values as they are continues</p>
</li>
<li>
<p>And consider all possible split</p>
</li>
<li>
<p>Every split leads to two subsets <span><span class="MathJax_Preview">S_1</span><script type="math/tex">S_1</script></span> and <span><span class="MathJax_Preview">S_2</span><script type="math/tex">S_2</script></span></p>
</li>
<li>
<p>And gini impurity for a set <span><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span> for given split is given by: <p align="center"><span><span class="MathJax_Preview">I(S) = \frac{|S_1|}{|S|}\cdot I(S_1) + \frac{|S_2|}{|S|}\cdot I(S_2)</span><script type="math/tex">I(S) = \frac{|S_1|}{|S|}\cdot I(S_1) + \frac{|S_2|}{|S|}\cdot I(S_2)</script></span></p></p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">gini</span><span class="p">(</span><span class="o">*</span><span class="n">distribution</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calculate gini impurity for given ditribution of samples&quot;&quot;&quot;</span>
  <span class="n">sum2</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">distribution</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>  <span class="c1"># normalization factor</span>

  <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">([</span><span class="n">p</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">distribution</span><span class="p">])</span><span class="o">/</span><span class="n">sum2</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">gini_split</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calcualte impurity for given split</span>

<span class="sd">  s1 -- the size of S1 subset</span>
<span class="sd">  s1 -- the size of S2 subset</span>
<span class="sd">  g1 -- I(S1)</span>
<span class="sd">  g2 -- I(S2)</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">s</span> <span class="o">=</span> <span class="n">s1</span> <span class="o">+</span> <span class="n">s2</span>  <span class="c1"># the total set size</span>

  <span class="k">return</span> <span class="n">s1</span><span class="o">/</span><span class="n">s</span> <span class="o">*</span> <span class="n">g1</span> <span class="o">+</span> <span class="n">s2</span><span class="o">/</span><span class="n">s</span> <span class="o">*</span> <span class="n">g2</span>
</pre></div>


<div class="codehilite"><pre><span></span>            | Play golf |
            =============
            | yes | no  |
      -------------------
      | yes |  2  |  3  | 5
rainy | no  |  7  |  2  | 9
      -------------------
               9     5
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">gini_split</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="n">gini</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">gini</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.3936507936507937
</pre></div>


<div class="codehilite"><pre><span></span>            | Play golf |
            =============
            | yes | no  |
      -------------------
      | yes |  3  |  2  | 5
sunny | no  |  6  |  3  | 9
      -------------------
               9     5
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">gini_split</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="n">gini</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">gini</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.45714285714285713
</pre></div>


<div class="codehilite"><pre><span></span>               | Play golf |
               =============
               | yes | no  |
         -------------------
         | yes |  4  |  0  | 4
overcast | no  |  5  |  5  | 10
         -------------------
                  9     5
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">gini_split</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">gini</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">gini</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.35714285714285715
</pre></div>


<ul>
<li>
<p>From <em>Outlook</em> feature the best choice is <em>Overcast</em> as it minimizes impurity</p>
</li>
<li>
<p>However, we would have to check other features and choose the best predictor from all possibilities</p>
</li>
<li>
<p>We have one step by step example done though</p>
</li>
<li>
<p>So lets use some tool</p>
</li>
</ul>
<h3 id="scikit-learn">Scikit learn<a class="headerlink" href="#scikit-learn" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>One step by step example is behind us, so now lets use some tool</p>
</li>
<li>
<p>CART is implemented in <code>scikit-learn</code></p>
</li>
<li>
<p>However, their implementation takes only numerical values</p>
</li>
<li>
<p>So we will use <code>LabelDecoder</code> to convert all values to numbers</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># pandas.DataFrame.apply applies a function to given axis (0 by default)</span>
<span class="c1"># LabelEncoder encodes class labels with values between 0 and n-1</span>
<span class="n">golf_data_num</span> <span class="o">=</span> <span class="n">golf_data</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">golf_data_num</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Outlook</th>
      <th>Temperature</th>
      <th>Humidity</th>
      <th>Windy</th>
      <th>Play golf</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>10</th>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>13</th>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<ul>
<li>Now, lets splits our dataset to features and labels</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># DataFrame.iloc makes an access thourgh indices</span>
<span class="c1"># we want all rows and first 4 columns for features</span>
<span class="c1"># and the last column for labels</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">golf_data_num</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">4</span><span class="p">])</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">golf_data_num</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">4</span><span class="p">])</span>
</pre></div>


<ul>
<li>Once data is prepared, creating a tree is as easy as 2 + 2 -1</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>

<span class="n">golf_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="n">golf_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">);</span>
</pre></div>


<ul>
<li><code>sklearn.tree</code> supports drawing a tree using <code>graphviz</code></li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">graphviz</span>

<span class="c1"># dot is a graph description language</span>
<span class="n">dot</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">golf_tree</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                           <span class="n">feature_names</span><span class="o">=</span><span class="n">golf_data</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="mi">4</span><span class="p">],</span>  
                           <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;no&quot;</span><span class="p">,</span> <span class="s2">&quot;yes&quot;</span><span class="p">],</span>  
                           <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>  
                           <span class="n">special_characters</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> 

<span class="c1"># we create a graph from dot source using graphviz.Source</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot</span><span class="p">)</span> 
<span class="n">graph</span>
</pre></div>


<p><img alt="svg" src="../output_207_0.svg" /></p>
<ul>
<li>Please note, that in the case of a real problem we would want to have a validation set and perform a pruning (<code>scikit-learn</code> does not support it though)</li>
</ul>
<h3 id="regression">Regression<a class="headerlink" href="#regression" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>The difference now is that targets are numerical values (instead of categorical), e.g. in golf data - number of hours played instead of "yes / no"</p>
</li>
<li>
<p>Features may be either discrete or continuous</p>
</li>
<li>
<p>The idea is the same though - we want to create a binary tree and minimize the error on in each leaf</p>
</li>
<li>
<p>However, having continuous values as targets we can not simply use entropy or gini</p>
</li>
<li>
<p>We need to use different measurement - variance <p align="center"><span><span class="MathJax_Preview">V(X) = \frac{1}{n}\sum\limits_{i=1}^n (x_i - \bar x)^2</span><script type="math/tex">V(X) = \frac{1}{n}\sum\limits_{i=1}^n (x_i - \bar x)^2</script></span></p></p>
</li>
<li>
<p>where <span><span class="MathJax_Preview">X = \{x_1, ..., x_n\}</span><script type="math/tex">X = \{x_1, ..., x_n\}</script></span> and <span><span class="MathJax_Preview">\bar x</span><script type="math/tex">\bar x</script></span> is the average value</p>
</li>
<li>
<p>Note, that here <span><span class="MathJax_Preview">x_i</span><script type="math/tex">x_i</script></span> are equally likely</p>
</li>
</ul>
<h4 id="simple-example">Simple example<a class="headerlink" href="#simple-example" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Before we learn how to grow a regression tree, lets take a look how it works on a simple example</p>
</li>
<li>
<p>Lets consider data distributed according to <span><span class="MathJax_Preview">x^2</span><script type="math/tex">x^2</script></span> (with some noise, obviously)</p>
</li>
<li>
<p>It means with have continuous features (<span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>) and targets (<span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span>)</p>
</li>
<li>
<p>We will split by hand the domain in <span><span class="MathJax_Preview">0.3</span><script type="math/tex">0.3</script></span> and <span><span class="MathJax_Preview">0.6</span><script type="math/tex">0.6</script></span></p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span> <span class="s1">&#39;g--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span> <span class="s1">&#39;g--&#39;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_213_0.png" /></p>
<ul>
<li>The corresponding tree would look like this</li>
</ul>
<div class="codehilite"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">Digraph</span><span class="p">()</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &lt; 0.3?&quot;</span><span class="p">,</span> <span class="s2">&quot;?&quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &lt; 0.3?&quot;</span><span class="p">,</span> <span class="s2">&quot;x &lt; 0.6?&quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &lt; 0.6?&quot;</span><span class="p">,</span> <span class="s2">&quot;? &quot;</span><span class="p">,</span> <span class="s2">&quot;No&quot;</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">edge</span><span class="p">(</span><span class="s2">&quot;x &lt; 0.6?&quot;</span><span class="p">,</span> <span class="s2">&quot;?  &quot;</span><span class="p">,</span> <span class="s2">&quot;Yes&quot;</span><span class="p">)</span>

<span class="n">tree</span>
</pre></div>


<p><img alt="svg" src="../output_215_0.svg" /></p>
<ul>
<li>For each split lets find a value <span><span class="MathJax_Preview">\bar y</span><script type="math/tex">\bar y</script></span></li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">avg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return the average value in (x_min, x_max) range&quot;&quot;&quot;</span>
  <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>    <span class="c1"># number of samples in given split </span>
  <span class="n">avg</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># average value</span>

  <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">x_min</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="n">x_max</span><span class="p">:</span>
      <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="n">avg</span> <span class="o">+=</span> <span class="n">y</span>

  <span class="k">return</span> <span class="n">avg</span> <span class="o">/</span> <span class="n">n</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span> <span class="s1">&#39;g--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span> <span class="s1">&#39;g--&#39;</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">avg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">avg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">avg</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_218_0.png" /></p>
<ul>
<li>Alternatively, one could do linear regression for split</li>
</ul>
<h4 id="growing-a-tree">Growing a tree<a class="headerlink" href="#growing-a-tree" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>The idea is similar as for numerical values in classification problems</p>
</li>
<li>
<p>For each feature we check all possible splits and calculate variance</p>
</li>
<li>
<p>We choose a binary split which minimzes variance</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="c1"># create a decision tree regressor</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>

<span class="c1"># and grow it (note that X must be reshaped)</span>
<span class="n">fit</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Y</span><span class="p">);</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># prepare test sample with &quot;newaxis&quot; trick</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_224_0.png" /></p>
<ul>
<li>
<p>And this is a perfect example of <strong>overfitting</strong></p>
</li>
<li>
<p>Each point was <em>classified</em> as a separate target</p>
</li>
<li>
<p>Beacause without any stopping criterion the tree is growing until there is a single point in a leaf</p>
</li>
<li>
<p>There are several strategies to pre-prune a tree:</p>
<ul>
<li>
<p>define a max depth of a tree</p>
</li>
<li>
<p>define a minimum number of samples in a leaf</p>
</li>
<li>
<p>define a minimum impurity</p>
</li>
<li>
<p>define a minimum impurity decrease</p>
</li>
</ul>
</li>
<li>
<p>Whatever method is chosen you get a hyperparameter</p>
</li>
<li>
<p>And we already know how to find an optimal hyperparameter: cross-validation</p>
</li>
</ul>
<h3 id="tree-cross-validation">Tree: cross-validation<a class="headerlink" href="#tree-cross-validation" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>To make it easier to check all possible methods lets create a simple class to do that for us</p>
</li>
<li>
<p>It takes training data and hyperparameter name (as named in <code>scikit-learn</code>)</p>
</li>
<li>
<p>It can change hyperparameter</p>
</li>
<li>
<p>It can perform a cross-validation for a set of hyperparameter values</p>
</li>
<li>
<p>It can make accuracy and best fit plots</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="k">class</span> <span class="nc">TreeCV</span><span class="p">:</span>
  <span class="sd">&quot;&quot;&quot;Perform a cross-validation for chosen hyperparameter&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">hp</span><span class="o">=</span><span class="s2">&quot;max_depth&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Save training data&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>    <span class="c1"># features</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span>    <span class="c1"># targets</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hp</span> <span class="o">=</span> <span class="n">hp</span>  <span class="c1"># hyperparameter</span>


  <span class="k">def</span> <span class="nf">set_method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hp</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Set hyperparameter to use&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hp</span> <span class="o">=</span> <span class="n">hp</span>


  <span class="k">def</span> <span class="nf">cross_me</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">hp_vals</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Perform cross validation for given hyperparameter values&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># the accuracy table</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="bp">None</span>  <span class="c1"># the best fit</span>

    <span class="n">best_score</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">hp</span> <span class="ow">in</span> <span class="n">hp_vals</span><span class="p">:</span>
      <span class="c1"># create a tree with given hyperparameter cut</span>
      <span class="n">fit</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">hp</span><span class="p">:</span> <span class="n">hp</span><span class="p">})</span>

      <span class="c1"># calculate a cross validation scores and a mean value</span>
      <span class="n">score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

      <span class="c1"># update best fit if necessary</span>
      <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">fit</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">hp</span><span class="p">,</span> <span class="n">score</span><span class="p">])</span>

    <span class="c1"># train the best fit</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Y</span><span class="p">)</span>


  <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plot accuracy as a function of hyperparameter values and best fit&quot;&quot;&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hp</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">*</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">scores</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">Y_test</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training data&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">*</span> <span class="n">X_test</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True distribution&quot;</span><span class="p">)</span>    
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Decision tree&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>


<h4 id="traning-dataset">Traning dataset<a class="headerlink" href="#traning-dataset" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>
</pre></div>


<h4 id="max_depth"><code>max_depth</code><a class="headerlink" href="#max_depth" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">tree_handler</span> <span class="o">=</span> <span class="n">TreeCV</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">tree_handler</span><span class="o">.</span><span class="n">cross_me</span><span class="p">(</span><span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">tree_handler</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="../output_232_0.png" /></p>
<h4 id="min_samples_leaf"><code>min_samples_leaf</code><a class="headerlink" href="#min_samples_leaf" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">tree_handler</span><span class="o">.</span><span class="n">set_method</span><span class="p">(</span><span class="s2">&quot;min_samples_leaf&quot;</span><span class="p">)</span>
<span class="n">tree_handler</span><span class="o">.</span><span class="n">cross_me</span><span class="p">(</span><span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">tree_handler</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="../output_234_0.png" /></p>
<h4 id="min_impurity_split"><code>min_impurity_split</code><a class="headerlink" href="#min_impurity_split" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="c1"># min_impurity_split is depracated so lets disable warnings</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">tree_handler</span><span class="o">.</span><span class="n">set_method</span><span class="p">(</span><span class="s2">&quot;min_impurity_split&quot;</span><span class="p">)</span>
<span class="n">tree_handler</span><span class="o">.</span><span class="n">cross_me</span><span class="p">(</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">5e-3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">))</span>
<span class="n">tree_handler</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="../output_237_0.png" /></p>
<h4 id="min_impurity_decrease"><code>min_impurity_decrease</code><a class="headerlink" href="#min_impurity_decrease" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">tree_handler</span><span class="o">.</span><span class="n">set_method</span><span class="p">(</span><span class="s2">&quot;min_impurity_decrease&quot;</span><span class="p">)</span>
<span class="n">tree_handler</span><span class="o">.</span><span class="n">cross_me</span><span class="p">(</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">5e-4</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">))</span>
<span class="n">tree_handler</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="png" src="../output_239_0.png" /></p>
<h2 id="bias-variance-trade-off">Bias-Variance trade-off<a class="headerlink" href="#bias-variance-trade-off" title="Permanent link">&para;</a></h2>
<div class="codehilite"><pre><span></span>        +================+================+
       /\                |                /\
      /  \               |               /  \
     /    \              |              /    \
    /      \             |             /      \
   /        \            |            /        \
  / variance \           |           /   bias   \
  ^^^^^^^^^^^^           |           ^^^^^^^^^^^^
                         |
                         |
                         |
overfitting   &lt;----------+---------&gt;   underfitting
</pre></div>


<ul>
<li>
<p>Bias is an error coming from wrong model assumptions, which do not allow an algorithm to learn all patterns from training data.</p>
</li>
<li>
<p>Variance is an error coming from sensivity to features specific for training data.</p>
</li>
<li>
<p>High bias leads to underfitting and high variance to overfitting.</p>
</li>
<li>
<p>Total error also depends on irreducible error (<em>noise</em> that can not be reduced by algorithm)</p>
</li>
<li>
<p>Ultmiate goal is to minimize the total error</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># fake bias, variance and noise</span>
<span class="n">complexity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">complexity</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">bias2</span> <span class="o">=</span> <span class="n">variance</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">irreducible</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mf">1.5</span><span class="p">),</span> <span class="mf">0.01</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">complexity</span><span class="p">]</span>

<span class="c1"># total error = variance + bias^2 + irreducible</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">variance</span> <span class="o">+</span> <span class="n">bias2</span> <span class="o">+</span> <span class="n">irreducible</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Algorithm complexity&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Error&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">complexity</span><span class="p">,</span> <span class="n">variance</span><span class="p">,</span> <span class="s1">&#39;C0o-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">complexity</span><span class="p">,</span> <span class="n">bias2</span><span class="p">,</span> <span class="s1">&#39;C1o-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Bias^2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">complexity</span><span class="p">,</span> <span class="n">total</span><span class="p">,</span> <span class="s1">&#39;C2o-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Total = Bias^2 + Variance + Irreducible error&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span> <span class="s1">&#39;C3--&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="s2">&quot;$\longleftarrow$ better chance of generalizing&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="s2">&quot;better chance of approximating $\longrightarrow$&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>


<p><img alt="png" src="../output_243_0.png" /></p>
<ul>
<li>
<p>Decision trees are sensitive to splits - small changes in training data may change a tree structure</p>
<ul>
<li>
<p>deep trees tend to have high variance and low bias</p>
</li>
<li>
<p>shallow trees tend to have low variance and high bias</p>
</li>
</ul>
</li>
</ul>
<h3 id="quick-math">Quick math<a class="headerlink" href="#quick-math" title="Permanent link">&para;</a></h3>
<h4 id="basic">Basic<a class="headerlink" href="#basic" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>The general goal of regression is to find how some dependent variable (target, <span><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span>) is changing when independent variable (feature, <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>) varies</p>
</li>
<li>
<p>Lets assume there is some <em>true</em> relationship describing this dependence <span><span class="MathJax_Preview">y = f(x)</span><script type="math/tex">y = f(x)</script></span></p>
</li>
<li>
<p>We want to find <span><span class="MathJax_Preview">f(x)</span><script type="math/tex">f(x)</script></span> from observations of <span><span class="MathJax_Preview">(x, y)</span><script type="math/tex">(x, y)</script></span> pairs</p>
</li>
<li>
<p>Although, in real life we get some noisy observation, so <span><span class="MathJax_Preview">y = f(x) + \epsilon</span><script type="math/tex">y = f(x) + \epsilon</script></span></p>
</li>
<li>
<p>As we do not know function <span><span class="MathJax_Preview">f(x)</span><script type="math/tex">f(x)</script></span> we want to approximate it with some other function <span><span class="MathJax_Preview">g(x)</span><script type="math/tex">g(x)</script></span> (estimator)</p>
</li>
<li>
<p>In general, <span><span class="MathJax_Preview">g(x)</span><script type="math/tex">g(x)</script></span> is a parametrized model which can take many possible functional form</p>
<ul>
<li>e.g. <span><span class="MathJax_Preview">g(x) = a\cdot x^2 + b\cdot x + c</span><script type="math/tex">g(x) = a\cdot x^2 + b\cdot x + c</script></span> can take different coefficients (based on a training dataset)</li>
</ul>
</li>
</ul>
<h4 id="bias-and-variance">Bias and variance<a class="headerlink" href="#bias-and-variance" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Lets imagine there are <span><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span> possible training datasets <span><span class="MathJax_Preview">\{D_1, D_2, ..., D_N\}</span><script type="math/tex">\{D_1, D_2, ..., D_N\}</script></span></p>
</li>
<li>
<p>For a given dataset one gets an estimators <span><span class="MathJax_Preview">g^{(D)}(x)</span><script type="math/tex">g^{(D)}(x)</script></span></p>
</li>
<li>
<p>Lets denote the expected estimator by <span><span class="MathJax_Preview">\mathbf{E}_{D}\left[g^{(D)}(x)\right] \equiv \bar g(x)</span><script type="math/tex">\mathbf{E}_{D}\left[g^{(D)}(x)\right] \equiv \bar g(x)</script></span></p>
</li>
<li>
<p>If <span><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span> is large we can approximate it by an average over all datasets (law of large numbers) <p align="center"><br><span><span class="MathJax_Preview">\bar g(x) \approx \frac{1}{N}\sum\limits_{i=1}^N g^{(D_i)}(x)</span><script type="math/tex">\bar g(x) \approx \frac{1}{N}\sum\limits_{i=1}^N g^{(D_i)}(x)</script></span></p><br></p>
</li>
<li>
<p>The <strong>variance</strong> of an estimator tells us how far particular predictions are from the mean value <p align="center"><br><span><span class="MathJax_Preview">var = \mathbf{E}_{D}\left[\left(g^{(D)}(x) - \bar g(x)\right)^2\right]</span><script type="math/tex">var = \mathbf{E}_{D}\left[\left(g^{(D)}(x) - \bar g(x)\right)^2\right]</script></span></p><br></p>
</li>
<li>
<p>Thus, if the training does not depend on the choice of a dataset the variance is low</p>
</li>
<li>
<p>The <strong>bias</strong> of an estimator tells us how far the mean value is from the true value <p align="center"><br><span><span class="MathJax_Preview">bias = \bar g(x) - f(x)</span><script type="math/tex">bias = \bar g(x) - f(x)</script></span></p><br></p>
</li>
<li>
<p>Thus, if the model decribes data accurately the bias is low</p>
</li>
<li>
<p>Please note the hidden assumption that all possible values of <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> are equally likely</p>
</li>
</ul>
<h4 id="goodness-of-a-model">Goodness of a model<a class="headerlink" href="#goodness-of-a-model" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>The common practice to determine the goodness of a model fit is to calculate mean squared error</p>
</li>
<li>
<p>The mean squared error is, well, the mean value of error squared: <p align="center"><br><span><span class="MathJax_Preview">mse = \mathbf{E}_{x}\left[\mathbf{E}_{D}\left[\left(g^{(D)}(x) - y\right)^2\right]\right]</span><script type="math/tex">mse = \mathbf{E}_{x}\left[\mathbf{E}_{D}\left[\left(g^{(D)}(x) - y\right)^2\right]\right]</script></span></p><br></p>
</li>
<li>
<p>Lets consider MSE for a particlar point <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>, <span><span class="MathJax_Preview">y = f(x) + \epsilon</span><script type="math/tex">y = f(x) + \epsilon</script></span>, so <p align="center"><br><span><span class="MathJax_Preview">mse = \mathbf{E}_{D}\left[\left(g^{(D)}(x) - y\right)^2\right] = \mathbf{E}_{D}\left[\left(g^{(D)}(x)\right)^2\right]- 2\cdot\mathbf{E}_{D}\left[g^{(D)}(x)\cdot y\right] + \mathbf{E}_{D}\left[y^2\right]</span><script type="math/tex">mse = \mathbf{E}_{D}\left[\left(g^{(D)}(x) - y\right)^2\right] = \mathbf{E}_{D}\left[\left(g^{(D)}(x)\right)^2\right]- 2\cdot\mathbf{E}_{D}\left[g^{(D)}(x)\cdot y\right] + \mathbf{E}_{D}\left[y^2\right]</script></span></p><br></p>
</li>
<li>
<p>Here, we used the linearity of the expected value operator. Lets use another common property: <span><span class="MathJax_Preview">\mathbf{E}\left[X^2\right] = \mathbf{E}\left[\left(X - \mathbf{E}\left[X\right]\right)^2\right] + \mathbf{E}\left[X\right]^2</span><script type="math/tex">\mathbf{E}\left[X^2\right] = \mathbf{E}\left[\left(X - \mathbf{E}\left[X\right]\right)^2\right] + \mathbf{E}\left[X\right]^2</script></span> </p>
</li>
<li>
<p>So the first term can be rewritten in the form <p align="center"><br><span><span class="MathJax_Preview">\mathbf{E}_{D}\left[\left(g^{(D)}(x)\right)^2\right] = \mathbf{E}_{D}\left[\left(g^{(D)}(x) - \mathbf{E}_{D}\left[g^{(D)}(x)\right]\right)^2\right] + \mathbf{E}_{D}\left[g^{(D)}(x)\right]^2 = \mathbf{E}_{D}\left[\left(g^{(D)}(x) - \bar g(x)\right)^2\right] + \left(\bar g(x)\right)^2</span><script type="math/tex">\mathbf{E}_{D}\left[\left(g^{(D)}(x)\right)^2\right] = \mathbf{E}_{D}\left[\left(g^{(D)}(x) - \mathbf{E}_{D}\left[g^{(D)}(x)\right]\right)^2\right] + \mathbf{E}_{D}\left[g^{(D)}(x)\right]^2 = \mathbf{E}_{D}\left[\left(g^{(D)}(x) - \bar g(x)\right)^2\right] + \left(\bar g(x)\right)^2</script></span></p><br></p>
</li>
<li>
<p>And the last term <p align="center"><br><span><span class="MathJax_Preview">\mathbf{E}_{D}\left[y^2\right] = \mathbf{E}_{D}\left[\left(y - \mathbf{E}_{D}\left[y\right]\right)^2\right] + \mathbf{E}_{D}\left[y\right]^2 = \mathbf{E}_{D}\left[\left(y - f(x)\right)^2\right] + \left(f(x)\right)^2</span><script type="math/tex">\mathbf{E}_{D}\left[y^2\right] = \mathbf{E}_{D}\left[\left(y - \mathbf{E}_{D}\left[y\right]\right)^2\right] + \mathbf{E}_{D}\left[y\right]^2 = \mathbf{E}_{D}\left[\left(y - f(x)\right)^2\right] + \left(f(x)\right)^2</script></span></p><br></p>
</li>
<li>
<p>Here, we used the fact that <span><span class="MathJax_Preview">\mathbf{E}_{D}\left[y\right] = f(x)</span><script type="math/tex">\mathbf{E}_{D}\left[y\right] = f(x)</script></span> (noise would average out when averaging over <em>infinite</em> number of datasets)</p>
</li>
<li>
<p>For the middle term we use the fact that for independent <span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span> and <span><span class="MathJax_Preview">Y</span><script type="math/tex">Y</script></span>: <span><span class="MathJax_Preview">\mathbf{E}\left[XY\right] = \mathbf{E}\left[X\right]\cdot\mathbf{E}\left[Y\right]</span><script type="math/tex">\mathbf{E}\left[XY\right] = \mathbf{E}\left[X\right]\cdot\mathbf{E}\left[Y\right]</script></span>, so <span><span class="MathJax_Preview">\mathbf{E}_{D}\left[g^{(D)}(x)\cdot y\right] = \bar g(x)\cdot f(x)</span><script type="math/tex">\mathbf{E}_{D}\left[g^{(D)}(x)\cdot y\right] = \bar g(x)\cdot f(x)</script></span></p>
</li>
<li>
<p>Taking all together we get <p align="center"><br><span><span class="MathJax_Preview">mse = \underbrace{\mathbf{E}_{D}\left[\left(g^{(D)}(x) - \bar g(x)\right)^2\right]}_{variance} + \underbrace{\left(\bar g(x) - f(x)\right)^2}_{bias^2} + \underbrace{\mathbf{E}_{D}\left[\left(y - f(x)\right)^2\right]}_{noise}</span><script type="math/tex">mse = \underbrace{\mathbf{E}_{D}\left[\left(g^{(D)}(x) - \bar g(x)\right)^2\right]}_{variance} + \underbrace{\left(\bar g(x) - f(x)\right)^2}_{bias^2} + \underbrace{\mathbf{E}_{D}\left[\left(y - f(x)\right)^2\right]}_{noise}</script></span></p><br></p>
</li>
</ul>
<h3 id="example_4">Example<a class="headerlink" href="#example_4" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Lets consider <span><span class="MathJax_Preview">f(x) = \sin(\pi x)</span><script type="math/tex">f(x) = \sin(\pi x)</script></span></p>
</li>
<li>
<p>With a noise given by a zero-mean Gaussian with a variance <span><span class="MathJax_Preview">\sigma^2</span><script type="math/tex">\sigma^2</script></span></p>
</li>
<li>
<p>So the observation <span><span class="MathJax_Preview">y = f(x) + \mathcal{N}(0, \sigma^2)</span><script type="math/tex">y = f(x) + \mathcal{N}(0, \sigma^2)</script></span></p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sin</span><span class="p">,</span> <span class="n">cos</span><span class="p">,</span> <span class="n">pi</span><span class="p">,</span> <span class="n">exp</span>

<span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Generate N training samples&quot;&quot;&quot;</span>
  <span class="c1"># X is a set of random points from [-1, 1]</span>
  <span class="n">X</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
  <span class="c1"># Y are corresponding target values (with noise included)</span>
  <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">sin</span><span class="p">(</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>

<span class="c1"># plot a sample</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">get_dataset</span><span class="p">()</span>

<span class="n">x_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_</span><span class="p">),</span> <span class="s1">&#39;C0--&#39;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_254_0.png" /></p>
<ul>
<li>
<p>We do not know <span><span class="MathJax_Preview">f(x)</span><script type="math/tex">f(x)</script></span></p>
</li>
<li>
<p>We assume it is a polynomial</p>
</li>
<li>
<p>Lets consider polynomials of orders: <span><span class="MathJax_Preview">1 - 9</span><script type="math/tex">1 - 9</script></span></p>
<ul>
<li>
<p><span><span class="MathJax_Preview">g_1(x) = a_1\cdot x + a_0</span><script type="math/tex">g_1(x) = a_1\cdot x + a_0</script></span></p>
</li>
<li>
<p><span><span class="MathJax_Preview">g_2(x) = a_2\cdot x^2 + \cdots + a_0</span><script type="math/tex">g_2(x) = a_2\cdot x^2 + \cdots + a_0</script></span></p>
</li>
<li>
<p><span><span class="MathJax_Preview">g_3(x) = a_3\cdot x^3 + \cdots + a_0</span><script type="math/tex">g_3(x) = a_3\cdot x^3 + \cdots + a_0</script></span></p>
</li>
<li>
<p>...</p>
</li>
</ul>
</li>
<li>
<p>Lets assume we have 100 independent dataset</p>
</li>
<li>
<p>Each one has 20 points <span><span class="MathJax_Preview">(x, y = \sin(\pi x) + \mathcal{N}(0, \sigma^2))</span><script type="math/tex">(x, y = \sin(\pi x) + \mathcal{N}(0, \sigma^2))</script></span></p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># generate 100 datasets with default settings</span>
<span class="n">datasets</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_dataset</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)]</span>

<span class="c1"># and plot them all together with true signal</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">datasets</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_</span><span class="p">),</span> <span class="s1">&#39;C0--&#39;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_256_0.png" /></p>
<ul>
<li>Now we need to fit each polynomial to each dataset separately</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_fit</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Find a fit of polynomial of order N to data = (X, Y)&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">N</span><span class="p">))</span>

<span class="c1"># for the whole range of possible polynomials orders</span>
<span class="c1"># create a list of fits to different datasets</span>
<span class="n">fits</span> <span class="o">=</span> <span class="p">[[</span><span class="n">get_fit</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">]</span> <span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)]</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">])</span>

  <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">fits</span><span class="p">[</span><span class="n">order</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">g</span><span class="p">(</span><span class="n">x_</span><span class="p">),</span> <span class="s1">&#39;C1-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_</span><span class="p">),</span> <span class="s1">&#39;C0--&#39;</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Polynomial of order {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">order</span><span class="p">));</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span>
</pre></div>


<p><img alt="png" src="../output_259_0.png" /></p>
<h3 id="training-and-test-errors">Training and test errors<a class="headerlink" href="#training-and-test-errors" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>In real life is impossible (unless one creates data by hand) to calculate true variance and bias</p>
</li>
<li>
<p>One would need all possible datasets <span><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span> and all possible input values <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span></p>
</li>
<li>
<p>Thus, usually one looks at training and test errors</p>
<ul>
<li>
<p>Training error is measured on the data used to make a fit</p>
</li>
<li>
<p>Test/validation error is measured on unseen data</p>
</li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># fake error</span>
<span class="n">complexity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">train_error</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">complexity</span><span class="p">)</span>
<span class="n">test_error</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">complexity</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">complexity</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Algorithm complexity&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Error&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">complexity</span><span class="p">,</span> <span class="n">train_error</span><span class="p">,</span> <span class="s1">&#39;C0o-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">complexity</span><span class="p">,</span> <span class="n">test_error</span><span class="p">,</span> <span class="s1">&#39;C1o-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test error&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s2">&quot;$\longleftarrow$ high bias&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="s2">&quot;high variance $\longrightarrow$&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>


<p><img alt="png" src="../output_262_0.png" /></p>
<ul>
<li>
<p>High training error indicates high bias (which means underfitting)</p>
</li>
<li>
<p>Training error must decrease with model complexity</p>
</li>
<li>
<p>If the training error is high:</p>
<ul>
<li>
<p>Use more complex model (or new model architecture)</p>
</li>
<li>
<p>Use more features - maybe there is just not enough information to make a good prediction</p>
</li>
<li>
<p>Train longer (if the algorithm is an iterative optimization problem)</p>
</li>
<li>
<p>Decrease regularization (next lecture)</p>
</li>
</ul>
</li>
<li>
<p>Test error deacreses with model complexity up to a point when algorithm is to sensitive to features seen in training data</p>
</li>
<li>
<p>If test error starts to increase it indicates high variance (which means overfitting)</p>
</li>
<li>
<p>If test error is high:</p>
<ul>
<li>
<p>Use more data - easy to say hard to do...</p>
</li>
<li>
<p>Use less features</p>
</li>
<li>
<p>Increase regularization </p>
</li>
<li>
<p>Use different model</p>
</li>
</ul>
</li>
</ul>
<h2 id="ensemble-learning">Ensemble learning<a class="headerlink" href="#ensemble-learning" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>Lets first define a <em>weak learner</em> as a classifier which is just slighlty better than random guessing</p>
</li>
<li>
<p>The idea behind ensemble learning is to create a <em>strong learner</em> as a combination of many <em>weak learners</em></p>
</li>
<li>
<p>We will discuss two popular ensemble methods:</p>
<ul>
<li>
<p>Bagging (<strong>b</strong>ootstrap <strong>agg</strong>regat<strong>ing</strong>), e.g. random forest</p>
</li>
<li>
<p>Boosting, e.g. boosted decision tress</p>
</li>
</ul>
</li>
</ul>
<h3 id="random-forest">Random forest<a class="headerlink" href="#random-forest" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Once we know a way to produce a tree we can create a forest</p>
</li>
<li>
<p>And each tree contributes to a final prediction</p>
</li>
<li>
<p>It is a <em>random</em> forest, because each tree is randomly <em>incomplete</em> - trained only on a random subsets of samples and features (<em>features bagging</em>)</p>
</li>
<li>
<p>The final prediction of a random forest is an avearge predictions (for regression) or a majority vote (classification)</p>
</li>
</ul>
<h4 id="intuitive-naive-example">Intuitive / naive example<a class="headerlink" href="#intuitive-naive-example" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Imagine you want to go to a cinema and need to choose a movie to watch</p>
</li>
<li>
<p>You can ask a friend about the recommendation</p>
<ul>
<li>
<p>She/he would ask you about movies you watched in the past</p>
</li>
<li>
<p>and (based on your answers) create a set of rules (a decision tree)</p>
</li>
<li>
<p>to finally recommend you a movie (make a prediction)</p>
</li>
</ul>
</li>
<li>
<p>Alternatively, you can ask many friends for an advice</p>
<ul>
<li>
<p>Each friend would ask you random questions to give an answer</p>
</li>
<li>
<p>At the end, you choose a movie with most votes</p>
</li>
</ul>
</li>
</ul>
<h4 id="the-algorithm">The algorithm<a class="headerlink" href="#the-algorithm" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>Lets imagine we have <span><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span> samples in our dataset (e.g. <span><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span> movies you watched)</p>
</li>
<li>
<p>Each sample has <span><span class="MathJax_Preview">M</span><script type="math/tex">M</script></span> features (e.g. do you like a movie? do you like the leading actor / actress or director?)</p>
</li>
<li>
<p>To create a tree take <span><span class="MathJax_Preview">n</span><script type="math/tex">n</script></span> random samples from the dataset and <strong>at each node</strong> select <span><span class="MathJax_Preview">m &lt;&lt; M</span><script type="math/tex">m << M</script></span> features (<span><span class="MathJax_Preview">m \sim \sqrt M</span><script type="math/tex">m \sim \sqrt M</script></span>) to find the best predictor</p>
</li>
<li>
<p>Repeat the procedure for next trees until you reach desired size of a forest</p>
</li>
</ul>
<div class="codehilite"><pre><span></span>                    +------------+
                    |            |
                    |   Dataset  |
         +----------+            +----------+
         |          | N features |          |
         |          |            |          |
         v          +------------+          v                    Hyperparameters:

+-----------------+                 +-----------------+
|                 |                 |                 |
| Random subset 1 |      . . .      | Random subset T |
|                 |                 |                 |              - the number of trees
|   N features    |                 |   N features    |              - the size of subsets
|                 |                 |                 |
+--------+--------+                 +--------+--------+
         |                                   |
         v                                   v

+-----------------+                 +-----------------+
|                 |                 |                 |
|     Tree 1      |      . . .      |     Tree T      |
|                 |                 |                 |
+--------+--------+                 +-----------------+
         |
         |          +-------------+          +--------+
         |          |             |          |        |
         +--------&gt; | M1 features +--------&gt; | Node 1 |              - the number of random features
         |          |             |          |        |              - the size of a single tree
         |          +-------------+          +--------+
         |
         |          +-------------+          +--------+
         |          |             |          |        |
         +--------&gt; | M2 features +--------&gt; | Node 2 |
         |          |             |          |        |
         |          +-------------+          +--------+

                           .
                           .
                           .
</pre></div>


<h3 id="boosted-trees">Boosted trees<a class="headerlink" href="#boosted-trees" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>The idea is similar to bagging</p>
</li>
<li>
<p>The key differences are:</p>
<ul>
<li>
<p>Data is reweighted every time a <em>weak learner</em> is added (so future learners focus on misclassified samples)</p>
</li>
<li>
<p>The final prediction is weighted average (better classifiers have higher weights)</p>
</li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span>                            Bagging (parallel)

       +--------------------+                +----------------+
       |                    |                |                |
+----&gt; |      Dataset       +--------------&gt; | Weak learner 1 |
|      |                    |                |                |
|      +--------------------+                +----------------+
|
|
|      +--------------------+                +----------------+
|      |                    |                |                |
+----&gt; |      Dataset       +-------------&gt;  | Weak learner 2 |
|      |                    |                |                |
|      +--------------------+       .        +----------------+
|                                   .
|                                   .
|      +--------------------+                +----------------+
|      |                    |                |                |
+----&gt; |      Dataset       +-------------&gt;  | Weak learner N |
       |                    |                |                |
       +--------------------+                +----------------+
</pre></div>


<p><span><span class="MathJax_Preview">\hspace{140pt}\text{output} = \frac{1}{N}\sum \text{output}_i</span><script type="math/tex">\hspace{140pt}\text{output} = \frac{1}{N}\sum \text{output}_i</script></span> </p>
<hr>

<div class="codehilite"><pre><span></span>                          Boosting (sequential)

      +--------------------+                +----------------+
      |                    |                |                |
      |      Dataset       +--------------&gt; | Weak learner 1 |
      |                    |                |                |
      +--------------------+                +--------+-------+
                                                     |
                +------------------------------------+
                |
                v

      +--------------------+                +----------------+
      |                    |                |                |
      | Reweighted dataset +-------------&gt;  | Weak learner 2 |
      |                    |                |                |
      +--------------------+                +--------+-------+
                                                     |
                +------------     . . .      --------+
                |
                v

      +--------------------+                +----------------+
      |                    |                |                |
      | Reweighted dataset +-------------&gt;  | Weak learner N |
      |                    |                |                |
      +--------------------+                +----------------+
</pre></div>


<p><span><span class="MathJax_Preview">\hspace{130pt}\text{output} = \sum w_i\cdot \text{output}_i</span><script type="math/tex">\hspace{130pt}\text{output} = \sum w_i\cdot \text{output}_i</script></span> </p>
<h4 id="adaboost">AdaBoost<a class="headerlink" href="#adaboost" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>AdaBoost is on of the most famous algorithms in machine learning</p>
</li>
<li>
<p>Y. Freund and R. Schapire got a Gödel Prize for this</p>
</li>
<li>
<p>Lets consider <span><span class="MathJax_Preview">N</span><script type="math/tex">N</script></span> labled training examples <span><span class="MathJax_Preview">(x_1, y_1), \cdots, (x_N, y_N)</span><script type="math/tex">(x_1, y_1), \cdots, (x_N, y_N)</script></span>, where <span><span class="MathJax_Preview">x_i \in X</span><script type="math/tex">x_i \in X</script></span> and <span><span class="MathJax_Preview">y_i = \left\{-1, 1\right\}</span><script type="math/tex">y_i = \left\{-1, 1\right\}</script></span></p>
</li>
<li>
<p>The initial distribution is initizlized with <span><span class="MathJax_Preview">D_1(i) = \frac{1}{N}</span><script type="math/tex">D_1(i) = \frac{1}{N}</script></span>, where <span><span class="MathJax_Preview">i = 1, \cdots, N</span><script type="math/tex">i = 1, \cdots, N</script></span> (so every sample is equaly likely)</p>
</li>
<li>
<p>For <span><span class="MathJax_Preview">t = 1, \cdots, T</span><script type="math/tex">t = 1, \cdots, T</script></span>:</p>
<ul>
<li>
<p>train a weak learner using <span><span class="MathJax_Preview">D_t</span><script type="math/tex">D_t</script></span>, <span><span class="MathJax_Preview">h_t: X \rightarrow \left\{-1, 1\right\}</span><script type="math/tex">h_t: X \rightarrow \left\{-1, 1\right\}</script></span></p>
</li>
<li>
<p>choose the one which minimizes the weighted error <p align="center"><span><span class="MathJax_Preview">\epsilon_t = \sum\limits_{i=1}^{N}D_t(i)\delta\left(h_t(x_i)\neq y_i\right)</span><script type="math/tex">\epsilon_t = \sum\limits_{i=1}^{N}D_t(i)\delta\left(h_t(x_i)\neq y_i\right)</script></span></p></p>
</li>
<li>
<p>calculate <span><span class="MathJax_Preview">\alpha_t</span><script type="math/tex">\alpha_t</script></span> <p align="center"><span><span class="MathJax_Preview">\alpha_t = \frac{1}{2}\ln\left(\frac{1 - \epsilon_t}{\epsilon_t}\right)</span><script type="math/tex">\alpha_t = \frac{1}{2}\ln\left(\frac{1 - \epsilon_t}{\epsilon_t}\right)</script></span></p></p>
</li>
<li>
<p>For <span><span class="MathJax_Preview">i = 1, \cdots, N</span><script type="math/tex">i = 1, \cdots, N</script></span> update weights according to <p align="center"><span><span class="MathJax_Preview">D_{t+1} = \frac{D_t(i)}{Z_t}\begin{cases}e^{-\alpha_t} &amp; h_t(x_i) = y_i \\ e^{\alpha_t} &amp; h_t(x_i) \neq y_i \end{cases} = \frac{D_t(i)}{Z_t}e^{-\alpha_ty_ih_t(x_i)}</span><script type="math/tex">D_{t+1} = \frac{D_t(i)}{Z_t}\begin{cases}e^{-\alpha_t} & h_t(x_i) = y_i \\ e^{\alpha_t} & h_t(x_i) \neq y_i \end{cases} = \frac{D_t(i)}{Z_t}e^{-\alpha_ty_ih_t(x_i)}</script></span></p></p>
</li>
<li>
<p><span><span class="MathJax_Preview">Z_t</span><script type="math/tex">Z_t</script></span> is a normilization factor so <span><span class="MathJax_Preview">D_{t+1}</span><script type="math/tex">D_{t+1}</script></span> is a distribution <p align="center"><span><span class="MathJax_Preview">Z_t = \sum\limits_{i=1}^ND_t(i)e^{-\alpha_ty_ih_t(x_i)}</span><script type="math/tex">Z_t = \sum\limits_{i=1}^ND_t(i)e^{-\alpha_ty_ih_t(x_i)}</script></span></p></p>
</li>
</ul>
</li>
<li>
<p>The final hyptohesis <span><span class="MathJax_Preview">H</span><script type="math/tex">H</script></span> is computes the sign of a weighted combination of weak hypotheses <p align="center"><span><span class="MathJax_Preview">H(x) = \text{sign}\left(\sum\limits_{t=1}^T\alpha_th_t(x)\right)</span><script type="math/tex">H(x) = \text{sign}\left(\sum\limits_{t=1}^T\alpha_th_t(x)\right)</script></span></p> </p>
</li>
</ul>
<h3 id="out-of-bag-error">Out-of-bag error<a class="headerlink" href="#out-of-bag-error" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Out-of-bag (OOB) error may be used for machine learning models using bootstrap aggregation (like random forest and boosted trees) instead of cross-validation</p>
</li>
<li>
<p>Bagging involves random sampling with replacement</p>
</li>
<li>
<p>Some samples are not used in the training process (out-of-bag samples) and therefore can be used to calculate test error</p>
</li>
<li>
<p>OOB error is the average error over all training samples calculated using predictions from weak classifiers which do not contain particular sample in their bootstrap samples</p>
</li>
</ul>
<h3 id="example_5">Example<a class="headerlink" href="#example_5" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Lets consider some fake data generated with <code>make_blobs</code> from <code>scikit-learn</code></p>
</li>
<li>
<p>and then apply decision trees with different maximum depths</p>
</li>
<li>
<p>and random forests with different maximum depths</p>
</li>
</ul>
<h4 id="dataset">Dataset<a class="headerlink" href="#dataset" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p><code>sklearn.datasets.make_blobs</code> allows to generate random Gaussian blobs</p>
</li>
<li>
<p>We generate 8 blobs with fixed random generator (just to make sure we get the same set every time)</p>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="c1"># generate 5 blobs with fixed random generator</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Dark2&#39;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="../output_288_0.png" /></p>
<h4 id="train-and-visualize">Train and visualize<a class="headerlink" href="#train-and-visualize" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>To make our life easier we create a function to</p>
<ul>
<li>
<p>plot training data on existing axes or new one (if not provided)</p>
</li>
<li>
<p>train given classifier on given dataset</p>
</li>
<li>
<p>create countours representing predictions of the classifier</p>
</li>
</ul>
</li>
</ul>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train_and_look</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Dark2&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Train classifier on (X,Y). Plot data and prediction.&quot;&quot;&quot;</span>
  <span class="c1"># create new axis if not provided</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span> <span class="ow">or</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">();</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

  <span class="c1"># plot training data</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>

  <span class="c1"># train a cliassifier</span>
  <span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

  <span class="c1"># create a grid of testing points</span>
  <span class="n">x_</span><span class="p">,</span> <span class="n">y_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">*</span><span class="n">ax</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">(),</span> <span class="n">num</span><span class="o">=</span><span class="mi">200</span><span class="p">),</span>
                       <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">*</span><span class="n">ax</span><span class="o">.</span><span class="n">get_ylim</span><span class="p">(),</span> <span class="n">num</span><span class="o">=</span><span class="mi">200</span><span class="p">))</span>

  <span class="c1"># convert to an array of 2D points</span>
  <span class="n">test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">x_</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>

  <span class="c1"># make a prediction and reshape to grid structure </span>
  <span class="n">z_</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

  <span class="c1"># arange z bins so class labels are in the middle</span>
  <span class="n">z_levels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>

  <span class="c1"># plot contours corresponding to classifier prediction</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">y_</span><span class="p">,</span> <span class="n">z_</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">z_levels</span><span class="p">)</span>
</pre></div>


<ul>
<li>Let check how it works on a decision tree classifier with default <code>sklearn</code> setting</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span> <span class="k">as</span> <span class="n">DT</span>

<span class="n">train_and_look</span><span class="p">(</span><span class="n">DT</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="../output_293_0.png" /></p>
<h4 id="decision-tree">Decision tree<a class="headerlink" href="#decision-tree" title="Permanent link">&para;</a></h4>
<ul>
<li>We consider decision trees with fixed maximum depths from 1 to 9</li>
</ul>
<div class="codehilite"><pre><span></span><span class="c1"># create a figure with 9 axes 3x3</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>

<span class="c1"># train and look at decision trees with different max depth</span>
<span class="k">for</span> <span class="n">max_depth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">9</span><span class="p">):</span>
  <span class="n">train_and_look</span><span class="p">(</span><span class="n">DT</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span>
                 <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">max_depth</span> <span class="o">//</span> <span class="mi">3</span><span class="p">][</span><span class="n">max_depth</span> <span class="o">%</span> <span class="mi">3</span><span class="p">],</span>
                 <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Max depth = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>


<p><img alt="png" src="../output_296_0.png" /></p>
<ul>
<li><code>max_depth</code> &lt;= 3 - undefitting</li>
<li><code>max_depth</code> &lt;= 6 - quite good</li>
<li><code>max_depth</code>  &gt; 6 - overfitting</li>
</ul>
<h4 id="random-forest_1">Random forest<a class="headerlink" href="#random-forest_1" title="Permanent link">&para;</a></h4>
<ul>
<li>Lets do the same with random forests (100 trees in each forest)</li>
</ul>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span> <span class="k">as</span> <span class="n">RF</span>

<span class="c1"># create a figure with 9 axes 3x3</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>

<span class="c1"># train and look at decision trees with different max depth</span>
<span class="k">for</span> <span class="n">max_depth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">9</span><span class="p">):</span>
  <span class="n">train_and_look</span><span class="p">(</span><span class="n">RF</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span>
                 <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">max_depth</span> <span class="o">//</span> <span class="mi">3</span><span class="p">][</span><span class="n">max_depth</span> <span class="o">%</span> <span class="mi">3</span><span class="p">],</span>
                 <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Max depth = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>


<p><img alt="png" src="../output_300_0.png" /></p>
<ul>
<li>
<p>The combination of shallow trees (weak learners) does a good job</p>
</li>
<li>
<p>Overfitting is somehow prevented </p>
</li>
</ul>
<h2 id="summary_2">Summary<a class="headerlink" href="#summary_2" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>The most important lesson today: <strong>bias-variance trade-off</strong></p>
<ul>
<li>
<p>For the lecture easy examples are chosen so they can be visualize</p>
</li>
<li>
<p>In real life problems, it is hard / impossible to determine using "bye eye" method if the model is underfitted or overfitted</p>
</li>
<li>
<p>Note, that actually you should never used this method even if you think "your eye" is right - you would be surprised how it is not</p>
</li>
<li>
<p>One needs a way to measure the goodnes of a model - usually mean squared error</p>
</li>
<li>
<p>In practice, most people use cross-calidation technique </p>
</li>
</ul>
</li>
<li>
<p>The biggest advantages of decision trees algoritms is that they are east to interpret (it is easy to explain even to non-experts how they work, which is not the case with e.g. deep neural networks)</p>
</li>
<li>
<p>Usually, decision trees are used as weak learners in ensemble learning</p>
</li>
<li>
<p>The most famous boosting algorithm is AdaBoost, because it is a good one and the first one. Although, there are many other boosting methods on market right now with XGBoost being one of the most popular one</p>
</li>
<li>
<p>As for today, deep learning has better publicity, but boosted trees are still one of the most common algorithms used in <a href="https://www.kaggle.com/">Kaggle competitions</a></p>
</li>
<li>
<p>Boosted trees are also popular among physicist and used by them as an alternative to neural networks for experimental elementary particle physics in event reconstruction procedures </p>
</li>
</ul>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../../introduction_to_machine_learning_01_knn/introduction_to_machine_learning_01_knn/" title="k-Nearest Neighbors" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                k-Nearest Neighbors
              </span>
            </div>
          </a>
        
        
          <a href="../../introduction_to_machine_learning_03_svm/introduction_to_machine_learning_03_svm/" title="Support Vector Machine" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Support Vector Machine
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
  <div class="md-footer-social">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    
      <a href="https://github.com/TomaszGolan/introduction_to_machine_learning" class="md-footer-social__link fa fa-github"></a>
    
  </div>

      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../assets/javascripts/application.6cdc17f0.js"></script>
      
      <script>app.initialize({version:"0.17.2",url:{base:"../../.."}})</script>
      
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
    
      
    
  </body>
</html>